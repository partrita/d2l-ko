<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html" class="active"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="트랜스포머를-사용한-대규모-사전-훈련-large-scale-pretraining-with-transformers"><a class="header" href="#트랜스포머를-사용한-대규모-사전-훈련-large-scale-pretraining-with-transformers">트랜스포머를 사용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></h1>
<p>:label:<code>sec_large-pretraining-transformers</code></p>
<p>지금까지 우리의 이미지 분류 및 기계 번역 실험에서,
모델은 특정 작업을 수행하기 위해 입력-출력 예제가 있는 데이터셋에서 <em>처음부터(from scratch)</em> 훈련되었습니다.
예를 들어 트랜스포머는 영어-프랑스어 쌍으로 훈련되어(:numref:<code>sec_transformer</code>) 입력 영어 텍스트를 프랑스어로 번역할 수 있습니다.
결과적으로 각 모델은 데이터 분포의 약간의 변화에도 민감한 *특정 전문가(specific expert)*가 됩니다 (:numref:<code>sec_environment-and-distribution-shift</code>).
더 잘 일반화된 모델, 또는 적응 없이 여러 작업을 수행할 수 있는 더 유능한 *제너럴리스트(generalist)*를 위해,
대규모 데이터에 대해 모델을 *사전 훈련(pretraining)*하는 것이 점점 보편화되고 있습니다.</p>
<p>사전 훈련을 위한 더 큰 데이터가 주어지면, 트랜스포머 아키텍처는 모델 크기와 훈련 컴퓨팅이 증가함에 따라 더 나은 성능을 발휘하여 우수한 <em>확장(scaling)</em> 동작을 보여줍니다.
구체적으로 트랜스포머 기반 언어 모델의 성능은 모델 파라미터 양, 훈련 토큰 및 훈련 컴퓨팅에 따라 거듭제곱 법칙으로 확장됩니다 :cite:<code>kaplan2020scaling</code>.
트랜스포머의 확장성은 더 큰 데이터에서 훈련된 더 큰 비전 트랜스포머(:numref:<code>sec_vision-transformer</code>에서 논의됨)의 크게 향상된 성능으로도 입증됩니다.
더 최근의 성공 사례로는 Atari 게임을 하고, 이미지에 캡션을 달고, 채팅하고, 로봇처럼 행동할 수 있는 <em>제너럴리스트</em> 모델인 Gato가 있습니다 :cite:<code>reed2022generalist</code>. Gato는 텍스트, 이미지, 관절 토크, 버튼 누름을 포함한 다양한 양식(modalities)에 대해 사전 훈련될 때 잘 확장되는 단일 트랜스포머입니다.
주목할 점은 이러한 모든 멀티모달 데이터가 평평한 토큰 시퀀스로 직렬화되어, 트랜스포머에 의해 텍스트 토큰(:numref:<code>sec_transformer</code>)이나 이미지 패치(:numref:<code>sec_vision-transformer</code>)와 유사하게 처리될 수 있다는 것입니다.</p>
<p>멀티모달 데이터에 대한 트랜스포머 사전 훈련의 놀라운 성공에 앞서, 트랜스포머는 풍부한 텍스트로 광범위하게 사전 훈련되었습니다.
원래 기계 번역을 위해 제안된 :numref:<code>fig_transformer</code>의 트랜스포머 아키텍처는 입력 시퀀스를 표현하기 위한 인코더와 타겟 시퀀스를 생성하기 위한 디코더로 구성됩니다.
주로 트랜스포머는 <em>인코더 전용(encoder-only)</em>, <em>인코더-디코더(encoder--decoder)</em>, *디코더 전용(decoder-only)*의 세 가지 다른 모드로 사용될 수 있습니다.
이 장을 마무리하기 위해, 이 세 가지 모드를 검토하고 트랜스포머 사전 훈련의 확장성을 설명할 것입니다.</p>
<h2 id="인코더-전용-encoder-only"><a class="header" href="#인코더-전용-encoder-only">인코더 전용 (Encoder-Only)</a></h2>
<p>트랜스포머 인코더만 사용되는 경우,
입력 토큰 시퀀스는 출력(예: 분류)으로 추가 투영될 수 있는 동일한 수의 표현으로 변환됩니다.
트랜스포머 인코더는 모든 입력 토큰이 서로에게 주의를 기울이는 셀프 어텐션 레이어로 구성됩니다.
예를 들어 :numref:<code>fig_vit</code>에 묘사된 비전 트랜스포머는 인코더 전용이며, 입력 이미지 패치 시퀀스를 특수 "&lt;cls&gt;" 토큰의 표현으로 변환합니다.
이 표현은 모든 입력 토큰에 의존하므로 분류 레이블로 추가 투영됩니다.
이 설계는 텍스트에 대해 사전 훈련된 초기 인코더 전용 트랜스포머인 BERT(Bidirectional Encoder Representations from Transformers)에서 영감을 받았습니다 :cite:<code>Devlin.Chang.Lee.ea.2018</code>.</p>
<h3 id="bert-사전-훈련-pretraining-bert"><a class="header" href="#bert-사전-훈련-pretraining-bert">BERT 사전 훈련 (Pretraining BERT)</a></h3>
<p><img src="../img/bert-encoder-only.svg" alt="왼쪽: 마스킹된 언어 모델링으로 BERT 사전 훈련. 마스킹된 &quot;love&quot; 토큰의 예측은 &quot;love&quot; 전후의 모든 입력 토큰에 의존합니다. 오른쪽: 트랜스포머 인코더의 주의 패턴. 세로축을 따른 각 토큰은 가로축을 따른 모든 입력 토큰에 주의를 기울입니다." />
:label:<code>fig_bert-encoder-only</code></p>
<p>BERT는 *마스킹된 언어 모델링(masked language modeling)*을 사용하여 텍스트 시퀀스에 대해 사전 훈련됩니다:
무작위로 마스킹된 토큰이 있는 입력 텍스트가 트랜스포머 인코더에 공급되어 마스킹된 토큰을 예측합니다.
:numref:<code>fig_bert-encoder-only</code>에 설명된 대로,
원래 텍스트 시퀀스 "I", "love", "this", "red", "car" 앞에 "&lt;cls&gt;" 토큰이 추가되고, "&lt;mask&gt;" 토큰이 "love"를 무작위로 대체합니다. 그런 다음 마스킹된 토큰 "love"와 그 예측 사이의 크로스 엔트로피 손실이 사전 훈련 중에 최소화됩니다.
트랜스포머 인코더의 주의 패턴(:numref:<code>fig_bert-encoder-only</code>의 오른쪽)에는 제약이 없으므로 모든 토큰이 서로에게 주의를 기울일 수 있음에 유의하십시오.
따라서 "love"의 예측은 시퀀스에서 그 전후의 입력 토큰에 의존합니다.
이것이 BERT가 "양방향 인코더"인 이유입니다.
수동 라벨링이 필요 없이 책과 위키피디아의 대규모 텍스트 데이터를 사용하여 BERT를 사전 훈련할 수 있습니다.</p>
<h3 id="bert-미세-조정-fine-tuning-bert"><a class="header" href="#bert-미세-조정-fine-tuning-bert">BERT 미세 조정 (Fine-Tuning BERT)</a></h3>
<p>사전 훈련된 BERT는 단일 텍스트 또는 텍스트 쌍을 포함하는 다운스트림 인코딩 작업에 *미세 조정(fine-tuned)*될 수 있습니다. 미세 조정 중에 무작위 파라미터가 있는 추가 레이어를 BERT에 추가할 수 있습니다: 이러한 파라미터와 사전 훈련된 BERT 파라미터는 다운스트림 작업의 훈련 데이터에 맞게 <em>업데이트</em>됩니다.</p>
<p><img src="../img/bert-finetune-classification.svg" alt="감성 분석을 위한 BERT 미세 조정." />
:label:<code>fig_bert-finetune-classification</code></p>
<p>:numref:<code>fig_bert-finetune-classification</code>은 감성 분석을 위한 BERT의 미세 조정을 보여줍니다.
트랜스포머 인코더는 사전 훈련된 BERT로, 텍스트 시퀀스를 입력으로 받아 "&lt;cls&gt;" 표현(입력의 전역 표현)을 추가적인 완전 연결 레이어에 공급하여 감성을 예측합니다.
미세 조정 중에 감성 분석 데이터의 예측과 레이블 간의 크로스 엔트로피 손실이 기울기 기반 알고리즘을 통해 최소화되며, 여기서 추가 레이어는 처음부터 훈련되는 반면 BERT의 사전 훈련된 파라미터는 업데이트됩니다.
BERT는 감성 분석 이상의 일을 합니다.
2,500억 개의 훈련 토큰에서 3억 5천만 개의 파라미터를 가진 BERT가 학습한 일반 언어 표현은 단일 텍스트 분류, 텍스트 쌍 분류 또는 회귀, 텍스트 태깅, 질문 응답과 같은 자연어 작업의 최첨단 기술을 발전시켰습니다.</p>
<p>이러한 다운스트림 작업에 텍스트 쌍 이해가 포함되어 있음을 알 수 있습니다.
BERT 사전 훈련에는 한 문장이 다른 문장 바로 뒤에 오는지 예측하는 또 다른 손실이 있습니다.
그러나 이 손실은 나중에 동일한 크기의 BERT 변형인 RoBERTa를 2,000억 개의 토큰으로 사전 훈련할 때 덜 유용한 것으로 밝혀졌습니다 :cite:<code>Liu.Ott.Goyal.ea.2019</code>.
BERT의 다른 파생물들은 모델 아키텍처나 사전 훈련 목표를 개선했습니다. 예를 들어 ALBERT(파라미터 공유 강제) :cite:<code>lan2019albert</code>,
SpanBERT(텍스트 범위 표현 및 예측) :cite:<code>joshi2020spanbert</code>,
DistilBERT(지식 증류를 통한 경량화) :cite:<code>sanh2019distilbert</code>,
ELECTRA(대체된 토큰 감지) :cite:<code>clark2019electra</code>가 있습니다.
또한 BERT는 컴퓨터 비전에서의 트랜스포머 사전 훈련에 영감을 주었습니다. 예를 들어 비전 트랜스포머 :cite:<code>Dosovitskiy.Beyer.Kolesnikov.ea.2021</code>,
Swin Transformer :cite:<code>liu2021swin</code>,
MAE(masked autoencoders) :cite:<code>he2022masked</code>가 있습니다.</p>
<h2 id="인코더-디코더-encoder--decoder"><a class="header" href="#인코더-디코더-encoder--decoder">인코더-디코더 (Encoder--Decoder)</a></h2>
<p>트랜스포머 인코더는 일련의 입력 토큰을 동일한 수의 출력 표현으로 변환하므로, 인코더 전용 모드는 기계 번역처럼 임의의 길이의 시퀀스를 생성할 수 없습니다.
원래 기계 번역을 위해 제안된 대로, 트랜스포머 아키텍처에는 인코더 출력과 디코더 출력 모두에 조건부로 임의의 길이의 타겟 시퀀스를 토큰별로 자동 회귀적으로 예측하는 디코더가 장착될 수 있습니다:
(i) 인코더 출력에 대한 컨디셔닝을 위해 인코더-디코더 크로스 어텐션(:numref:<code>fig_transformer</code>의 디코더 멀티 헤드 어텐션)은 타겟 토큰이 <em>모든</em> 입력 토큰에 주의를 기울일 수 있게 합니다;
(ii) 디코더 출력에 대한 컨디셔닝은 소위 <em>인과(causal)</em> 어텐션(이 이름은 문헌에서 흔하지만 인과 관계에 대한 적절한 연구와는 관련이 거의 없기 때문에 오해의 소지가 있습니다) 패턴(:numref:<code>fig_transformer</code>의 디코더 마스킹된 멀티 헤드 어텐션)에 의해 달성됩니다. 여기서 타겟 토큰은 타겟 시퀀스의 <em>과거</em> 및 <em>현재</em> 토큰에만 주의를 기울일 수 있습니다.</p>
<p>인간이 라벨링한 기계 번역 데이터를 넘어 인코더-디코더 트랜스포머를 사전 훈련하기 위해,
BART :cite:<code>lewis2019bart</code>와 T5 :cite:<code>raffel2020exploring</code>는 대규모 텍스트 코퍼스에서 사전 훈련된 두 개의 동시에 제안된 인코더-디코더 트랜스포머입니다.
둘 다 사전 훈련 목표에서 원본 텍스트를 재구성하려고 시도하지만, 전자는 입력 노이즈(예: 마스킹, 삭제, 순열 및 회전)를 강조하고 후자는 포괄적인 절제 연구(ablation studies)를 통한 멀티태스크 통합을 강조합니다.</p>
<h3 id="t5-사전-훈련-pretraining-t5"><a class="header" href="#t5-사전-훈련-pretraining-t5">T5 사전 훈련 (Pretraining T5)</a></h3>
<p>사전 훈련된 트랜스포머 인코더-디코더의 예로서,
T5(Text-to-Text Transfer Transformer)는 많은 작업을 동일한 텍스트-투-텍스트 문제로 통합합니다:
모든 작업에 대해 인코더의 입력은 작업 설명(예: "Summarize", ":")과 작업 입력(예: 기사의 토큰 시퀀스)이 뒤따르는 것이고,
디코더는 작업 출력(예: 입력 기사를 요약하는 토큰 시퀀스)을 예측합니다.
텍스트-투-텍스트로 수행하기 위해, T5는 입력 텍스트에 조건부로 일부 타겟 텍스트를 생성하도록 훈련됩니다.</p>
<p><img src="../img/t5-encoder-decoder.svg" alt="왼쪽: 연속적인 범위를 예측하여 T5 사전 훈련. 원래 문장은 &quot;I&quot;, &quot;love&quot;, &quot;this&quot;, &quot;red&quot;, &quot;car&quot;이며, 여기서 &quot;love&quot;는 특수 &quot;&lt;X&gt;&quot; 토큰으로 대체되고 연속적인 &quot;red&quot;, &quot;car&quot;는 특수 &quot;&lt;Y&gt;&quot; 토큰으로 대체됩니다. 타겟 시퀀스는 특수 &quot;&lt;Z&gt;&quot; 토큰으로 끝납니다. 오른쪽: 트랜스포머 인코더-디코더의 주의 패턴. 인코더 셀프 어텐션(아래쪽 정사각형)에서 모든 입력 토큰은 서로에게 주의를 기울입니다; 인코더-디코더 크로스 어텐션(위쪽 직사각형)에서 각 타겟 토큰은 모든 입력 토큰에 주의를 기울입니다; 디코더 셀프 어텐션(위쪽 삼각형)에서 각 타겟 토큰은 현재 및 과거 타겟 토큰에만 주의를 기울입니다(인과적)." />
:label:<code>fig_t5-encoder-decoder</code></p>
<p>임의의 원본 텍스트에서 입력과 출력을 얻기 위해,
T5는 연속적인 범위를 예측하도록 사전 훈련됩니다.
구체적으로 텍스트의 토큰은 무작위로 특수 토큰으로 대체되며, 여기서 각 연속적인 범위는 동일한 특수 토큰으로 대체됩니다.
:numref:<code>fig_t5-encoder-decoder</code>의 예를 고려해 보십시오. 여기서 원본 텍스트는 "I", "love", "this", "red", "car"입니다.
"love", "red", "car" 토큰은 무작위로 특수 토큰으로 대체됩니다.
"red"와 "car"는 연속적인 범위이므로 동일한 특수 토큰으로 대체됩니다.
결과적으로 입력 시퀀스는 "I", "&lt;X&gt;", "this", "&lt;Y&gt;"이고,
타겟 시퀀스는 "&lt;X&gt;", "love", "&lt;Y&gt;", "red", "car", "&lt;Z&gt;"이며,
여기서 "&lt;Z&gt;"는 끝을 표시하는 또 다른 특수 토큰입니다.
:numref:<code>fig_t5-encoder-decoder</code>에 표시된 것처럼, 디코더는 시퀀스 예측 중에 미래 토큰에 주의를 기울이는 것을 방지하기 위해 인과적 어텐션 패턴을 갖습니다.</p>
<p>T5에서 연속적인 범위를 예측하는 것은 손상된 텍스트를 재구성하는 것으로도 불립니다.
이 목표를 가지고 T5는 웹에서 가져온 깨끗한 영어 텍스트로 구성된 C4(Colossal Clean Crawled Corpus) 데이터의 1조 개 토큰으로 사전 훈련됩니다 :cite:<code>raffel2020exploring</code>.</p>
<h3 id="t5-미세-조정-fine-tuning-t5"><a class="header" href="#t5-미세-조정-fine-tuning-t5">T5 미세 조정 (Fine-Tuning T5)</a></h3>
<p>BERT와 마찬가지로 T5는 이 작업을 수행하기 위해 작업별 훈련 데이터에 대해 미세 조정(T5 파라미터 업데이트)되어야 합니다.
BERT 미세 조정과의 주요 차이점은 다음과 같습니다:
(i) T5 입력에는 작업 설명이 포함됩니다;
(ii) T5는 트랜스포머 디코더를 사용하여 임의 길이의 시퀀스를 생성할 수 있습니다;
(iii) 추가 레이어가 필요하지 않습니다.</p>
<p><img src="../img/t5-finetune-summarization.svg" alt="텍스트 요약을 위한 T5 미세 조정. 작업 설명과 기사 토큰 모두 트랜스포머 인코더에 입력되어 요약을 예측합니다." />
:label:<code>fig_t5-finetune-summarization</code></p>
<p>:numref:<code>fig_t5-finetune-summarization</code>은 텍스트 요약을 예로 들어 T5 미세 조정을 설명합니다.
이 다운스트림 작업에서 작업 설명 토큰 "Summarize", ":" 뒤에 기사 토큰이 인코더에 입력됩니다.</p>
<p>미세 조정 후, 110억 개의 파라미터를 가진 T5(T5-11B)는 여러 인코딩(예: 분류) 및 생성(예: 요약) 벤치마크에서 최첨단 결과를 달성했습니다.
출시 이후 T5는 후속 연구에서 광범위하게 사용되었습니다.
예를 들어 스위치 트랜스포머(switch Transformers)는 더 나은 계산 효율성을 위해 파라미터의 하위 집합을 활성화하도록 T5를 기반으로 설계되었습니다 :cite:<code>fedus2022switch</code>.
Imagen이라는 텍스트-투-이미지 모델에서는 텍스트가 46억 개의 파라미터를 가진 고정된 T5 인코더(T5-XXL)에 입력됩니다 :cite:<code>saharia2022photorealistic</code>.
:numref:<code>fig_imagen</code>의 사실적인 텍스트-투-이미지 예제는 T5 인코더만으로도 미세 조정 없이 텍스트를 효과적으로 표현할 수 있음을 시사합니다.</p>
<p><img src="../img/imagen.png" alt="T5의 텍스트 인코더를 사용하는 Imagen 모델의 텍스트-투-이미지 예제 (그림 출처: :citet:saharia2022photorealistic)." />
:width:<code>700px</code>
:label:<code>fig_imagen</code></p>
<h2 id="디코더-전용-decoder-only"><a class="header" href="#디코더-전용-decoder-only">디코더 전용 (Decoder-Only)</a></h2>
<p>우리는 인코더 전용 및 인코더-디코더 트랜스포머를 검토했습니다.
대안으로, 디코더 전용 트랜스포머는 :numref:<code>fig_transformer</code>에 묘사된 원래 인코더-디코더 아키텍처에서 전체 인코더와 인코더-디코더 크로스 어텐션이 있는 디코더 하위 레이어를 제거합니다.
오늘날 디코더 전용 트랜스포머는 대규모 언어 모델링(:numref:<code>sec_language-model</code>)의 <em>사실상</em> 아키텍처가 되었으며, 이는 자기 지도 학습을 통해 전 세계의 풍부한 라벨이 없는 텍스트 코퍼스를 활용합니다.</p>
<h3 id="gpt와-gpt-2"><a class="header" href="#gpt와-gpt-2">GPT와 GPT-2</a></h3>
<p>언어 모델링을 훈련 목표로 사용하여, GPT(generative pre-training) 모델은 트랜스포머 디코더를 백본으로 선택합니다 :cite:<code>Radford.Narasimhan.Salimans.ea.2018</code>.</p>
<p><img src="../img/gpt-decoder-only.svg" alt="왼쪽: 언어 모델링으로 GPT 사전 훈련. 타겟 시퀀스는 한 토큰 이동된 입력 시퀀스입니다. &quot;&lt;bos&gt;&quot;와 &quot;&lt;eos&gt;&quot;는 각각 시퀀스의 시작과 끝을 표시하는 특수 토큰입니다. 오른쪽: 트랜스포머 디코더의 주의 패턴. 세로축을 따른 각 토큰은 가로축을 따른 과거 토큰에만 주의를 기울입니다(인과적)." />
:label:<code>fig_gpt-decoder-only</code></p>
<p>:numref:<code>subsec_partitioning-seqs</code>에 설명된 자동 회귀 언어 모델 훈련에 따라,
:numref:<code>fig_gpt-decoder-only</code>는 트랜스포머 인코더를 사용한 GPT 사전 훈련을 보여줍니다. 여기서 타겟 시퀀스는 한 토큰 이동된 입력 시퀀스입니다.
트랜스포머 디코더의 주의 패턴은 각 토큰이 과거 토큰에만 주의를 기울이도록 강제한다는 점에 유의하십시오(미래 토큰은 아직 선택되지 않았으므로 주의를 기울일 수 없습니다).</p>
<p>GPT는 1억 개의 파라미터를 가지고 있으며 개별 다운스트림 작업에 대해 미세 조정해야 합니다.
훨씬 더 큰 트랜스포머-디코더 언어 모델인 GPT-2가 1년 후에 소개되었습니다 :cite:<code>Radford.Wu.Child.ea.2019</code>.
GPT의 원래 트랜스포머 디코더와 비교하여, GPT-2에서는 사전 정규화(:numref:<code>subsec_vit-encoder</code>에서 논의됨)와 개선된 초기화 및 가중치 스케일링이 채택되었습니다.
40GB의 텍스트로 사전 훈련된 15억 파라미터 GPT-2는 <em>파라미터나 아키텍처 업데이트 없이</em> 언어 모델링 벤치마크에서 최첨단 결과와 여러 다른 작업에서 유망한 결과를 얻었습니다.</p>
<h3 id="gpt-3와-그-이후-gpt-3-and-beyond"><a class="header" href="#gpt-3와-그-이후-gpt-3-and-beyond">GPT-3와 그 이후 (GPT-3 and Beyond)</a></h3>
<p>GPT-2는 모델 업데이트 없이 여러 작업에 동일한 언어 모델을 사용할 수 있는 가능성을 보여주었습니다.
이는 기울기 계산을 통한 모델 업데이트가 필요한 미세 조정보다 계산 효율적입니다.</p>
<p><img src="../img/gpt-3-xshot.svg" alt="언어 모델(트랜스포머 디코더)을 사용한 제로 샷, 원 샷, 퓨 샷 인컨텍스트 학습. 파라미터 업데이트가 필요하지 않습니다." />
:label:<code>fig_gpt-3-xshot</code></p>
<p>파라미터 업데이트 없이 언어 모델을 더 계산 효율적으로 사용하는 것을 설명하기 전에,
:numref:<code>sec_rnn-scratch</code>에서 언어 모델이 일부 접두사 텍스트 시퀀스에 조건부로 텍스트 시퀀스를 생성하도록 훈련될 수 있음을 상기하십시오.
따라서 사전 훈련된 언어 모델은 작업 설명, 작업별 입력-출력 예제 및 프롬프트(작업 입력)가 있는 입력 시퀀스에 조건부로 <em>파라미터 업데이트 없이</em> 시퀀스로서 작업 출력을 생성할 수 있습니다.
이 학습 패러다임을 *인컨텍스트 학습(in-context learning)*이라고 하며 :cite:<code>brown2020language</code>,
작업별 입력-출력 예제가 없거나, 하나 있거나, 몇 개 있을 때 각각 <em>제로 샷(zero-shot)</em>, <em>원 샷(one-shot)</em>, *퓨 샷(few-shot)*으로 더 분류될 수 있습니다 (:numref:<code>fig_gpt-3-xshot</code>).</p>
<p><img src="../img/gpt3-xshot-scaling.png" alt="모든 42개 정확도 기준 벤치마크에 대한 GPT-3의 종합 성능 (캡션 수정 및 그림 출처: :citet:brown2020language)." />
:width:<code>400px</code>
:label:<code>fig_gpt3-xshot-scaling</code></p>
<p>이 세 가지 설정은 GPT-3에서 테스트되었습니다 :cite:<code>brown2020language</code>.
GPT-3의 가장 큰 버전은 GPT-2보다 약 두 자릿수 더 큰 데이터 및 모델 크기를 사용합니다.
GPT-3는 교대 레이어에서 주의 패턴(:numref:<code>fig_gpt-decoder-only</code>의 오른쪽)이 더 희소하다는 점을 제외하고는 직계 전임자인 GPT-2와 동일한 트랜스포머 디코더 아키텍처를 사용합니다.
3,000억 개의 토큰으로 사전 훈련된 GPT-3는 더 큰 모델 크기에서 더 나은 성능을 발휘하며, 퓨 샷 성능이 가장 빠르게 증가합니다 (:numref:<code>fig_gpt3-xshot-scaling</code>).</p>
<p>후속 GPT-4 모델은 보고서에서 기술적 세부 사항을 완전히 공개하지 않았습니다 :cite:<code>openai2023gpt4</code>.
전임자들과 달리, GPT-4는 텍스트와 이미지를 모두 입력으로 받아 텍스트 출력을 생성할 수 있는 대규모 멀티모달 모델입니다.</p>
<h2 id="확장성-scalability"><a class="header" href="#확장성-scalability">확장성 (Scalability)</a></h2>
<p>:numref:<code>fig_gpt3-xshot-scaling</code>은 GPT-3 언어 모델에서 트랜스포머의 확장성을 경험적으로 보여줍니다.
언어 모델링의 경우, 트랜스포머의 확장성에 대한 더 포괄적인 경험적 연구를 통해 연구자들은 더 많은 데이터와 컴퓨팅으로 더 큰 트랜스포머를 훈련할 가능성을 보게 되었습니다 :cite:<code>kaplan2020scaling</code>.</p>
<p><img src="../img/scaling-power-law.png" alt="모델 크기, 데이터셋 크기 및 훈련에 사용되는 컴퓨팅 양을 늘리면 트랜스포머 언어 모델 성능이 부드럽게 향상됩니다. 최적의 성능을 위해서는 세 가지 요소를 모두 함께 확장해야 합니다. 경험적 성능은 다른 두 요소에 의해 병목 현상이 발생하지 않을 때 각 개별 요소와 거듭제곱 법칙 관계를 갖습니다 (캡션 수정 및 그림 출처: :citet:kaplan2020scaling)." />
:width:<code>700px</code>
:label:<code>fig_scaling-power-law3</code></p>
<p>:numref:<code>fig_scaling-power-law3</code>에 표시된 것처럼,
모델 크기(임베딩 레이어를 제외한 파라미터 수), 데이터셋 크기(훈련 토큰 수) 및 훈련 컴퓨팅 양(PetaFLOP/s-days, 임베딩 레이어 제외)에 대한 성능에서 *거듭제곱 법칙 확장(power-law scaling)*을 관찰할 수 있습니다.
일반적으로 이 세 가지 요소를 모두 함께 늘리면 성능이 향상됩니다.
그러나 이들을 <em>어떻게</em> 함께 늘릴지는 여전히 논쟁의 여지가 있습니다 :cite:<code>hoffmann2022training</code>.</p>
<p><img src="../img/scaling-sample-conv.png" alt="트랜스포머 언어 모델 훈련 실행 (그림 출처: :citet:kaplan2020scaling)." />
:width:<code>700px</code>
:label:<code>fig_scaling-sample-conv</code></p>
<p>성능 향상 외에도, 큰 모델은 작은 모델보다 더 나은 샘플 효율성을 누립니다. :numref:<code>fig_scaling-sample-conv</code>는 큰 모델이 작은 모델이 달성한 동일한 수준의 성능을 수행하기 위해 더 적은 훈련 샘플(처리된 토큰)이 필요하며, 성능이 컴퓨팅과 함께 부드럽게 확장됨을 보여줍니다.</p>
<p><img src="../img/scaling-gpt3.png" alt="GPT-3 성능(크로스 엔트로피 검증 손실)은 훈련에 사용된 컴퓨팅 양에 따른 거듭제곱 법칙 추세를 따릅니다. :citet:kaplan2020scaling에서 관찰된 거듭제곱 법칙 동작은 예측된 곡선에서 약간만 벗어나며 두 자릿수 더 계속됩니다. 임베딩 파라미터는 컴퓨팅 및 파라미터 수에서 제외됩니다 (캡션 수정 및 그림 출처: :citet:brown2020language)." />
:width:<code>250px</code>
:label:<code>fig_scaling-gpt3</code></p>
<p>:citet:<code>kaplan2020scaling</code>의 경험적 확장 동작은 후속 대규모 트랜스포머 모델에서 테스트되었습니다. 예를 들어 GPT-3는 :numref:<code>fig_scaling-gpt3</code>에서 두 자릿수 더 큰 규모로 이 가설을 뒷받침했습니다.</p>
<h2 id="대규모-언어-모델-large-language-models"><a class="header" href="#대규모-언어-모델-large-language-models">대규모 언어 모델 (Large Language Models)</a></h2>
<p>GPT 시리즈에서 트랜스포머의 확장성은 후속 대규모 언어 모델에 영감을 주었습니다.
GPT-2 트랜스포머 디코더는 2,700억 개의 훈련 토큰으로 5,300억 파라미터의 Megatron-Turing NLG :cite:<code>smith2022using</code>를 훈련하는 데 사용되었습니다. GPT-2 설계를 따라 3,000억 개의 토큰으로 사전 훈련된 2,800억 파라미터의 Gopher :cite:<code>rae2021scaling</code>는 다양한 작업에서 경쟁력 있는 성능을 보였습니다.
동일한 아키텍처를 상속하고 Gopher와 동일한 컴퓨팅 예산을 사용하여, Chinchilla :cite:<code>hoffmann2022training</code>는 훨씬 더 오래(1조 4천억 훈련 토큰) 훈련된 실질적으로 더 작은(700억 파라미터) 모델로, 파라미터 수보다 토큰 수에 더 중점을 두어 많은 작업에서 Gopher를 능가했습니다.
언어 모델링의 확장 라인을 계속 이어가며,
PaLM(Pathway Language Model) :cite:<code>chowdhery2022palm</code>은 7,800억 개의 토큰으로 사전 훈련된 수정된 설계를 가진 5,400억 파라미터의 트랜스포머 디코더로, BIG-Bench 벤치마크 :cite:<code>srivastava2022beyond</code>에서 평균 인간 성능을 능가했습니다. 그 후속 버전인 PaLM 2 :cite:<code>anil2023palm</code>는 데이터와 모델을 대략 1:1로 확장하고 다국어 및 추론 기능을 개선했습니다.
제너럴리스트(PaLM)를 추가로 훈련하는 Minerva :cite:<code>lewkowycz2022solving</code>와 일반 코퍼스에서 훈련되지 않은 Galactica :cite:<code>taylor2022galactica</code>와 같은 다른 대규모 언어 모델은 유망한 정량적 및 과학적 추론 능력을 보여주었습니다.</p>
<p>OPT(Open Pretrained Transformers) :cite:<code>zhang2022opt</code>, BLOOM :cite:<code> scao2022bloom</code>, FALCON :cite:<code>penedo2023refinedweb</code>과 같은 오픈 소스 릴리스는 대규모 언어 모델의 연구와 사용을 민주화했습니다.
추론 시간의 계산 효율성에 초점을 맞춘 오픈 소스 Llama 1 :cite:<code>touvron2023llama</code>은 일반적으로 사용되는 것보다 더 많은 토큰으로 훈련하여 훨씬 더 큰 모델을 능가했습니다. 업데이트된 Llama 2 :cite:<code>touvron2023llama2</code>는 사전 훈련 코퍼스를 40% 더 늘려 경쟁력 있는 비공개 소스 모델의 성능과 일치할 수 있는 제품 모델로 이어졌습니다.</p>
<p>:citet:<code>wei2022emergent</code>는 작은 모델에는 없지만 큰 모델에는 존재하는 대규모 언어 모델의 창발적 능력에 대해 논의했습니다.
그러나 단순히 모델 크기를 늘린다고 해서 본질적으로 모델이 인간의 지시를 더 잘 따르게 되는 것은 아닙니다.
:citet:<code>wei2021finetuned,sanh2021multitask</code>는 *지시(instructions)*를 통해 설명된 다양한 데이터셋에서 대규모 언어 모델을 미세 조정하면 보류된(held-out) 작업에 대한 제로 샷 성능을 향상시킬 수 있음을 발견했습니다.
<em>인간 피드백을 통한 강화 학습</em>을 사용하여 :citet:<code>ouyang2022training</code>은 다양한 지시 세트를 따르도록 GPT-3를 미세 조정했습니다.
미세 조정을 통해 언어 모델을 인간의 의도와 정렬하는 결과물인 InstructGPT를 따라 :cite:<code>ouyang2022training</code>,
<a href="https://chat.openai.com/">ChatGPT</a>는 인간과의 대화를 기반으로 인간과 유사한 응답(예: 코드 디버깅 및 창의적 글쓰기)을 생성할 수 있으며 많은 자연어 처리 작업을 제로 샷으로 수행할 수 있습니다 :cite:<code>qin2023chatgpt</code>.
:citet:<code>bai2022constitutional</code>는 인간 입력(예: 사람이 라벨링한 데이터)을 모델 출력으로 대체하여 지시 튜닝 프로세스를 부분적으로 자동화했습니다. 이는 <em>AI 피드백을 통한 강화 학습</em>으로도 알려져 있습니다.</p>
<p>대규모 언어 모델은 인컨텍스트 학습을 통해 모델이 원하는 작업을 수행하도록 유도하기 위해 텍스트 입력을 공식화하는 흥미로운 전망을 제공하며, 이는 *프롬프팅(prompting)*으로도 알려져 있습니다.
특히,
퓨 샷 "질문, 중간 추론 단계, 답변" 데모가 있는 인컨텍스트 학습 방법인 <em>생각의 사슬(chain-of-thought) 프롬프팅</em> :cite:<code>wei2022chain</code>은
수학적, 상식적, 상징적 추론 문제를 해결하기 위해 대규모 언어 모델의 복잡한 추론 능력을 끌어냅니다.
여러 추론 경로 샘플링 :cite:<code>wang2023self</code>, 퓨 샷 데모 다양화 :cite:<code>zhang2023automatic</code>,
복잡한 문제를 하위 문제로 줄이는 것 :cite:<code>zhou2023least</code>은 모두 추론 정확도를 향상시킬 수 있습니다.
실제로 각 답변 바로 앞에 "단계별로 생각해보자"와 같은 간단한 프롬프트를 사용하면,
대규모 언어 모델은 괜찮은 정확도로 <em>제로 샷</em> 생각의 사슬 추론을 수행할 수도 있습니다 :cite:<code>kojima2022large</code>.
텍스트와 이미지로 구성된 멀티모달 입력의 경우에도,
언어 모델은 텍스트 입력만 사용하는 것보다 더 높은 정확도로 멀티모달 생각의 사슬 추론을 수행할 수 있습니다 :cite:<code>zhang2023multicot</code>.</p>
<h2 id="요약-및-토론-summary-and-discussion"><a class="header" href="#요약-및-토론-summary-and-discussion">요약 및 토론 (Summary and Discussion)</a></h2>
<p>트랜스포머는 인코더 전용(예: BERT), 인코더-디코더(예: T5), 디코더 전용(예: GPT 시리즈)으로 사전 훈련되었습니다. 사전 훈련된 모델은 모델 업데이트(예: 미세 조정) 또는 업데이트 없이(예: 퓨 샷) 다른 작업을 수행하도록 조정될 수 있습니다. 트랜스포머의 확장성은 더 큰 모델, 더 많은 훈련 데이터, 더 많은 훈련 컴퓨팅에서 더 나은 성능을 얻을 수 있음을 시사합니다. 트랜스포머는 처음에 텍스트 데이터를 위해 설계되고 사전 훈련되었기 때문에 이 섹션은 자연어 처리 쪽으로 약간 기울어져 있습니다. 그럼에도 불구하고 위에서 논의된 모델들은 여러 양식에 걸친 더 최근 모델에서 종종 발견될 수 있습니다. 예를 들어,
(i) Chinchilla :cite:<code>hoffmann2022training</code>는 퓨 샷 학습을 위한 시각적 언어 모델인 Flamingo :cite:<code>alayrac2022flamingo</code>로 확장되었습니다;
(ii) GPT-2 :cite:<code>Radford.Wu.Child.ea.2019</code>와 비전 트랜스포머는 CLIP(Contrastive Language-Image Pre-training) :cite:<code>radford2021learning</code>에서 텍스트와 이미지를 인코딩하며, 이 이미지 및 텍스트 임베딩은 나중에 DALL-E 2 텍스트-투-이미지 시스템 :cite:<code>ramesh2022hierarchical</code>에 채택되었습니다. 아직 멀티모달 사전 훈련에서 트랜스포머 확장성에 대한 체계적인 연구는 없지만, Parti :cite:<code>yu2022scaling</code>라는 완전 트랜스포머 텍스트-투-이미지 모델은 양식 전반에 걸친 확장 가능성을 보여줍니다:
더 큰 Parti는 충실도 높은 이미지 생성과 내용이 풍부한 텍스트 이해 능력이 더 뛰어납니다 (:numref:<code>fig_parti</code>).</p>
<p><img src="../img/parti.png" alt="증가하는 크기(350M, 750M, 3B, 20B)의 Parti 모델에 의해 동일한 텍스트에서 생성된 이미지 예제 (예제 출처: :citet:yu2022scaling)." />
:width:<code>700px</code>
:label:<code>fig_parti</code></p>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>서로 다른 작업으로 구성된 미니배치를 사용하여 T5를 미세 조정하는 것이 가능합니까? 그 이유는 무엇입니까? GPT-2의 경우는 어떻습니까?</li>
<li>강력한 언어 모델이 주어졌을 때 어떤 응용 프로그램을 생각할 수 있습니까?</li>
<li>텍스트 분류를 수행하기 위해 추가 레이어를 추가하여 언어 모델을 미세 조정하라는 요청을 받았다고 가정해 보십시오. 어디에 추가하시겠습니까? 그 이유는 무엇입니까?</li>
<li>입력 시퀀스가 타겟 시퀀스 예측 내내 항상 사용 가능한 시퀀스-투-시퀀스 문제(예: 기계 번역)를 고려하십시오. 디코더 전용 트랜스포머로 모델링할 때의 한계는 무엇일 수 있습니까? 그 이유는 무엇입니까?</li>
</ol>
<p><a href="https://discuss.d2l.ai/t/9232">Discussions</a></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_optimization/index.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_optimization/index.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
