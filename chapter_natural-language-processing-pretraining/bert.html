<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT)) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/bert.html" class="active"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="트랜스포머로부터의-양방향-인코더-표현-bert"><a class="header" href="#트랜스포머로부터의-양방향-인코더-표현-bert">트랜스포머로부터의 양방향 인코더 표현 (BERT)</a></h1>
<p>:label:<code>sec_bert</code></p>
<p>우리는 자연어 이해를 위한 여러 단어 임베딩 모델을 소개했습니다.
사전 훈련 후, 출력은 각 행이 미리 정의된 어휘의 단어를 나타내는 벡터인 행렬로 생각할 수 있습니다.
사실, 이러한 단어 임베딩 모델은 모두 *문맥 독립적(context-independent)*입니다.
이 속성을 설명하는 것으로 시작하겠습니다.</p>
<h2 id="문맥-독립적-표현에서-문맥-의존적-표현으로-from-context-independent-to-context-sensitive"><a class="header" href="#문맥-독립적-표현에서-문맥-의존적-표현으로-from-context-independent-to-context-sensitive">문맥 독립적 표현에서 문맥 의존적 표현으로 (From Context-Independent to Context-Sensitive)</a></h2>
<p>:numref:<code>sec_word2vec_pretraining</code>과 :numref:<code>sec_synonyms</code>의 실험을 상기해 보십시오.
예를 들어, word2vec과 GloVe는 단어의 문맥에 관계없이 동일한 단어에 동일한 사전 훈련된 벡터를 할당합니다(문맥이 있는 경우).
공식적으로, 임의의 토큰 $x$의 문맥 독립적 표현은 $x$만을 입력으로 취하는 함수 $f(x)$입니다.
자연어의 다의어와 복잡한 의미론의 풍부함을 고려할 때,
문맥 독립적 표현은 명백한 한계를 가지고 있습니다.
예를 들어, "a crane is flying"과 "a crane driver came"이라는 문맥에서 "crane"이라는 단어는 완전히 다른 의미를 갖습니다(전자는 '학', 후자는 '기중기').
따라서 동일한 단어라도 문맥에 따라 다른 표현이 할당되어야 할 수 있습니다.</p>
<p>이것은 단어의 표현이 문맥에 의존하는 <em>문맥 의존적(context-sensitive)</em> 단어 표현의 개발에 동기를 부여했습니다.
따라서 토큰 $x$의 문맥 의존적 표현은 $x$와 그 문맥 $c(x)$ 모두에 의존하는 함수 $f(x, c(x))$입니다.
인기 있는 문맥 의존적 표현으로는
TagLM(language-model-augmented sequence tagger) :cite:<code>Peters.Ammar.Bhagavatula.ea.2017</code>,
CoVe(Context Vectors) :cite:<code>McCann.Bradbury.Xiong.ea.2017</code>,
ELMo(Embeddings from Language Models) :cite:<code>Peters.Neumann.Iyyer.ea.2018</code>가 있습니다.</p>
<p>예를 들어, 전체 시퀀스를 입력으로 취함으로써,
ELMo는 입력 시퀀스의 각 단어에 표현을 할당하는 함수입니다.
구체적으로, ELMo는 사전 훈련된 양방향 LSTM의 모든 중간 레이어 표현을 출력 표현으로 결합합니다.
그런 다음 ELMo 표현은 다운스트림 작업의 기존 지도 모델에 추가 특징으로 추가됩니다. 예를 들어 기존 모델의 토큰에 대한 원본 표현(예: GloVe)과 ELMo 표현을 연결하는 방식입니다.
한편으로, 사전 훈련된 양방향 LSTM 모델의 모든 가중치는 ELMo 표현이 추가된 후 고정됩니다.
반면, 기존 지도 모델은 주어진 작업에 맞게 특별히 맞춤화됩니다.
당시 서로 다른 작업에 대해 서로 다른 최적의 모델을 활용하고 ELMo를 추가함으로써,
감정 분석, 자연어 추론, 의미역 결정(semantic role labeling), 상호참조 해결(coreference resolution), 개체명 인식(named entity recognition), 질문 응답 등 6가지 자연어 처리 작업 전반에 걸쳐 최첨단 기술을 향상시켰습니다.</p>
<h2 id="작업별에서-작업-불가지론적으로-from-task-specific-to-task-agnostic"><a class="header" href="#작업별에서-작업-불가지론적으로-from-task-specific-to-task-agnostic">작업별에서 작업 불가지론적으로 (From Task-Specific to Task-Agnostic)</a></h2>
<p>ELMo가 다양한 자연어 처리 작업에 대한 솔루션을 크게 개선했지만,
각 솔루션은 여전히 <em>작업별(task-specific)</em> 아키텍처에 의존합니다.
그러나 모든 자연어 처리 작업에 대해 특정 아키텍처를 만드는 것은 실제로 쉽지 않습니다.
GPT(Generative Pre-Training) 모델은 문맥 의존적 표현을 위한 일반적인 <em>작업 불가지론적(task-agnostic)</em> 모델을 설계하려는 노력을 나타냅니다 :cite:<code>Radford.Narasimhan.Salimans.ea.2018</code>.
트랜스포머 디코더를 기반으로 구축된 GPT는 텍스트 시퀀스를 표현하는 데 사용될 언어 모델을 사전 훈련합니다.
GPT를 다운스트림 작업에 적용할 때, 언어 모델의 출력은 작업의 레이블을 예측하기 위해 추가된 선형 출력 레이어에 공급됩니다.
사전 훈련된 모델의 파라미터를 고정하는 ELMo와 극명하게 대조적으로,
GPT는 다운스트림 작업의 지도 학습 중에 사전 훈련된 트랜스포머 디코더의 <em>모든</em> 파라미터를 미세 조정합니다.
GPT는 자연어 추론, 질문 응답, 문장 유사성 및 분류의 12가지 작업에서 평가되었으며,
모델 아키텍처에 최소한의 변경만으로 그중 9가지 작업에서 최첨단 기술을 개선했습니다.</p>
<p>그러나 언어 모델의 자기 회귀 특성으로 인해,
GPT는 앞만 봅니다(왼쪽에서 오른쪽으로).
"i went to the bank to deposit cash"와 "i went to the bank to sit down"이라는 문맥에서,
"bank"는 그 왼쪽 문맥에 민감하므로,
GPT는 "bank"에 대해 동일한 표현을 반환하지만, 실제로는 다른 의미를 갖습니다.</p>
<h2 id="bert-두-세계의-장점-결합-bert-combining-the-best-of-both-worlds"><a class="header" href="#bert-두-세계의-장점-결합-bert-combining-the-best-of-both-worlds">BERT: 두 세계의 장점 결합 (BERT: Combining the Best of Both Worlds)</a></h2>
<p>우리가 보았듯이,
ELMo는 문맥을 양방향으로 인코딩하지만 작업별 아키텍처를 사용합니다.
반면 GPT는 작업 불가지론적이지만 문맥을 왼쪽에서 오른쪽으로 인코딩합니다.
두 세계의 장점을 결합하여,
BERT(Bidirectional Encoder Representations from Transformers)는
문맥을 양방향으로 인코딩하고 광범위한 자연어 처리 작업에 대해 최소한의 아키텍처 변경만 요구합니다 :cite:<code>Devlin.Chang.Lee.ea.2018</code>.
사전 훈련된 트랜스포머 인코더를 사용하여,
BERT는 양방향 문맥을 기반으로 모든 토큰을 표현할 수 있습니다.
다운스트림 작업의 지도 학습 중에,
BERT는 두 가지 측면에서 GPT와 유사합니다.
첫째, BERT 표현은 추가된 출력 레이어에 공급되며, 모든 토큰에 대해 예측하는 것과 전체 시퀀스에 대해 예측하는 것과 같이 작업의 성격에 따라 모델 아키텍처에 최소한의 변경만 가합니다.
둘째, 사전 훈련된 트랜스포머 인코더의 모든 파라미터가 미세 조정되는 반면, 추가 출력 레이어는 처음부터 훈련됩니다.
:numref:<code>fig_elmo-gpt-bert</code>는 ELMo, GPT, BERT 간의 차이점을 묘사합니다.</p>
<p><img src="../img/elmo-gpt-bert.svg" alt="ELMo, GPT, BERT 비교." />
:label:<code>fig_elmo-gpt-bert</code></p>
<p>BERT는 (i) 단일 텍스트 분류(예: 감정 분석), (ii) 텍스트 쌍 분류(예: 자연어 추론), (iii) 질문 응답, (iv) 텍스트 태깅(예: 개체명 인식)의 광범위한 범주 아래 11가지 자연어 처리 작업에서 최첨단 기술을 더욱 향상시켰습니다.
모두 2018년에 제안된 문맥 의존적 ELMo에서 작업 불가지론적 GPT와 BERT에 이르기까지,
개념적으로 간단하면서도 경험적으로 강력한 자연어에 대한 심층 표현의 사전 훈련은 다양한 자연어 처리 작업에 대한 솔루션에 혁명을 일으켰습니다.</p>
<p>이 장의 나머지 부분에서는 BERT의 사전 훈련에 대해 자세히 알아볼 것입니다.
:numref:<code>chap_nlp_app</code>에서 자연어 처리 응용 프로그램이 설명될 때,
다운스트림 응용 프로그램을 위한 BERT의 미세 조정을 설명할 것입니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
from d2l import mxnet as d2l
from mxnet import gluon, np, npx
from mxnet.gluon import nn

npx.set_np()
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
from d2l import torch as d2l
import torch
from torch import nn
</code></pre>
<h2 id="입력-표현-input-representation"><a class="header" href="#입력-표현-input-representation">[<strong>입력 표현 (Input Representation)</strong>]</a></h2>
<p>:label:<code>subsec_bert_input_rep</code></p>
<p>자연어 처리에서,
어떤 작업(예: 감정 분석)은 단일 텍스트를 입력으로 취하고,
다른 작업(예: 자연어 추론)에서는 입력이 텍스트 시퀀스 쌍입니다.
BERT 입력 시퀀스는 단일 텍스트와 텍스트 쌍을 명확하게 나타냅니다.
전자의 경우,
BERT 입력 시퀀스는
특수 분류 토큰 “&lt;cls&gt;”,
텍스트 시퀀스의 토큰,
그리고 특수 구분 토큰 “&lt;sep&gt;”의 연결입니다.
후자의 경우,
BERT 입력 시퀀스는
“&lt;cls&gt;”, 첫 번째 텍스트 시퀀스의 토큰,
“&lt;sep&gt;”, 두 번째 텍스트 시퀀스의 토큰, 그리고 “&lt;sep&gt;”의 연결입니다.
우리는 "BERT 입력 시퀀스"라는 용어를 다른 유형의 "시퀀스"와 일관되게 구별할 것입니다.
예를 들어, 하나의 <em>BERT 입력 시퀀스</em>는 하나의 <em>텍스트 시퀀스</em> 또는 두 개의 <em>텍스트 시퀀스</em>를 포함할 수 있습니다.</p>
<p>텍스트 쌍을 구별하기 위해,
학습된 세그먼트 임베딩 $\mathbf{e}_A$와 $\mathbf{e}_B$가
각각 첫 번째 시퀀스와 두 번째 시퀀스의 토큰 임베딩에 추가됩니다.
단일 텍스트 입력의 경우 $\mathbf{e}_A$만 사용됩니다.</p>
<p>다음 <code>get_tokens_and_segments</code>는 한 문장 또는 두 문장을 입력으로 받아
BERT 입력 시퀀스의 토큰과 해당 세그먼트 ID를 반환합니다.</p>
<pre><code class="language-{.python .input}">#@tab all
#@save
def get_tokens_and_segments(tokens_a, tokens_b=None):
    """BERT 입력 시퀀스의 토큰과 세그먼트 ID를 가져옵니다."""
    tokens = ['&lt;cls&gt;'] + tokens_a + ['&lt;sep&gt;']
    # 0과 1은 각각 세그먼트 A와 B를 표시합니다
    segments = [0] * (len(tokens_a) + 2)
    if tokens_b is not None:
        tokens += tokens_b + ['&lt;sep&gt;']
        segments += [1] * (len(tokens_b) + 1)
    return tokens, segments
</code></pre>
<p>BERT는 양방향 아키텍처로 트랜스포머 인코더를 선택합니다.
트랜스포머 인코더에서 흔히 그렇듯이,
위치 임베딩이 BERT 입력 시퀀스의 모든 위치에 추가됩니다.
그러나 원래 트랜스포머 인코더와 달리,
BERT는 <em>학습 가능한</em> 위치 임베딩을 사용합니다.
요약하자면, :numref:<code>fig_bert-input</code>은
BERT 입력 시퀀스의 임베딩이
토큰 임베딩, 세그먼트 임베딩, 위치 임베딩의 합임을 보여줍니다.</p>
<p><img src="../img/bert-input.svg" alt="BERT 입력 시퀀스의 임베딩은 토큰 임베딩, 세그먼트 임베딩, 위치 임베딩의 합입니다." />
:label:<code>fig_bert-input</code></p>
<p>다음 [<strong><code>BERTEncoder</code> 클래스</strong>]는 :numref:<code>sec_transformer</code>에서 구현된 <code>TransformerEncoder</code> 클래스와 유사합니다.
<code>TransformerEncoder</code>와 달리, <code>BERTEncoder</code>는
세그먼트 임베딩과 학습 가능한 위치 임베딩을 사용합니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
#@save
class BERTEncoder(nn.Block):
    """BERT 인코더."""
    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,
                 num_blks, dropout, max_len=1000, **kwargs):
        super(BERTEncoder, self).__init__(**kwargs)
        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)
        self.segment_embedding = nn.Embedding(2, num_hiddens)
        self.blks = nn.Sequential()
        for _ in range(num_blks):
            self.blks.add(d2l.TransformerEncoderBlock(
                num_hiddens, ffn_num_hiddens, num_heads, dropout, True))
        # BERT에서 위치 임베딩은 학습 가능하므로, 충분히 긴 위치 임베딩 파라미터를 생성합니다
        self.pos_embedding = self.params.get('pos_embedding',
                                             shape=(1, max_len, num_hiddens))

    def forward(self, tokens, segments, valid_lens):
        # `X`의 모양은 다음 코드 스니펫에서 변경되지 않은 상태로 유지됩니다:
        # (배치 크기, 최대 시퀀스 길이, `num_hiddens`)
        X = self.token_embedding(tokens) + self.segment_embedding(segments)
        X = X + self.pos_embedding.data(ctx=X.ctx)[:, :X.shape[1], :]
        for blk in self.blks:
            X = blk(X, valid_lens)
        return X
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
#@save
class BERTEncoder(nn.Module):
    """BERT 인코더."""
    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,
                 num_blks, dropout, max_len=1000, **kwargs):
        super(BERTEncoder, self).__init__(**kwargs)
        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)
        self.segment_embedding = nn.Embedding(2, num_hiddens)
        self.blks = nn.Sequential()
        for i in range(num_blks):
            self.blks.add_module(f"{i}", d2l.TransformerEncoderBlock(
                num_hiddens, ffn_num_hiddens, num_heads, dropout, True))
        # BERT에서 위치 임베딩은 학습 가능하므로, 충분히 긴 위치 임베딩 파라미터를 생성합니다
        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,
                                                      num_hiddens))

    def forward(self, tokens, segments, valid_lens):
        # `X`의 모양은 다음 코드 스니펫에서 변경되지 않은 상태로 유지됩니다:
        # (배치 크기, 최대 시퀀스 길이, `num_hiddens`)
        X = self.token_embedding(tokens) + self.segment_embedding(segments)
        X = X + self.pos_embedding[:, :X.shape[1], :]
        for blk in self.blks:
            X = blk(X, valid_lens)
        return X
</code></pre>
<p>어휘 크기가 10,000이라고 가정합니다.
[<strong><code>BERTEncoder</code>의 순방향 추론</strong>]을 시연하기 위해,
인스턴스를 생성하고 파라미터를 초기화해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4
num_blks, dropout = 2, 0.2
encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens, num_heads,
                      num_blks, dropout)
encoder.initialize()
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4
ffn_num_input, num_blks, dropout = 768, 2, 0.2
encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens, num_heads,
                      num_blks, dropout)
</code></pre>
<p><code>tokens</code>를 길이 8의 BERT 입력 시퀀스 2개로 정의합니다.
여기서 각 토큰은 어휘의 인덱스입니다.
입력 <code>tokens</code>를 사용한 <code>BERTEncoder</code>의 순방향 추론은
각 토큰이 하이퍼파라미터 <code>num_hiddens</code>에 의해 미리 정의된 길이의 벡터로 표현되는 인코딩된 결과를 반환합니다.
이 하이퍼파라미터는 일반적으로 트랜스포머 인코더의 <em>은닉 크기(hidden size)</em> (은닉 유닛 수)라고 합니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
tokens = np.random.randint(0, vocab_size, (2, 8))
segments = np.array([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])
encoded_X = encoder(tokens, segments, None)
encoded_X.shape
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
tokens = torch.randint(0, vocab_size, (2, 8))
segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])
encoded_X = encoder(tokens, segments, None)
encoded_X.shape
</code></pre>
<h2 id="사전-훈련-작업-pretraining-tasks"><a class="header" href="#사전-훈련-작업-pretraining-tasks">사전 훈련 작업 (Pretraining Tasks)</a></h2>
<p>:label:<code>subsec_bert_pretraining_tasks</code></p>
<p><code>BERTEncoder</code>의 순방향 추론은 입력 텍스트의 각 토큰과 삽입된 특수 토큰 “&lt;cls&gt;” 및 “&lt;seq&gt;”의 BERT 표현을 제공합니다.
다음으로, 우리는 이 표현들을 사용하여 BERT 사전 훈련을 위한 손실 함수를 계산할 것입니다.
사전 훈련은 마스킹된 언어 모델링(masked language modeling)과 다음 문장 예측(next sentence prediction)이라는 두 가지 작업으로 구성됩니다.</p>
<h3 id="마스킹된-언어-모델링-masked-language-modeling"><a class="header" href="#마스킹된-언어-모델링-masked-language-modeling">[<strong>마스킹된 언어 모델링 (Masked Language Modeling)</strong>]</a></h3>
<p>:label:<code>subsec_mlm</code></p>
<p>:numref:<code>sec_language-model</code>에 설명된 대로,
언어 모델은 왼쪽의 문맥을 사용하여 토큰을 예측합니다.
각 토큰을 표현하기 위해 문맥을 양방향으로 인코딩하기 위해,
BERT는 무작위로 토큰을 마스킹하고 양방향 문맥의 토큰을 사용하여
자기 지도 방식으로 마스킹된 토큰을 예측합니다.
이 작업을 *마스킹된 언어 모델(masked language model)*이라고 합니다.</p>
<p>이 사전 훈련 작업에서,
토큰의 15%가 예측을 위한 마스킹된 토큰으로 무작위로 선택됩니다.
레이블을 사용하여 부정행위 없이 마스킹된 토큰을 예측하기 위해,
가장 간단한 접근 방식은 BERT 입력 시퀀스에서 항상 특수 “&lt;mask&gt;” 토큰으로 대체하는 것입니다.
그러나 인공적인 특수 토큰 “&lt;mask&gt;”는 미세 조정 단계에서는 절대 나타나지 않습니다.
사전 훈련과 미세 조정 사이의 이러한 불일치를 피하기 위해,
토큰이 예측을 위해 마스킹되는 경우(예: "this movie is great"에서 "great"이 마스킹되고 예측되도록 선택됨),
입력에서 다음과 같이 대체됩니다:</p>
<ul>
<li>80%의 경우 특수 “&lt;mask&gt;” 토큰으로 대체됩니다(예: "this movie is great"가 "this movie is &lt;mask&gt;"가 됨).</li>
<li>10%의 경우 무작위 토큰으로 대체됩니다(예: "this movie is great"가 "this movie is drink"가 됨).</li>
<li>10%의 경우 변경되지 않은 원래 토큰으로 유지됩니다(예: "this movie is great"가 "this movie is great"가 됨).</li>
</ul>
<p>15% 중 10%의 시간에는 무작위 토큰이 삽입된다는 점에 유의하십시오.
이러한 가끔 발생하는 노이즈는 BERT가 양방향 문맥 인코딩에서 마스킹된 토큰에 덜 편향되도록(특히 레이블 토큰이 변경되지 않은 상태로 유지될 때) 장려합니다.</p>
<p>우리는 BERT 사전 훈련의 마스킹된 언어 모델 작업에서 마스킹된 토큰을 예측하기 위해 다음 <code>MaskLM</code> 클래스를 구현합니다.
예측에는 1개의 은닉층 MLP(<code>self.mlp</code>)가 사용됩니다.
순방향 추론에서, 이는 <code>BERTEncoder</code>의 인코딩된 결과와 예측을 위한 토큰 위치라는 두 가지 입력을 받습니다.
출력은 해당 위치에서의 예측 결과입니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
#@save
class MaskLM(nn.Block):
    """BERT의 마스킹된 언어 모델 작업."""
    def __init__(self, vocab_size, num_hiddens, **kwargs):
        super(MaskLM, self).__init__(**kwargs)
        self.mlp = nn.Sequential()
        self.mlp.add(
            nn.Dense(num_hiddens, flatten=False, activation='relu'))
        self.mlp.add(nn.LayerNorm())
        self.mlp.add(nn.Dense(vocab_size, flatten=False))

    def forward(self, X, pred_positions):
        num_pred_positions = pred_positions.shape[1]
        pred_positions = pred_positions.reshape(-1)
        batch_size = X.shape[0]
        batch_idx = np.arange(0, batch_size)
        # `batch_size` = 2, `num_pred_positions` = 3이라고 가정하면,
        # `batch_idx`는 `np.array([0, 0, 0, 1, 1, 1])`입니다
        batch_idx = np.repeat(batch_idx, num_pred_positions)
        masked_X = X[batch_idx, pred_positions]
        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))
        mlm_Y_hat = self.mlp(masked_X)
        return mlm_Y_hat
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
#@save
class MaskLM(nn.Module):
    """BERT의 마스킹된 언어 모델 작업."""
    def __init__(self, vocab_size, num_hiddens, **kwargs):
        super(MaskLM, self).__init__(**kwargs)
        self.mlp = nn.Sequential(nn.LazyLinear(num_hiddens),
                                 nn.ReLU(),
                                 nn.LayerNorm(num_hiddens),
                                 nn.LazyLinear(vocab_size))

    def forward(self, X, pred_positions):
        num_pred_positions = pred_positions.shape[1]
        pred_positions = pred_positions.reshape(-1)
        batch_size = X.shape[0]
        batch_idx = torch.arange(0, batch_size)
        # `batch_size` = 2, `num_pred_positions` = 3이라고 가정하면,
        # `batch_idx`는 `torch.tensor([0, 0, 0, 1, 1, 1])`입니다
        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)
        masked_X = X[batch_idx, pred_positions]
        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))
        mlm_Y_hat = self.mlp(masked_X)
        return mlm_Y_hat
</code></pre>
<p>[<strong><code>MaskLM</code>의 순방향 추론</strong>]을 보여주기 위해,
인스턴스 <code>mlm</code>을 생성하고 초기화합니다.
<code>BERTEncoder</code>의 순방향 추론에서 나온 <code>encoded_X</code>는 2개의 BERT 입력 시퀀스를 나타냄을 상기하십시오.
<code>mlm_positions</code>를 <code>encoded_X</code>의 BERT 입력 시퀀스 중 하나에서 예측할 3개의 인덱스로 정의합니다.
<code>mlm</code>의 순방향 추론은 <code>encoded_X</code>의 모든 마스킹된 위치 <code>mlm_positions</code>에서의 예측 결과 <code>mlm_Y_hat</code>을 반환합니다.
각 예측에 대해 결과의 크기는 어휘 크기와 같습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
mlm = MaskLM(vocab_size, num_hiddens)
mlm.initialize()
mlm_positions = np.array([[1, 5, 2], [6, 1, 5]])
mlm_Y_hat = mlm(encoded_X, mlm_positions)
mlm_Y_hat.shape
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
mlm = MaskLM(vocab_size, num_hiddens)
mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])
mlm_Y_hat = mlm(encoded_X, mlm_positions)
mlm_Y_hat.shape
</code></pre>
<p>마스크 아래의 예측된 토큰 <code>mlm_Y_hat</code>의 정답 레이블 <code>mlm_Y</code>를 사용하여,
BERT 사전 훈련에서 마스킹된 언어 모델 작업의 크로스 엔트로피 손실을 계산할 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
mlm_Y = np.array([[7, 8, 9], [10, 20, 30]])
loss = gluon.loss.SoftmaxCrossEntropyLoss()
mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))
mlm_l.shape
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
mlm_Y = torch.tensor([[7, 8, 9], [10, 20, 30]])
loss = nn.CrossEntropyLoss(reduction='none')
mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))
mlm_l.shape
</code></pre>
<h3 id="다음-문장-예측-next-sentence-prediction"><a class="header" href="#다음-문장-예측-next-sentence-prediction">[<strong>다음 문장 예측 (Next Sentence Prediction)</strong>]</a></h3>
<p>:label:<code>subsec_nsp</code></p>
<p>마스킹된 언어 모델링은 단어를 표현하기 위해 양방향 문맥을 인코딩할 수 있지만,
텍스트 쌍 간의 논리적 관계를 명시적으로 모델링하지는 않습니다.
두 텍스트 시퀀스 간의 관계를 이해하는 데 도움을 주기 위해,
BERT는 사전 훈련에서 <em>다음 문장 예측</em>이라는 이진 분류 작업을 고려합니다.
사전 훈련을 위한 문장 쌍을 생성할 때,
절반은 실제로 연속된 문장이며 "True" 레이블이 붙고,
나머지 절반은 두 번째 문장이 코퍼스에서 무작위로 샘플링되며 "False" 레이블이 붙습니다.</p>
<p>다음 <code>NextSentencePred</code> 클래스는 1개의 은닉층 MLP를 사용하여
BERT 입력 시퀀스에서 두 번째 문장이 첫 번째 문장의 다음 문장인지 여부를 예측합니다.
트랜스포머 인코더의 셀프 어텐션으로 인해,
특수 토큰 “&lt;cls&gt;”의 BERT 표현은 입력의 두 문장을 모두 인코딩합니다.
따라서 MLP 분류기의 출력 레이어(<code>self.output</code>)는 <code>X</code>를 입력으로 받습니다.
여기서 <code>X</code>는 인코딩된 “&lt;cls&gt;” 토큰을 입력으로 하는 MLP 은닉층의 출력입니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
#@save
class NextSentencePred(nn.Block):
    """BERT의 다음 문장 예측 작업."""
    def __init__(self, **kwargs):
        super(NextSentencePred, self).__init__(**kwargs)
        self.output = nn.Dense(2)

    def forward(self, X):
        # `X` 모양: (배치 크기, `num_hiddens`)
        return self.output(X)
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
#@save
class NextSentencePred(nn.Module):
    """BERT의 다음 문장 예측 작업."""
    def __init__(self, **kwargs):
        super(NextSentencePred, self).__init__(**kwargs)
        self.output = nn.LazyLinear(2)

    def forward(self, X):
        # `X` 모양: (배치 크기, `num_hiddens`)
        return self.output(X)
</code></pre>
<p>우리는 [<strong><code>NextSentencePred</code> 인스턴스의 순방향 추론</strong>]이
각 BERT 입력 시퀀스에 대해 이진 예측을 반환함을 알 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
nsp = NextSentencePred()
nsp.initialize()
nsp_Y_hat = nsp(encoded_X)
nsp_Y_hat.shape
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
# PyTorch는 기본적으로 텐서를 평탄화하지 않지만, mxnet에서는 flatten=True인 경우
# 입력 데이터의 첫 번째 축을 제외한 모든 축이 함께 축소됩니다
encoded_X = torch.flatten(encoded_X, start_dim=1)
# NSP의 input_shape: (배치 크기, `num_hiddens`)
nsp = NextSentencePred()
nsp_Y_hat = nsp(encoded_X)
nsp_Y_hat.shape
</code></pre>
<p>2개의 이진 분류에 대한 크로스 엔트로피 손실도 계산할 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
nsp_y = np.array([0, 1])
nsp_l = loss(nsp_Y_hat, nsp_y)
nsp_l.shape
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
nsp_y = torch.tensor([0, 1])
nsp_l = loss(nsp_Y_hat, nsp_y)
nsp_l.shape
</code></pre>
<p>앞서 언급한 두 사전 훈련 작업의 모든 레이블은
수동 라벨링 노력 없이 사전 훈련 코퍼스에서 사소하게 얻을 수 있다는 점이 주목할 만합니다.
원래 BERT는 BookCorpus :cite:<code>Zhu.Kiros.Zemel.ea.2015</code>와 영문 위키피디아의 연결에 대해 사전 훈련되었습니다.
이 두 텍스트 코퍼스는 거대합니다:
각각 8억 단어와 25억 단어를 가지고 있습니다.</p>
<h2 id="종합하기-putting-it-all-together"><a class="header" href="#종합하기-putting-it-all-together">[<strong>종합하기 (Putting It All Together)</strong>]</a></h2>
<p>BERT를 사전 훈련할 때, 최종 손실 함수는
마스킹된 언어 모델링과 다음 문장 예측에 대한 손실 함수의 선형 결합입니다.
이제 우리는 <code>BERTEncoder</code>, <code>MaskLM</code>, <code>NextSentencePred</code>의 세 가지 클래스를 인스턴스화하여 <code>BERTModel</code> 클래스를 정의할 수 있습니다.
순방향 추론은 인코딩된 BERT 표현 <code>encoded_X</code>,
마스킹된 언어 모델링의 예측 <code>mlm_Y_hat</code>,
그리고 다음 문장 예측 <code>nsp_Y_hat</code>을 반환합니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
#@save
class BERTModel(nn.Block):
    """BERT 모델."""
    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,
                 num_blks, dropout, max_len=1000):
        super(BERTModel, self).__init__()
        self.encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens,
                                   num_heads, num_blks, dropout, max_len)
        self.hidden = nn.Dense(num_hiddens, activation='tanh')
        self.mlm = MaskLM(vocab_size, num_hiddens)
        self.nsp = NextSentencePred()

    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):
        encoded_X = self.encoder(tokens, segments, valid_lens)
        if pred_positions is not None:
            mlm_Y_hat = self.mlm(encoded_X, pred_positions)
        else:
            mlm_Y_hat = None
        # 다음 문장 예측을 위한 MLP 분류기의 은닉층.
        # 0은 '&lt;cls&gt;' 토큰의 인덱스입니다
        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))
        return encoded_X, mlm_Y_hat, nsp_Y_hat
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
#@save
class BERTModel(nn.Module):
    """BERT 모델."""
    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, 
                 num_heads, num_blks, dropout, max_len=1000):
        super(BERTModel, self).__init__()
        self.encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens,
                                   num_heads, num_blks, dropout,
                                   max_len=max_len)
        self.hidden = nn.Sequential(nn.LazyLinear(num_hiddens),
                                    nn.Tanh())
        self.mlm = MaskLM(vocab_size, num_hiddens)
        self.nsp = NextSentencePred()

    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):
        encoded_X = self.encoder(tokens, segments, valid_lens)
        if pred_positions is not None:
            mlm_Y_hat = self.mlm(encoded_X, pred_positions)
        else:
            mlm_Y_hat = None
        # 다음 문장 예측을 위한 MLP 분류기의 은닉층.
        # 0은 '&lt;cls&gt;' 토큰의 인덱스입니다
        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))
        return encoded_X, mlm_Y_hat, nsp_Y_hat
</code></pre>
<h2 id="요약-summary"><a class="header" href="#요약-summary">요약 (Summary)</a></h2>
<ul>
<li>word2vec 및 GloVe와 같은 단어 임베딩 모델은 문맥 독립적입니다. 단어의 문맥에 관계없이(있는 경우) 동일한 단어에 동일한 사전 훈련된 벡터를 할당합니다. 자연어의 다의어나 복잡한 의미론을 잘 처리하기 어렵습니다.</li>
<li>ELMo 및 GPT와 같은 문맥 의존적 단어 표현의 경우, 단어의 표현은 문맥에 따라 달라집니다.</li>
<li>ELMo는 문맥을 양방향으로 인코딩하지만 작업별 아키텍처를 사용합니다(그러나 모든 자연어 처리 작업에 대해 특정 아키텍처를 만드는 것은 실제로 쉽지 않습니다). 반면 GPT는 작업 불가지론적이지만 문맥을 왼쪽에서 오른쪽으로 인코딩합니다.</li>
<li>BERT는 두 세계의 장점을 결합합니다: 문맥을 양방향으로 인코딩하고 광범위한 자연어 처리 작업에 대해 최소한의 아키텍처 변경만 요구합니다.</li>
<li>BERT 입력 시퀀스의 임베딩은 토큰 임베딩, 세그먼트 임베딩, 위치 임베딩의 합입니다.</li>
<li>BERT 사전 훈련은 마스킹된 언어 모델링과 다음 문장 예측이라는 두 가지 작업으로 구성됩니다. 전자는 단어를 표현하기 위해 양방향 문맥을 인코딩할 수 있으며, 후자는 텍스트 쌍 간의 논리적 관계를 명시적으로 모델링합니다.</li>
</ul>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>다른 모든 조건이 동일하다면, 마스킹된 언어 모델은 왼쪽에서 오른쪽으로 진행하는 언어 모델보다 수렴하는 데 더 많은 사전 훈련 단계가 필요합니까 아니면 더 적게 필요합니까? 그 이유는 무엇입니까?</li>
<li>BERT의 원래 구현에서, <code>BERTEncoder</code>의 포지션와이즈 피드 포워드 네트워크(<code>d2l.TransformerEncoderBlock</code>를 통해)와 <code>MaskLM</code>의 완전 연결 레이어는 모두 활성화 함수로 GELU(Gaussian error linear unit) :cite:<code>Hendrycks.Gimpel.2016</code>를 사용합니다. GELU와 ReLU의 차이점을 조사하십시오.</li>
</ol>
<p>:begin_tab:<code>mxnet</code>
<a href="https://discuss.d2l.ai/t/388">Discussions</a>
:end_tab:</p>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/1490">Discussions</a>
:end_tab:</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_natural-language-processing-pretraining/bert-dataset.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_natural-language-processing-pretraining/bert-dataset.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
