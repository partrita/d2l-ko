<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>선형 회귀 (Linear Regression) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../chapter_linear-regression/linear-regression.html" class="active"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <pre><code class="language-{.python .input}">%load_ext d2lbook.tab
tab.interact_select(['mxnet', 'pytorch', 'tensorflow', 'jax'])
</code></pre>
<h1 id="선형-회귀-linear-regression"><a class="header" href="#선형-회귀-linear-regression">선형 회귀 (Linear Regression)</a></h1>
<p>:label:<code>sec_linear_regression</code></p>
<p><em>회귀(Regression)</em> 문제는 수치 값을 예측하고 싶을 때마다 나타납니다.
일반적인 예로는 주택, 주식 등의 가격 예측, 병원 환자의 입원 기간 예측, 소매 판매 수요 예측 등이 있습니다.
모든 예측 문제가 고전적인 회귀 문제는 아닙니다.
나중에 목표가 여러 범주 중 멤버십을 예측하는 것인 분류 문제를 소개할 것입니다.</p>
<p>실행 예제로, 주택의 면적(제곱피트)과 연식(년)을 기반으로 주택 가격(달러)을 추정하고 싶다고 가정해 봅시다.
주택 가격을 예측하는 모델을 개발하려면 각 주택의 판매 가격, 면적, 연식을 포함한 데이터를 확보해야 합니다.
머신러닝 용어에서 이 데이터셋을 <em>훈련 데이터셋(training dataset)</em> 또는 *훈련 세트(training set)*라고 하며,
각 행(한 번의 판매에 해당하는 데이터를 포함)을 <em>예제(example)</em> (또는 <em>데이터 포인트(data point)</em>, <em>인스턴스(instance)</em>, <em>샘플(sample)</em>)라고 합니다.
우리가 예측하려는 것(가격)을 <em>레이블(label)</em> (또는 <em>타겟(target)</em>)이라고 합니다.
예측의 기반이 되는 변수(연식 및 면적)를 <em>특성(features)</em> (또는 <em>공변량(covariates)</em>)이라고 합니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
%matplotlib inline
from d2l import mxnet as d2l
import math
from mxnet import np
import time
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
%matplotlib inline
from d2l import torch as d2l
import math
import torch
import numpy as np
import time
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
%matplotlib inline
from d2l import tensorflow as d2l
import math
import tensorflow as tf
import numpy as np
import time
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
%matplotlib inline
from d2l import jax as d2l
from jax import numpy as jnp
import math
import time
</code></pre>
<h2 id="기초-basics"><a class="header" href="#기초-basics">기초 (Basics)</a></h2>
<p>*선형 회귀(Linear regression)*는 회귀 문제를 다루기 위한 표준 도구 중 가장 단순하면서도 가장 인기가 있습니다.
19세기 초로 거슬러 올라가는 :cite:<code>Legendre.1805,Gauss.1809</code> 선형 회귀는 몇 가지 간단한 가정에서 출발합니다.
첫째, 우리는 특성 $\mathbf{x}$와 타겟 $y$ 사이의 관계가 대략 선형이라고 가정합니다.
즉, 조건부 평균 $E[Y \mid X=\mathbf{x}]$가 특성 $\mathbf{x}$의 가중 합으로 표현될 수 있다는 것입니다.
이 설정은 관찰 노이즈 때문에 타겟 값이 예상 값에서 여전히 벗어날 수 있음을 허용합니다.
다음으로, 우리는 그러한 노이즈가 가우스 분포를 따르며 잘 작동한다고 가정을 부여할 수 있습니다.
일반적으로 우리는 데이터셋의 예제 수를 나타내기 위해 $n$을 사용합니다.
샘플과 타겟을 열거하기 위해 위첨자를 사용하고, 좌표를 인덱싱하기 위해 아래첨자를 사용합니다.
더 구체적으로, $\mathbf{x}^{(i)}$는 $i^{\textrm{th}}$ 샘플을 나타내고 $x_j^{(i)}$는 그 $j^{\textrm{th}}$ 좌표를 나타냅니다.</p>
<h3 id="모델-model"><a class="header" href="#모델-model">모델 (Model)</a></h3>
<p>:label:<code>subsec_linear_model</code></p>
<p>모든 솔루션의 핵심은 특성을 타겟의 추정치로 변환하는 방법을 설명하는 모델입니다.
선형성 가정은 타겟(가격)의 예상 값이 특성(면적 및 연식)의 가중 합으로 표현될 수 있음을 의미합니다:</p>
<p>$$\textrm{가격} = w_{\textrm{area}} \cdot \textrm{면적} + w_{\textrm{age}} \cdot \textrm{연식} + b.$$
:eqlabel:<code>eq_price-area</code></p>
<p>여기서 $w_{\textrm{area}}$와 $w_{\textrm{age}}$는 *가중치(weights)*라고 불리고, $b$는 <em>편향(bias)</em> (또는 <em>오프셋</em> 또는 <em>절편</em>)이라고 불립니다.
가중치는 각 특성이 우리의 예측에 미치는 영향을 결정합니다.
편향은 모든 특성이 0일 때의 추정치 값을 결정합니다.
면적이 정확히 0인 신축 주택은 결코 볼 수 없겠지만, (원점을 지나는 직선으로 제한하기보다) 우리 특성의 모든 선형 함수를 표현할 수 있게 해주기 때문에 여전히 편향이 필요합니다.
엄밀히 말하면, :eqref:<code>eq_price-area</code>는 입력 특성의 *아핀 변환(affine transformation)*으로, 가중 합을 통한 특성의 <em>선형 변환</em>과 추가된 편향을 통한 *평행 이동(translation)*이 결합된 특징이 있습니다.
데이터셋이 주어졌을 때, 우리의 목표는 평균적으로 모델의 예측이 데이터에서 관찰된 실제 가격과 가능한 한 밀접하게 일치하도록 하는 가중치 $\mathbf{w}$와 편향 $b$를 선택하는 것입니다.</p>
<p>단 몇 가지 특성만 있는 데이터셋에 집중하는 것이 일반적인 학문 분야에서는 :eqref:<code>eq_price-area</code>와 같이 모델을 긴 형식으로 명시적으로 표현하는 것이 일반적입니다.
머신러닝에서는 보통 고차원 데이터셋으로 작업하며, 이때는 간결한 선형 대수 표기법을 사용하는 것이 더 편리합니다.
입력이 $d$개의 특성으로 구성될 때, 각 특성에 (1에서 $d$ 사이의) 인덱스를 할당하고 우리의 예측 $\hat{y}$ (일반적으로 "햇(hat)" 기호는 추정치를 나타냄)를 다음과 같이 표현할 수 있습니다.</p>
<p>$$\hat{y} = w_1  x_1 + \cdots + w_d  x_d + b.$$</p>
<p>모든 특성을 벡터 $\mathbf{x} \in \mathbb{R}^d$로, 모든 가중치를 벡터 $\mathbf{w} \in \mathbb{R}^d$로 모으면, $\mathbf{w}$와 $\mathbf{x}$ 사이의 내적을 통해 우리 모델을 간결하게 표현할 수 있습니다:</p>
<p>$$\hat{y} = \mathbf{w}^\top \mathbf{x} + b.$$
:eqlabel:<code>eq_linreg-y</code></p>
<p>:eqref:<code>eq_linreg-y</code>에서 벡터 $\mathbf{x}$는 단일 예제의 특성에 해당합니다.
우리는 $n$개 예제로 구성된 전체 데이터셋의 특성을 <em>설계 행렬(design matrix)</em> $\mathbf{X} \in \mathbb{R}^{n \times d}$를 통해 참조하는 것이 편리할 때가 많습니다.
여기서 $\mathbf{X}$는 모든 예제에 대해 하나의 행을, 모든 특성에 대해 하나의 열을 포함합니다.
특성 모음 $\mathbf{X}$에 대해, 예측 $\hat{\mathbf{y}} \in \mathbb{R}^n$은 행렬-벡터 곱을 통해 표현될 수 있습니다:</p>
<p>$${\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b,$$
:eqlabel:<code>eq_linreg-y-vec</code></p>
<p>여기서 합산 중에 브로드캐스팅(:numref:<code>subsec_broadcasting</code>)이 적용됩니다.
훈련 데이터셋 $\mathbf{X}$의 특성과 해당 (알려진) 레이블 $\mathbf{y}$가 주어졌을 때, 선형 회귀의 목표는 $\mathbf{X}$와 동일한 분포에서 샘플링된 새로운 데이터 예제의 특성이 주어졌을 때, 새로운 예제의 레이블이 (기대치에서) 가장 작은 오차로 예측되도록 가중치 벡터 $\mathbf{w}$와 편향 항 $b$를 찾는 것입니다.</p>
<p>$\mathbf{x}$가 주어졌을 때 $y$를 예측하기 위한 최선의 모델이 선형이라고 믿더라도, 모든 $1 \leq i \leq n$에 대해 $y^{(i)}$가 $\mathbf{w}^\top \mathbf{x}^{(i)}+b$와 정확히 일치하는 $n$개 예제의 실제 데이터셋을 찾을 것으로 기대하지는 않습니다.
예를 들어, 특성 $\mathbf{X}$와 레이블 $\mathbf{y}$를 관찰하기 위해 어떤 도구를 사용하든 소량의 측정 오차가 있을 수 있습니다.
따라서 기본 관계가 선형이라고 확신하더라도 그러한 오차를 설명하기 위해 노이즈 항을 통합할 것입니다.</p>
<p>최상의 <em>파라미터</em> (또는 <em>모델 파라미터</em>) $\mathbf{w}$와 $b$를 탐색하기 전에, 두 가지가 더 필요합니다:
(i) 주어진 모델의 품질에 대한 척도;
그리고 (ii) 품질을 개선하기 위해 모델을 업데이트하는 절차.</p>
<h3 id="손실-함수-loss-function"><a class="header" href="#손실-함수-loss-function">손실 함수 (Loss Function)</a></h3>
<p>:label:<code>subsec_linear-regression-loss-function</code></p>
<p>당연하게도 모델을 데이터에 맞추려면 <em>적합성(fitness)</em> (또는 동등하게 <em>부적합성</em>)에 대한 어떤 척도에 합의해야 합니다.
*손실 함수(Loss functions)*는 타겟의 <em>실제</em> 값과 <em>예측</em> 값 사이의 거리를 정량화합니다.
손실은 일반적으로 값이 작을수록 더 좋고 완벽한 예측은 0의 손실을 입는 음이 아닌 숫자입니다.
회귀 문제에서 가장 일반적인 손실 함수는 제곱 오차(squared error)입니다.
예제 $i$에 대한 우리의 예측이 $\hat{y}^{(i)}$이고 해당 실제 레이블이 $y^{(i)}$일 때, <em>제곱 오차</em>는 다음과 같이 주어집니다:</p>
<p>$$l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2.$$
:eqlabel:<code>eq_mse</code></p>
<p>상수 $\frac{1}{2}$은 실제적인 차이를 만들지 않지만, 손실의 도함수를 취할 때 상쇄되기 때문에 표기법상 편리한 것으로 밝혀졌습니다.
훈련 데이터셋은 우리에게 주어지며 우리의 통제 밖이기 때문에, 경험적 오차는 모델 파라미터의 함수일 뿐입니다.
:numref:<code>fig_fit_linreg</code>에서는 1차원 입력 문제에서 선형 회귀 모델의 적합도를 시각화합니다.</p>
<p><img src="../img/fit-linreg.svg" alt="1차원 데이터에 선형 회귀 모델 맞추기." />
:label:<code>fig_fit_linreg</code></p>
<p>추정치 $\hat{y}^{(i)}$와 타겟 $y^{(i)}$ 사이의 큰 차이는 이차 형식(quadratic form)으로 인해 손실에 훨씬 더 큰 기여를 한다는 점에 유의하십시오.
(이 이차성은 양날의 검이 될 수 있습니다. 모델이 큰 오차를 피하도록 장려하는 반면, 비정상적인 데이터에 과도하게 민감해질 수도 있습니다.)
$n$개 예제로 구성된 전체 데이터셋에서 모델의 품질을 측정하기 위해, 우리는 단순히 훈련 세트에서의 손실을 평균(또는 동등하게 합산)합니다:</p>
<p>$$L(\mathbf{w}, b) =\frac{1}{n}\sum_{i=1}^n l^{(i)}(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2.$$</p>
<p>모델을 훈련할 때, 우리는 모든 훈련 예제에 걸쳐 총 손실을 최소화하는 파라미터($\mathbf{w}^<em>, b^</em>$)를 찾습니다:</p>
<p>$$\mathbf{w}^<em>, b^</em> = \operatorname*{argmin}_{\mathbf{w}, b}\  L(\mathbf{w}, b).$$$</p>
<h3 id="해석적-해-analytic-solution"><a class="header" href="#해석적-해-analytic-solution">해석적 해 (Analytic Solution)</a></h3>
<p>우리가 다룰 대부분의 모델과 달리, 선형 회귀는 놀라울 정도로 쉬운 최적화 문제를 제시합니다.
특히, 다음과 같이 간단한 공식을 적용하여 (훈련 데이터에서 평가된) 최적의 파라미터를 해석적으로 찾을 수 있습니다.
먼저, 모두 1로 구성된 열을 설계 행렬에 추가하여 편향 $b$를 파라미터 $\mathbf{w}$에 포함시킬 수 있습니다.
그러면 우리의 예측 문제는 $|\mathbf{y} - \mathbf{X}\mathbf{w}|^2$를 최소화하는 것이 됩니다.
설계 행렬 $\mathbf{X}$가 풀 랭크(full rank)인 한 (어떤 특성도 다른 특성에 선형적으로 종속되지 않음), 손실 표면에는 임계점이 단 하나만 존재하며 이는 전체 도메인에서의 손실 최소값에 해당합니다.
$\mathbf{w}$에 대해 손실의 도함수를 취하고 0으로 설정하면 다음을 얻습니다:</p>
<p>$$\begin{aligned}
\partial_{\mathbf{w}} |\mathbf{y} - \mathbf{X}\mathbf{w}|^2 =
2 \mathbf{X}^\top (\mathbf{X} \mathbf{w} - \mathbf{y}) = 0
\textrm{ 이고 따라서 }
\mathbf{X}^\top \mathbf{y} = \mathbf{X}^\top \mathbf{X} \mathbf{w}.
\end{aligned}$$</p>
<p>$\mathbf{w}$에 대해 풀면 최적화 문제에 대한 최적의 해를 얻을 수 있습니다.
이 해</p>
<p>$$\mathbf{w}^* = (\mathbf X^\top \mathbf X)^{-1}\mathbf X^\top \mathbf{y}$$</p>
<p>는 행렬 $\mathbf X^\top \mathbf X$가 가역적일 때, 즉 설계 행렬의 열이 선형 독립일 때만 유일할 것입니다 :cite:<code>Golub.Van-Loan.1996</code>.</p>
<p>선형 회귀와 같은 단순한 문제는 해석적 해를 허용할 수 있지만, 그러한 행운에 익숙해져서는 안 됩니다.
해석적 해는 멋진 수학적 분석을 가능하게 하지만, 해석적 해의 요구 사항은 너무 제한적이어서 딥러닝의 거의 모든 흥미로운 측면을 제외하게 될 것입니다.</p>
<h3 id="미니배치-확률적-경사-하강법-minibatch-stochastic-gradient-descent"><a class="header" href="#미니배치-확률적-경사-하강법-minibatch-stochastic-gradient-descent">미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></h3>
<p>다행히도 모델을 해석적으로 풀 수 없는 경우에도 실제로는 모델을 효과적으로 훈련할 수 있는 경우가 많습니다.
게다가 많은 작업에서 최적화하기 어려운 모델들이 훨씬 더 뛰어나다는 것이 밝혀져서, 그것들을 어떻게 훈련할지 알아내는 것은 충분히 수고할 가치가 있게 됩니다.</p>
<p>거의 모든 딥러닝 모델을 최적화하는 핵심 기술이자 이 책 전체에서 계속해서 호출할 기술은, 손실 함수를 점진적으로 낮추는 방향으로 파라미터를 업데이트하여 오차를 반복적으로 줄이는 것입니다.
이 알고리즘을 *경사 하강법(gradient descent)*이라고 합니다.</p>
<p>경사 하강법의 가장 순진한 적용은 데이터셋의 모든 단일 예제에서 계산된 손실의 평균인 손실 함수의 도함수를 취하는 것입니다.
실제로 이는 매우 느릴 수 있습니다. 업데이트 단계가 매우 강력하더라도 단일 업데이트를 수행하기 전에 전체 데이터셋을 거쳐야 하기 때문입니다 :cite:<code>Liu.Nocedal.1989</code>.
설상가상으로 훈련 데이터에 중복이 많으면 전체 업데이트의 이점이 제한적입니다.</p>
<p>다른 극단은 한 번에 하나의 예제만 고려하고 한 번에 하나의 관찰을 기반으로 업데이트 단계를 밟는 것입니다.
결과 알고리즘인 <em>확률적 경사 하강법</em>(Stochastic Gradient Descent, SGD)은 대규모 데이터셋에 대해서도 효과적인 전략이 될 수 있습니다 :cite:<code>Bottou.2010</code>.
불행히도 SGD는 계산적 및 통계적으로 모두 단점이 있습니다.
한 가지 문제는 프로세서가 메인 메모리에서 프로세서 캐시로 데이터를 이동하는 것보다 숫자를 곱하고 더하는 속도가 훨씬 빠르다는 사실에서 발생합니다.
행렬-벡터 곱셈을 수행하는 것이 그에 상응하는 수의 벡터-벡터 연산을 수행하는 것보다 최대 한 자릿수 더 효율적입니다.
이는 전체 배치에 비해 한 번에 한 샘플을 처리하는 데 훨씬 더 오랜 시간이 걸릴 수 있음을 의미합니다.
두 번째 문제는 배치 정규화(batch normalization, :numref:<code>sec_batch_norm</code>에서 설명)와 같은 일부 레이어는 한 번에 두 개 이상의 관찰에 액세스할 수 있을 때만 잘 작동한다는 것입니다.</p>
<p>두 문제에 대한 해결책은 중간 전략을 선택하는 것입니다. 전체 배치나 단일 샘플만 취하는 대신, 관찰의 <em>미니배치</em>를 취하는 것입니다 :cite:<code>Li.Zhang.Chen.ea.2014</code>.
해당 미니배치 크기의 구체적인 선택은 메모리 양, 가속기 수, 레이어 선택, 총 데이터셋 크기 등 많은 요소에 달려 있습니다.
그럼에도 불구하고 32에서 256 사이, 가급적이면 2의 거듭제곱 배수가 좋은 시작입니다.
이것은 우리를 <em>미니배치 확률적 경사 하강법</em>으로 인도합니다.</p>
<p>가장 기본적인 형태에서, 각 반복 $t$마다 먼저 고정된 수 $|\mathcal{B}|$의 훈련 예제로 구성된 미니배치 $\mathcal{B}_t$를 무작위로 샘플링합니다.
그런 다음 모델 파라미터에 대한 미니배치의 평균 손실의 도함수(기울기)를 계산합니다.
마지막으로 기울기에 *학습률(learning rate)*이라 불리는 미리 정해진 작은 양수 값 $\eta$를 곱하고, 현재 파라미터 값에서 결과 항을 뺍니다.
업데이트를 다음과 같이 표현할 수 있습니다:</p>
<p>$$(\mathbf{w},b) \leftarrow (\mathbf{w},b) - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}<em>t} \partial</em>{(\mathbf{w},b)} l^{(i)}(\mathbf{w},b).$$$</p>
<p>요약하자면, 미니배치 SGD는 다음과 같이 진행됩니다:
(i) 모델 파라미터의 값을 초기화합니다(일반적으로 무작위로);
(ii) 데이터에서 무작위 미니배치를 반복적으로 샘플링하여 음의 기울기 방향으로 파라미터를 업데이트합니다.
이차 손실과 아핀 변환의 경우, 이는 닫힌 형식(closed-form) 확장을 갖습니다:</p>
<p>$$\begin{aligned} \mathbf{w} &amp; \leftarrow \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}<em>t} \partial</em>{\mathbf{w}} l^{(i)}(\mathbf{w}, b) &amp;&amp; = \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}<em>t} \mathbf{x}^{(i)} (\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)})\ b &amp;\leftarrow b -  \frac{\eta}{|\mathcal{B}|} \sum</em>{i \in \mathcal{B}<em>t} \partial_b l^{(i)}(\mathbf{w}, b) &amp;&amp;  = b - \frac{\eta}{|\mathcal{B}|} \sum</em>{i \in \mathcal{B}_t} (\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}). \end{aligned}$$
:eqlabel:<code>eq_linreg_batch_update</code></p>
<p>미니배치 $\mathcal{B}$를 선택하므로 그 크기 $|\mathcal{B}|$로 정규화해야 합니다.
종종 미니배치 크기와 학습률은 사용자가 정의합니다.
훈련 루프에서 업데이트되지 않는 이러한 조정 가능한 파라미터를 *하이퍼파라미터(hyperparameters)*라고 합니다.
베이지안 최적화 :cite:<code>Frazier.2018</code>와 같은 여러 기술을 통해 자동으로 튜닝될 수 있습니다.
결국 솔루션의 품질은 일반적으로 별도의 <em>검증 데이터셋(validation dataset)</em> (또는 <em>검증 세트</em>)에서 평가됩니다.</p>
<p>미리 정해진 반복 횟수 동안 (또는 다른 중지 기준이 충족될 때까지) 훈련한 후, $\hat{\mathbf{w}}, \hat{b}$로 표시되는 추정된 모델 파라미터를 기록합니다.
우리의 함수가 진정으로 선형이고 노이즈가 없더라도, 이러한 파라미터는 손실의 정확한 최소값이 아니며 심지어 결정론적이지도 않을 것임에 유의하십시오.
알고리즘이 최소값을 향해 천천히 수렴하지만 유한한 단계 내에서 정확하게 찾지는 못할 것이기 때문입니다.
게다가 파라미터를 업데이트하는 데 사용되는 미니배치 $\mathcal{B}$는 무작위로 선택됩니다.
이것은 결정론을 깨뜨립니다.</p>
<p>선형 회귀는 전역 최소값이 있는 학습 문제입니다
($\mathbf{X}$가 풀 랭크일 때마다, 또는 동등하게 $\mathbf{X}^\top \mathbf{X}$가 가역적일 때마다).
그러나 심층 네트워크의 손실 표면에는 많은 안장점과 최소값이 포함되어 있습니다.
다행히도 우리는 일반적으로 정확한 파라미터 세트를 찾는 데 관심이 있는 것이 아니라, 정확한 예측(따라서 낮은 손실)으로 이어지는 파라미터 세트만 찾으면 됩니다.
실제로 딥러닝 실무자들은 <em>훈련 세트에서</em> 손실을 최소화하는 파라미터를 찾는 데 거의 어려움을 겪지 않습니다 :cite:<code>Izmailov.Podoprikhin.Garipov.ea.2018,Frankle.Carbin.2018</code>.
더 어려운 과제는 이전에 본 적 없는 데이터에서 정확한 예측으로 이어지는 파라미터를 찾는 것이며, 이 도전을 *일반화(generalization)*라고 합니다.
우리는 책 전반에 걸쳐 이러한 주제로 돌아올 것입니다.</p>
<h3 id="예측-predictions"><a class="header" href="#예측-predictions">예측 (Predictions)</a></h3>
<p>모델 $\hat{\mathbf{w}}^\top \mathbf{x} + \hat{b}$가 주어지면, 이제 새로운 예제에 대해 <em>예측</em>을 할 수 있습니다.
예를 들어, 면적 $x_1$과 연식 $x_2$가 주어졌을 때 이전에 본 적 없는 주택의 판매 가격을 예측하는 것입니다.
딥러닝 실무자들은 예측 단계를 *추론(inference)*이라고 부르곤 하지만, 이는 약간 잘못된 명칭입니다.
<em>추론</em>은 파라미터의 값과 보지 못한 인스턴스에 대한 가능성 있는 레이블을 모두 포함하여 증거를 바탕으로 도달한 모든 결론을 광범위하게 지칭하기 때문입니다.
통계 문헌에서 <em>추론</em>은 파라미터 추론을 더 자주 의미하며, 이러한 용어의 중복 사용은 딥러닝 실무자들이 통계학자들과 대화할 때 불필요한 혼란을 야기합니다.
다음에서는 가능한 한 *예측(prediction)*을 고수할 것입니다.</p>
<h2 id="속도를-위한-벡터화-vectorization-for-speed"><a class="header" href="#속도를-위한-벡터화-vectorization-for-speed">속도를 위한 벡터화 (Vectorization for Speed)</a></h2>
<p>모델을 훈련할 때, 우리는 일반적으로 예제의 전체 미니배치를 동시에 처리하기를 원합니다.
이를 효율적으로 수행하려면 (<strong>Python에서 비용이 많이 드는 for-루프를 작성하기보다 계산을 벡터화하고 빠른 선형 대수 라이브러리를 활용해야 합니다.</strong>)</p>
<p>이것이 왜 그렇게 중요한지 알아보기 위해, (<strong>벡터를 더하는 두 가지 방법을 고려해 봅시다.</strong>)
시작하기 위해 모두 1을 포함하는 10,000차원 벡터 두 개를 인스턴스화합니다.
첫 번째 방법에서는 Python for-루프로 벡터를 반복합니다.
두 번째 방법에서는 <code>+</code>에 대한 단일 호출에 의존합니다.</p>
<pre><code class="language-{.python .input}">%%tab all
n = 10000
a = d2l.ones(n)
b = d2l.ones(n)
</code></pre>
<p>이제 작업 부하를 벤치마킹할 수 있습니다.
먼저, [<strong>for-루프를 사용하여 한 번에 한 좌표씩 더합니다.</strong>]</p>
<pre><code class="language-{.python .input}">%%tab mxnet, pytorch
c = d2l.zeros(n)
t = time.time()
for i in range(n):
    c[i] = a[i] + b[i]
f'{time.time() - t:.5f} sec'
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
c = tf.Variable(d2l.zeros(n))
t = time.time()
for i in range(n):
    c[i].assign(a[i] + b[i])
f'{time.time() - t:.5f} sec'
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
# JAX 배열은 불변이므로 한 번 생성되면 내용을 변경할 수 없습니다. 
# 개별 요소를 업데이트하기 위해 JAX는 업데이트된 사본을 반환하는 
# 인덱싱된 업데이트 구문을 제공합니다.
c = d2l.zeros(n)
t = time.time()
for i in range(n):
    c = c.at[i].set(a[i] + b[i])
f'{time.time() - t:.5f} sec'
</code></pre>
<p>(<strong>대안으로, 재정의된 <code>+</code> 연산자에 의존하여 요소별 합계를 계산합니다.</strong>)</p>
<pre><code class="language-{.python .input}">%%tab all
t = time.time()
d = a + b
f'{time.time() - t:.5f} sec'
</code></pre>
<p>두 번째 방법이 첫 번째 방법보다 획기적으로 빠릅니다.
코드를 벡터화하면 종종 수십 배의 속도 향상을 얻을 수 있습니다.
게다가 우리는 수학의 더 많은 부분을 라이브러리에 밀어 넣어 스스로 많은 계산을 작성할 필요가 없게 함으로써, 오차 가능성을 줄이고 코드의 이식성을 높입니다.</p>
<h2 id="정규-분포와-제곱-손실-the-normal-distribution-and-squared-loss"><a class="header" href="#정규-분포와-제곱-손실-the-normal-distribution-and-squared-loss">정규 분포와 제곱 손실 (The Normal Distribution and Squared Loss)</a></h2>
<p>:label:<code>subsec_normal_distribution_and_squared_loss</code></p>
<p>지금까지 우리는 제곱 손실 목적 함수에 대해 상당히 기능적인 동기를 부여했습니다:
기본 패턴이 진정으로 선형일 때마다 최적의 파라미터는 조건부 기대치 $E[Y\mid X]$를 반환하며, 손실은 이상값에 대해 큰 페널티를 할당한다는 것입니다.
우리는 또한 노이즈 분포에 대한 확률적 가정을 함으로써 제곱 손실 목적 함수에 대해 더 공식적인 동기를 제공할 수 있습니다.</p>
<p>선형 회귀는 19세기 전환기에 발명되었습니다.
가우스(Gauss)나 르장드르(Legendre) 중 누가 먼저 아이디어를 냈는지에 대해서는 오랫동안 논쟁이 있어 왔지만, 정규 분포(<em>가우시안</em>이라고도 함)를 발견한 것도 가우스였습니다.
정규 분포와 제곱 손실을 사용한 선형 회귀는 공통 조상 이상의 깊은 연결을 공유하는 것으로 밝혀졌습니다.</p>
<p>시작하기 위해, 평균이 $\mu$이고 분산이 $\sigma^2$ (표준 편차 $\sigma$)인 정규 분포가 다음과 같이 주어진다는 것을 상기하십시오.</p>
<p>$$p(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{1}{2 \sigma^2} (x - \mu)^2\right).$$$</p>
<p>아래에서 [<strong>정규 분포를 계산하는 함수를 정의합니다</strong>].</p>
<pre><code class="language-{.python .input}">%%tab all
def normal(x, mu, sigma):
    p = 1 / math.sqrt(2 * math.pi * sigma**2)
    if tab.selected('jax'):
        return p * jnp.exp(-0.5 * (x - mu)**2 / sigma**2)
    if tab.selected('pytorch', 'mxnet', 'tensorflow'):
        return p * np.exp(-0.5 * (x - mu)**2 / sigma**2)
</code></pre>
<p>이제 (<strong>정규 분포를 시각화</strong>)할 수 있습니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
# 시각화를 위해 NumPy 다시 사용
x = np.arange(-7, 7, 0.01)

# 평균 및 표준 편차 쌍
params = [(0, 1), (0, 2), (3, 1)]
d2l.plot(x.asnumpy(), [normal(x, mu, sigma).asnumpy() for mu, sigma in params], xlabel='x',
         ylabel='p(x)', figsize=(4.5, 2.5),
         legend=[f'mean {mu}, std {sigma}' for mu, sigma in params])
</code></pre>
<pre><code class="language-{.python .input}">
%%tab pytorch, tensorflow, jax
if tab.selected('jax'):
    # 시각화를 위해 JAX NumPy 사용
    x = jnp.arange(-7, 7, 0.01)
if tab.selected('pytorch', 'mxnet', 'tensorflow'):
    # 시각화를 위해 NumPy 다시 사용
    x = np.arange(-7, 7, 0.01)

# 평균 및 표준 편차 쌍
params = [(0, 1), (0, 2), (3, 1)]
d2l.plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel='x',
         ylabel='p(x)', figsize=(4.5, 2.5),
         legend=[f'mean {mu}, std {sigma}' for mu, sigma in params])
</code></pre>
<p>평균을 변경하면 $x$축을 따라 이동하고, 분산을 늘리면 분포가 퍼져서 정점이 낮아진다는 점에 유의하십시오.</p>
<p>제곱 손실을 사용한 선형 회귀에 동기를 부여하는 한 가지 방법은 관찰이 노이즈가 섞인 측정값에서 발생한다고 가정하는 것입니다. 여기서 노이즈 $\epsilon$은 정규 분포 $\mathcal{N}(0, \sigma^2)$를 따릅니다:</p>
<p>$$y = \mathbf{w}^\top \mathbf{x} + b + \epsilon \textrm{ 여기서 } \epsilon \sim \mathcal{N}(0, \sigma^2).$$$</p>
<p>따라서 주어진 $\mathbf{x}$에 대해 특정 $y$를 볼 *우도(likelihood)*를 다음과 같이 작성할 수 있습니다.</p>
<p>$$P(y \mid \mathbf{x}) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{1}{2 \sigma^2} (y - \mathbf{w}^\top \mathbf{x} - b)^2\right).$$$</p>
<p>이와 같이 우도는 인수 분해됩니다. *최대 우도 원칙(principle of maximum likelihood)*에 따라, 파라미터 $\mathbf{w}$와 $b$의 최적 값은 전체 데이터셋의 <em>우도</em>를 최대화하는 값입니다:</p>
<p>$$P(\mathbf y \mid \mathbf X) = \prod_{i=1}^{n} p(y^{(i)} \mid \mathbf{x}^{(i)}).$$$</p>
<p>모든 쌍 $(\mathbf{x}^{(i)}, y^{(i)})$이 서로 독립적으로 추출되었으므로 등식이 성립합니다.
최대 우도 원칙에 따라 선택된 추정량을 *최대 우도 추정량(maximum likelihood estimators)*이라고 합니다.
많은 지수 함수의 곱을 최대화하는 것이 어려워 보일 수 있지만, 목적 함수를 바꾸지 않고 대신 우도의 로그를 최대화함으로써 상황을 크게 단순화할 수 있습니다.
역사적인 이유로 최적화는 최대화보다 최소화로 더 자주 표현됩니다.
따라서 아무것도 바꾸지 않고 *음의 로그 우도(negative log-likelihood)*를 <em>최소화</em>할 수 있으며, 이를 다음과 같이 표현할 수 있습니다:</p>
<p>$$- \log P(\mathbf y \mid \mathbf X) = \sum_{i=1}^n \frac{1}{2} \log(2 \pi \sigma^2) + \frac{1}{2 \sigma^2} \left(y^{(i)} - \mathbf{w}^\top \mathbf{x}^{(i)} - b\right)^2.$$</p>
<p>$\sigma$가 고정되어 있다고 가정하면 첫 번째 항은 $\mathbf{w}$나 $b$에 의존하지 않으므로 무시할 수 있습니다.
두 번째 항은 곱셈 상수 $\frac{1}{\sigma^2}$를 제외하고 앞서 소개한 제곱 오차 손실과 동일합니다.
다행히도 해는 $\sigma$에도 의존하지 않습니다.
따라서 평균 제곱 오차를 최소화하는 것은 가산 가우스 노이즈 가정 하에서 선형 모델의 최대 우도 추정과 동일하다는 결론이 나옵니다.</p>
<h2 id="신경망으로서의-선형-회귀-linear-regression-as-a-neural-network"><a class="header" href="#신경망으로서의-선형-회귀-linear-regression-as-a-neural-network">신경망으로서의 선형 회귀 (Linear Regression as a Neural Network)</a></h2>
<p>선형 모델은 이 책에서 소개할 많은 복잡한 네트워크를 표현하기에 충분히 풍부하지 않지만, (인공) 신경망은 모든 특성이 입력 뉴런으로 표현되고 모두 출력에 직접 연결되는 네트워크로서 선형 모델을 포괄할 만큼 충분히 풍부합니다.</p>
<p>:numref:<code>fig_single_neuron</code>은 선형 회귀를 신경망으로 묘사합니다.
다이어그램은 각 입력이 출력에 연결되는 방식과 같은 연결 패턴을 강조하지만, 가중치나 편향이 취하는 특정 값은 강조하지 않습니다.</p>
<p><img src="../img/singleneuron.svg" alt="선형 회귀는 단일 레이어 신경망입니다." />
:label:<code>fig_single_neuron</code></p>
<p>입력은 $x_1, \ldots, x_d$입니다.
우리는 $d$를 입력 레이어의 <em>입력 수</em> 또는 <em>특성 차원</em>이라고 부릅니다.
네트워크의 출력은 $o_1$입니다.
우리는 단일 수치 값을 예측하려고 하기 때문에 출력 뉴런이 하나만 있습니다.
입력 값은 모두 <em>주어진</em> 값이라는 점에 유의하십시오. <em>계산된</em> 뉴런은 단 하나뿐입니다.
요약하자면, 우리는 선형 회귀를 단일 레이어 완전 연결 신경망으로 생각할 수 있습니다.
우리는 나중 장에서 훨씬 더 많은 레이어를 가진 네트워크를 만나게 될 것입니다.</p>
<h3 id="생물학-biology"><a class="header" href="#생물학-biology">생물학 (Biology)</a></h3>
<p>선형 회귀는 계산 신경과학보다 앞서기 때문에 선형 회귀를 신경망 측면에서 설명하는 것이 시대착오적으로 보일 수 있습니다.
그럼에도 불구하고 사이버네틱스학자와 신경생리학자인 워런 맥컬록(Warren McCulloch)과 월터 피츠(Walter Pitts)가 인공 뉴런 모델을 개발하기 시작했을 때 선형 회귀는 자연스러운 출발점이었습니다.
:numref:<code>fig_Neuron</code>에서 <em>수상 돌기(dendrites)</em> (입력 단자), <em>핵(nucleus)</em> (CPU), <em>축삭(axon)</em> (출력 와이어), <em>축삭 말단(axon terminals)</em> (출력 단자)으로 구성되어 <em>시냅스</em>를 통해 다른 뉴런과의 연결을 가능하게 하는 생물학적 뉴런의 만화 같은 그림을 고려해 보십시오.</p>
<p><img src="../img/neuron.svg" alt="실제 뉴런 (출처: 미국 국립 암 연구소의 감시, 역학 및 최종 결과(SEER) 프로그램의 &quot;해부학 및 생리학&quot;)." />
:label:<code>fig_Neuron</code></p>
<p>다른 뉴런(또는 환경 센서)에서 도착하는 정보 $x_i$는 수상 돌기에서 수신됩니다.
특히 그 정보는 <em>시냅스 가중치</em> $w_i$에 의해 가중치가 부여되어, 곱 $x_i w_i$를 통한 활성화 또는 억제와 같은 입력의 효과를 결정합니다.
여러 소스에서 도착하는 가중치 입력은 핵에서 가중 합 $y = \sum_i x_i w_i + b$로 집계되며, 함수 $\sigma(y)$를 통한 일부 비선형 후처리를 거칠 수 있습니다.
이 정보는 축삭을 통해 축삭 말단으로 보내져 목적지(예: 근육과 같은 액추에이터)에 도달하거나 수상 돌기를 통해 다른 뉴런으로 공급됩니다.</p>
<p>분명히, 올바른 연결성과 학습 알고리즘이 주어지면 하나의 뉴런만으로는 표현할 수 없는 훨씬 더 흥미롭고 복잡한 행동을 생성하기 위해 많은 그러한 유닛이 결합될 수 있다는 높은 수준의 아이디어는 실제 생물학적 신경계 연구에서 비롯된 것입니다.
동시에 오늘날 딥러닝의 대부분의 연구는 훨씬 더 넓은 소스에서 영감을 얻습니다.
우리는 비행기가 새에서 <em>영감을 받았을</em> 수는 있지만, 조류학이 몇 세기 동안 항공 혁신의 주요 동력은 아니었다고 지적한 :citet:<code>Russell.Norvig.2016</code>를 인용합니다.
마찬가지로 요즘 딥러닝의 영감은 수학, 언어학, 심리학, 통계학, 컴퓨터 과학 및 기타 많은 분야에서 동일하거나 더 큰 비중으로 옵니다.</p>
<h2 id="요약-summary"><a class="header" href="#요약-summary">요약 (Summary)</a></h2>
<p>이 섹션에서는 훈련 세트에서 제곱 손실을 최소화하도록 선형 함수의 파라미터를 선택하는 전통적인 선형 회귀를 소개했습니다.
우리는 또한 몇 가지 실용적인 고려 사항과 선형성 및 가우스 노이즈 가정 하에서의 최대 우도 추정으로서의 선형 회귀 해석을 통해 이 목적 함수 선택에 동기를 부여했습니다.
계산적 고려 사항과 통계와의 연결을 모두 논의한 후, 이러한 선형 모델이 입력이 출력에 직접 연결되는 단순한 신경망으로 어떻게 표현될 수 있는지 보여주었습니다.
곧 선형 모델을 완전히 벗어나겠지만, 이들은 우리가 모델에 요구하는 대부분의 구성 요소를 도입하기에 충분합니다: 파라미터 형식, 미분 가능한 목적 함수, 미니배치 확률적 경사 하강법을 통한 최적화, 그리고 궁극적으로 이전에 본 적 없는 데이터에 대한 평가입니다.</p>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>일부 데이터 $x_1, \ldots, x_n \in \mathbb{R}$가 있다고 가정합니다. 우리의 목표는 $\sum_i (x_i - b)^2$가 최소화되는 상수 $b$를 찾는 것입니다.
<ol>
<li>$b$의 최적 값에 대한 해석적 해를 찾으십시오.</li>
<li>이 문제와 그 해는 정규 분포와 어떤 관련이 있습니까?</li>
<li>손실을 $\sum_i (x_i - b)^2$에서 $\sum_i |x_i-b|$로 바꾸면 어떻게 됩니까? $b$에 대한 최적의 해를 찾을 수 있습니까?</li>
</ol>
</li>
<li>$\mathbf{x}^\top \mathbf{w} + b$로 표현될 수 있는 아핀 함수가 $(\mathbf{x}, 1)$에 대한 선형 함수와 동등함을 증명하십시오.</li>
<li>$\mathbf{x}$의 이차 함수, 즉 $f(\mathbf{x}) = b + \sum_i w_i x_i + \sum_{j \leq i} w_{ij} x_{i} x_{j}$를 찾고 싶다고 가정합니다. 이를 심층 네트워크에서 어떻게 공식화하겠습니까?</li>
<li>선형 회귀 문제가 해결 가능하기 위한 조건 중 하나는 설계 행렬 $\mathbf{X}^\top \mathbf{X}$가 풀 랭크(full rank)를 갖는 것이었습니다.
<ol>
<li>그렇지 않은 경우 어떻게 됩니까?</li>
<li>어떻게 고칠 수 있을까요? $\mathbf{X}$의 모든 항목에 좌표별로 독립적인 가우스 노이즈를 소량 추가하면 어떻게 됩니까?</li>
<li>이 경우 설계 행렬 $\mathbf{X}^\top \mathbf{X}$의 기댓값은 얼마입니까?</li>
<li>$\mathbf{X}^\top \mathbf{X}$가 풀 랭크가 아닐 때 확률적 경사 하강법은 어떻게 됩니까?</li>
</ol>
</li>
<li>가산 노이즈 $\epsilon$을 지배하는 노이즈 모델이 지수 분포라고 가정합니다. 즉, $p(\epsilon) = \frac{1}{2} \exp(-|\epsilon|)$입니다.
<ol>
<li>모델 하에서 데이터의 음의 로그 우도 $-\log P(\mathbf y \mid \mathbf X)$를 작성하십시오.</li>
<li>닫힌 형식의 해를 찾을 수 있습니까?</li>
<li>이 문제를 해결하기 위해 미니배치 확률적 경사 하강법 알고리즘을 제안하십시오. 무엇이 잘못될 수 있을까요 (힌트: 파라미터를 계속 업데이트함에 따라 정지점 근처에서 무슨 일이 일어납니까)? 이를 고칠 수 있습니까?</li>
</ol>
</li>
<li>두 개의 선형 레이어를 합성하여 두 개의 레이어가 있는 신경망을 설계하고 싶다고 가정합니다. 즉, 첫 번째 레이어의 출력이 두 번째 레이어의 입력이 됩니다. 왜 그런 단순한 합성이 작동하지 않을까요?</li>
<li>식료품점에서 판매된 사과의 <em>수</em>를 추정하기 위해 회귀를 사용하고 싶다고 가정해 봅시다.
<ol>
<li>가우스 가산 노이즈 모델의 문제는 무엇입니까? 힌트: 당신은 기름이 아니라 사과를 팔고 있습니다.</li>
<li><a href="https://en.wikipedia.org/wiki/Poisson_distribution">포아송 분포(Poisson distribution)</a>는 카운트에 대한 분포를 캡처합니다. $p(k \mid \lambda) = \lambda^k e^{-\lambda}/k!$로 주어집니다. 여기서 $\lambda$는 비율 함수이고 $k$는 관찰되는 이벤트의 수입니다. $\lambda$가 카운트 $k$의 기댓값임을 증명하십시오.</li>
<li>포아송 분포와 관련된 손실 함수를 설계하십시오.</li>
<li>대신 $\log \lambda$를 추정하기 위한 손실 함수를 설계하십시오.</li>
</ol>
</li>
</ol>
<p>:begin_tab:<code>mxnet</code>
<a href="https://discuss.d2l.ai/t/40">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/258">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>tensorflow</code>
<a href="https://discuss.d2l.ai/t/259">토론</a>
:end_tab:</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_linear-regression/index.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_linear-regression/oo-design.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_linear-regression/index.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_linear-regression/oo-design.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
