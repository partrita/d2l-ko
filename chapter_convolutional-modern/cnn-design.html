<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/cnn-design.html" class="active"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <pre><code class="language-{.python .input}">%load_ext d2lbook.tab
tab.interact_select(['mxnet', 'pytorch', 'tensorflow', 'jax'])
</code></pre>
<h1 id="합성곱-네트워크-아키텍처-설계-designing-convolution-network-architectures"><a class="header" href="#합성곱-네트워크-아키텍처-설계-designing-convolution-network-architectures">합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></h1>
<p>:label:<code>sec_cnn-design</code></p>
<p>이전 섹션들에서는 컴퓨터 비전을 위한 현대 네트워크 설계에 대해 살펴보았습니다.
많은 아키텍처가 과학자들의 직관에 크게 의존했으며, 인간의 창의성에 크게 의존하고 심층 네트워크가 제공하는 설계 공간에 대한 체계적인 탐구에는 훨씬 덜 의존했습니다.
그럼에도 불구하고 이 <em>네트워크 엔지니어링</em> 접근 방식은 엄청난 성공을 거두었습니다.</p>
<p>AlexNet(:numref:<code>sec_alexnet</code>)이 ImageNet에서 기존 컴퓨터 비전 모델을 능가한 이래로,
동일한 패턴에 따라 설계된 합성곱 블록을 쌓아 매우 깊은 네트워크를 구축하는 것이 인기를 얻었습니다.
특히 $3 \times 3$ 합성곱은 VGG 네트워크(:numref:<code>sec_vgg</code>)에 의해 대중화되었습니다.
NiN(:numref:<code>sec_nin</code>)은 $1 \times 1$ 합성곱조차도 국소 비선형성을 추가함으로써 유익할 수 있음을 보여주었습니다.
또한 NiN은 모든 위치에 걸쳐 집계함으로써 네트워크 헤드에서 정보를 집계하는 문제를 해결했습니다.
GoogLeNet(:numref:<code>sec_googlenet</code>)은 Inception 블록에서 VGG와 NiN의 장점을 결합하여 다양한 합성곱 너비의 다중 분기를 추가했습니다.
ResNet(:numref:<code>sec_resnet</code>)은 항등 매핑($f(x) = 0$에서)으로 귀납적 편향을 변경했습니다.
이로써 매우 깊은 네트워크가 가능해졌습니다.
거의 10년이 지난 지금도 ResNet 설계는 여전히 인기가 있으며, 이는 그 설계의 증거입니다.
마지막으로 ResNeXt(:numref:<code>subsec_resnext</code>)는 그룹화된 합성곱을 추가하여 파라미터와 계산 간의 더 나은 트레이드오프를 제공했습니다.
비전을 위한 Transformer의 전신인 Squeeze-and-Excitation Networks (SENets)는 위치 간의 효율적인 정보 전송을 가능하게 합니다 :cite:<code>Hu.Shen.Sun.2018</code>.
이는 채널별 전역 주의 함수를 계산하여 달성되었습니다.</p>
<p>지금까지 <em>신경 아키텍처 검색(neural architecture search, NAS)</em> :cite:<code>zoph2016neural,liu2018darts</code>을 통해 얻은 네트워크는 생략했습니다.
우리는 그 비용이 일반적으로 엄청나며 무차별 대입 검색, 유전 알고리즘, 강화 학습 또는 다른 형태의 하이퍼파라미터 최적화에 의존하기 때문에 그렇게 하기로 결정했습니다.
고정된 검색 공간이 주어지면 NAS는 반환된 성능 추정을 기반으로 아키텍처를 자동으로 선택하는 검색 전략을 사용합니다.
NAS의 결과는 단일 네트워크 인스턴스입니다. EfficientNet은 이 검색의 주목할 만한 결과입니다 :cite:<code>tan2019efficientnet</code>.</p>
<p>다음에서는 <em>단일 최고의 네트워크</em>를 찾는 탐구와는 상당히 다른 아이디어를 논의합니다.
계산적으로 상대적으로 저렴하고, 도중에 과학적 통찰력으로 이어지며, 결과의 품질 측면에서 매우 효과적입니다.
<em>네트워크 설계 공간을 설계</em>하기 위한 :citet:<code>Radosavovic.Kosaraju.Girshick.ea.2020</code>의 전략을 검토해 봅시다.
이 전략은 수동 설계와 NAS의 강점을 결합합니다.
<em>네트워크 분포</em>에 대해 작업하고 전체 네트워크 패밀리에 대해 좋은 성능을 얻는 방식으로 분포를 최적화함으로써 이를 달성합니다.
그 결과는 <em>RegNets</em>, 구체적으로 RegNetX 및 RegNetY, 그리고 고성능 CNN 설계를 위한 다양한 지침 원칙입니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
from d2l import mxnet as d2l
from mxnet import np, npx, init
from mxnet.gluon import nn

npx.set_np()
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
from d2l import torch as d2l
import torch
from torch import nn
from torch.nn import functional as F
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
import tensorflow as tf
from d2l import tensorflow as d2l
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
from d2l import jax as d2l
from flax import linen as nn
</code></pre>
<h2 id="anynet-설계-공간-the-anynet-design-space"><a class="header" href="#anynet-설계-공간-the-anynet-design-space">AnyNet 설계 공간 (The AnyNet Design Space)</a></h2>
<p>:label:<code>subsec_the-anynet-design-space</code></p>
<p>아래 설명은 :citet:<code>Radosavovic.Kosaraju.Girshick.ea.2020</code>의 추론을 밀접하게 따르며 책의 범위에 맞게 일부 약어를 사용합니다.
시작하려면 탐색할 네트워크 패밀리를 위한 템플릿이 필요합니다.
이 장의 설계 중 공통점 중 하나는 네트워크가 <em>스템(stem)</em>, <em>바디(body)</em>, *헤드(head)*로 구성된다는 것입니다.
스템은 종종 더 큰 윈도우 크기를 가진 합성곱을 통해 초기 이미지 처리를 수행합니다.
바디는 원시 이미지에서 객체 표현으로 가는 데 필요한 변환의 대부분을 수행하는 다중 블록으로 구성됩니다.
마지막으로 헤드는 이를 다중 클래스 분류를 위한 소프트맥스 회귀기와 같은 원하는 출력으로 변환합니다.
바디는 차례로 감소하는 해상도에서 이미지에 대해 작업하는 다중 단계로 구성됩니다.
사실 스템과 각 후속 단계는 공간 해상도를 4분의 1로 줄입니다.
마지막으로 각 단계는 하나 이상의 블록으로 구성됩니다.
이 패턴은 VGG에서 ResNeXt에 이르기까지 모든 네트워크에 공통적입니다.
실제로 일반적인 AnyNet 네트워크 설계를 위해 :citet:<code>Radosavovic.Kosaraju.Girshick.ea.2020</code>는 :numref:<code>fig_resnext_block</code>의 ResNeXt 블록을 사용했습니다.</p>
<p><img src="../img/anynet.svg" alt="AnyNet 설계 공간. 각 화살표를 따라 있는 숫자 $(\mathit{c}, \mathit{r})$은 해당 지점에서의 채널 수 $c$와 이미지의 해상도 $\mathit{r} \times \mathit{r}$를 나타냅니다. 왼쪽에서 오른쪽으로: 스템, 바디, 헤드로 구성된 일반적인 네트워크 구조; 4단계로 구성된 바디; 단계의 상세 구조; 다운샘플링이 없는 블록과 각 차원에서 해상도를 절반으로 줄이는 블록의 두 가지 대안 구조. 설계 선택에는 깊이 $\mathit{d_i}$, 출력 채널 수 $\mathit{c_i}$, 그룹 수 $\mathit{g_i}$, 그리고 모든 단계 $\mathit{i}$에 대한 병목 비율 $\mathit{k_i}$가 포함됩니다." />
:label:<code>fig_anynet_full</code></p>
<p>:numref:<code>fig_anynet_full</code>에 설명된 구조를 자세히 검토해 봅시다. 언급했듯이 AnyNet은 스템, 바디, 헤드로 구성됩니다. 스템은 RGB 이미지(3채널)를 입력으로 받아 스트라이드가 $2$인 $3 \times 3$ 합성곱을 사용하고 배치 정규화가 뒤따라 해상도를 $r \times r$에서 $r/2 \times r/2$로 절반으로 줄입니다. 또한 바디에 입력으로 사용될 $c_0$ 채널을 생성합니다.</p>
<p>네트워크는 $224 \times 224 \times 3$ 모양의 ImageNet 이미지와 잘 작동하도록 설계되었으므로, 바디는 4단계(상기하자면 $224 / 2^{1+4} = 7$)를 통해 이를 $7 \times 7 \times c_4$로 줄이는 역할을 하며, 각 단계는 결국 스트라이드가 $2$입니다.
마지막으로 헤드는 NiN(:numref:<code>sec_nin</code>)과 유사한 전역 평균 풀링을 통해 완전히 표준적인 설계를 채택하고, $n$-클래스 분류를 위한 $n$차원 벡터를 방출하기 위해 완전 연결 레이어가 뒤따릅니다.</p>
<p>대부분의 관련 설계 결정은 네트워크 바디에 내재되어 있습니다.
바디는 단계적으로 진행되며, 각 단계는 :numref:<code>subsec_resnext</code>에서 논의한 것과 동일한 유형의 ResNeXt 블록으로 구성됩니다.
거기서의 설계는 다시 완전히 일반적입니다: 스트라이드 $2$를 사용하여 해상도를 절반으로 줄이는 블록으로 시작합니다(:numref:<code>fig_anynet_full</code>의 맨 오른쪽).
이에 맞추기 위해 ResNeXt 블록의 잔차 분기는 $1 \times 1$ 합성곱을 통과해야 합니다.
이 블록 뒤에는 해상도와 채널 수를 변경하지 않는 가변 수의 추가 ResNeXt 블록이 잇따릅니다.
일반적인 설계 관행은 합성곱 블록 설계에 약간의 병목 현상을 추가하는 것입니다.
따라서 병목 비율 $k_i \geq 1$로 단계 $i$의 각 블록 내에 $c_i/k_i$ 채널을 제공합니다(실험에서 알 수 있듯이 이는 실제로 효과적이지 않으므로 건너뛰어야 합니다).
마지막으로 ResNeXt 블록을 다루고 있으므로 단계 $i$에서 그룹화된 합성곱에 대한 그룹 수 $g_i$도 선택해야 합니다.</p>
<p>이 겉보기에 일반적인 설계 공간은 그럼에도 불구하고 우리에게 많은 파라미터를 제공합니다:
블록 너비(채널 수) $c_0, \ldots c_4$, 단계별 깊이(블록 수) $d_1, \ldots d_4$, 병목 비율 $k_1, \ldots k_4$, 그룹 너비(그룹 수) $g_1, \ldots g_4$를 설정할 수 있습니다.
총 17개의 파라미터가 추가되어 탐색을 정당화할 수 없을 만큼 많은 수의 구성이 생성됩니다.
이 거대한 설계 공간을 효과적으로 줄이기 위한 도구가 필요합니다.
이곳이 설계 공간의 개념적 아름다움이 들어오는 곳입니다. 그렇게 하기 전에 일반적인 설계를 먼저 구현해 봅시다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
class AnyNet(d2l.Classifier):
    def stem(self, num_channels):
        net = nn.Sequential()
        net.add(nn.Conv2D(num_channels, kernel_size=3, padding=1, strides=2),
                nn.BatchNorm(), nn.Activation('relu'))
        return net
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
class AnyNet(d2l.Classifier):
    def stem(self, num_channels):
        return nn.Sequential(
            nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),
            nn.LazyBatchNorm2d(), nn.ReLU())
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
class AnyNet(d2l.Classifier):
    def stem(self, num_channels):
        return tf.keras.models.Sequential([
            tf.keras.layers.Conv2D(num_channels, kernel_size=3, strides=2,
                                   padding='same'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Activation('relu')])
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
class AnyNet(d2l.Classifier):
    arch: tuple
    stem_channels: int
    lr: float = 0.1
    num_classes: int = 10
    training: bool = True

    def setup(self):
        self.net = self.create_net()

    def stem(self, num_channels):
        return nn.Sequential([
            nn.Conv(num_channels, kernel_size=(3, 3), strides=(2, 2),
                    padding=(1, 1)),
            nn.BatchNorm(not self.training),
            nn.relu
        ])
</code></pre>
<p>각 단계는 <code>depth</code>개의 ResNeXt 블록으로 구성되며,
<code>num_channels</code>는 블록 너비를 지정합니다.
첫 번째 블록은 입력 이미지의 높이와 너비를 절반으로 줄인다는 점에 유의하십시오.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
@d2l.add_to_class(AnyNet)
def stage(self, depth, num_channels, groups, bot_mul):
    net = nn.Sequential()
    for i in range(depth):
        if i == 0:
            net.add(d2l.ResNeXtBlock(
                num_channels, groups, bot_mul, use_1x1conv=True, strides=2))
        else:
            net.add(d2l.ResNeXtBlock(
                num_channels, num_channels, groups, bot_mul))
    return net
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
@d2l.add_to_class(AnyNet)
def stage(self, depth, num_channels, groups, bot_mul):
    blk = []
    for i in range(depth):
        if i == 0:
            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,
                use_1x1conv=True, strides=2))
        else:
            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul))
    return nn.Sequential(*blk)
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
@d2l.add_to_class(AnyNet)
def stage(self, depth, num_channels, groups, bot_mul):
    net = tf.keras.models.Sequential()
    for i in range(depth):
        if i == 0:
            net.add(d2l.ResNeXtBlock(num_channels, groups, bot_mul,
                use_1x1conv=True, strides=2))
        else:
            net.add(d2l.ResNeXtBlock(num_channels, groups, bot_mul))
    return net
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
@d2l.add_to_class(AnyNet)
def stage(self, depth, num_channels, groups, bot_mul):
    blk = []
    for i in range(depth):
        if i == 0:
            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,
                use_1x1conv=True, strides=(2, 2), training=self.training))
        else:
            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,
                                        training=self.training))
    return nn.Sequential(blk)
</code></pre>
<p>네트워크 스템, 바디, 헤드를 합쳐 AnyNet 구현을 완료합니다.</p>
<pre><code class="language-{.python .input}">%%tab pytorch, mxnet, tensorflow
@d2l.add_to_class(AnyNet)
def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):
    super(AnyNet, self).__init__()
    self.save_hyperparameters()
    if tab.selected('mxnet'):
        self.net = nn.Sequential()
        self.net.add(self.stem(stem_channels))
        for i, s in enumerate(arch):
            self.net.add(self.stage(*s))
        self.net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))
        self.net.initialize(init.Xavier())
    if tab.selected('pytorch'):
        self.net = nn.Sequential(self.stem(stem_channels))
        for i, s in enumerate(arch):
            self.net.add_module(f'stage{i+1}', self.stage(*s))
        self.net.add_module('head', nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),
            nn.LazyLinear(num_classes)))
        self.net.apply(d2l.init_cnn)
    if tab.selected('tensorflow'):
        self.net = tf.keras.models.Sequential(self.stem(stem_channels))
        for i, s in enumerate(arch):
            self.net.add(self.stage(*s))
        self.net.add(tf.keras.models.Sequential([
            tf.keras.layers.GlobalAvgPool2D(),
            tf.keras.layers.Dense(units=num_classes)]))
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
@d2l.add_to_class(AnyNet)
def create_net(self):
    net = nn.Sequential([self.stem(self.stem_channels)])
    for i, s in enumerate(self.arch):
        net.layers.extend([self.stage(*s)])
    net.layers.extend([nn.Sequential([
        lambda x: nn.avg_pool(x, window_shape=x.shape[1:3],
                            strides=x.shape[1:3], padding='valid'),
        lambda x: x.reshape((x.shape[0], -1)),
        nn.Dense(self.num_classes)])])
    return net
</code></pre>
<h2 id="설계-공간의-분포-및-파라미터-distributions-and-parameters-of-design-spaces"><a class="header" href="#설계-공간의-분포-및-파라미터-distributions-and-parameters-of-design-spaces">설계 공간의 분포 및 파라미터 (Distributions and Parameters of Design Spaces)</a></h2>
<p>:numref:<code>subsec_the-anynet-design-space</code>에서 논의했듯이 설계 공간의 파라미터는 해당 설계 공간에 있는 네트워크의 하이퍼파라미터입니다.
AnyNet 설계 공간에서 좋은 파라미터를 식별하는 문제를 고려해 보십시오.
우리는 주어진 계산량(예: FLOPs 및 컴퓨팅 시간)에 대해 <em>단일 최고의</em> 파라미터 선택을 찾으려고 시도할 수 있습니다.
각 파라미터에 대해 <em>두 가지</em> 가능한 선택만 허용하더라도, 최고의 솔루션을 찾기 위해 $2^{17} = 131072$ 조합을 탐색해야 합니다.
이는 엄청난 비용 때문에 명백히 실행 불가능합니다.
설상가상으로 우리는 네트워크를 어떻게 설계해야 하는지에 대해 이 연습에서 실제로 아무것도 배우지 못합니다.
다음에 예를 들어 X-스테이지, 시프트 연산 또는 이와 유사한 것을 추가하면 처음부터 다시 시작해야 합니다.
더 나쁜 것은 훈련의 확률성(반올림, 셔플링, 비트 오류) 때문에 두 번의 실행이 정확히 동일한 결과를 생성할 가능성이 낮다는 것입니다.
더 나은 전략은 파라미터 선택이 어떻게 관련되어야 하는지에 대한 일반적인 지침을 결정하려고 노력하는 것입니다.
예를 들어 병목 비율, 채널 수, 블록, 그룹 또는 레이어 간의 변경은 이상적으로는 일련의 간단한 규칙에 의해 관리되어야 합니다.
:citet:<code>radosavovic2019network</code>의 접근 방식은 다음 네 가지 가정에 의존합니다:</p>
<ol>
<li>우리는 일반적인 설계 원칙이 실제로 존재한다고 가정하므로 이러한 요구 사항을 충족하는 많은 네트워크가 좋은 성능을 제공해야 합니다. 결과적으로 네트워크에 대한 <em>분포</em>를 식별하는 것은 합리적인 전략이 될 수 있습니다. 즉, 건초더미에 좋은 바늘이 많이 있다고 가정합니다.</li>
<li>네트워크가 좋은지 평가하기 위해 수렴될 때까지 네트워크를 훈련할 필요는 없습니다. 대신 중간 결과를 최종 정확도에 대한 신뢰할 수 있는 지침으로 사용하는 것으로 충분합니다. 목적 함수를 최적화하기 위해 (근사) 프록시를 사용하는 것을 다중 충실도 최적화(multi-fidelity optimization)라고 합니다 :cite:<code>forrester2007multi</code>. 결과적으로 데이터셋을 몇 번 통과한 후 달성한 정확도를 기반으로 설계 최적화가 수행되어 비용을 크게 줄입니다.</li>
<li>더 작은 규모(더 작은 네트워크)에서 얻은 결과는 더 큰 규모로 일반화됩니다. 결과적으로 최적화는 구조적으로 유사하지만 블록 수가 적고 채널이 적은 네트워크에 대해 수행됩니다. 결국에만 이렇게 찾은 네트워크가 대규모에서도 좋은 성능을 제공하는지 확인해야 합니다.</li>
<li>설계의 측면은 대략적으로 인수 분해될 수 있으므로 결과의 품질에 미치는 영향을 다소 독립적으로 추론할 수 있습니다. 즉, 최적화 문제는 적당히 쉽습니다.</li>
</ol>
<p>이러한 가정을 통해 우리는 많은 네트워크를 저렴하게 테스트할 수 있습니다. 특히 구성 공간에서 균일하게 <em>샘플링</em>하고 성능을 평가할 수 있습니다.
그 후, 해당 네트워크로 달성할 수 있는 오류/정확도의 <em>분포</em>를 검토하여 파라미터 선택의 품질을 평가할 수 있습니다.
$F(e)$를 확률 분포 $p$를 사용하여 추출된 주어진 설계 공간의 네트워크가 범한 오류에 대한 누적 분포 함수(CDF)로 표시합니다. 즉,</p>
<p>$$F(e, p) \stackrel{\textrm{def}}{=} P_{\textrm{net} \sim p} {e(\textrm{net}) \leq e}.$$</p>
<p>우리의 목표는 이제 대부분의 네트워크가 매우 낮은 오류율을 갖고 $p$의 지원(support)이 간결한 <em>네트워크</em>에 대한 분포 $p$를 찾는 것입니다.
물론 이것을 정확하게 수행하는 것은 계산적으로 실행 불가능합니다.
우리는 $p$에서 네트워크 샘플 $\mathcal{Z} \stackrel{\textrm{def}}{=} {\textrm{net}_1, \ldots \textrm{net}_n}$ (각각 오류 $e_1, \ldots, e_n$ 포함)에 의존하고 대신 경험적 CDF $\hat{F}(e, \mathcal{Z})$를 사용합니다:</p>
<p>$$\hat{F}(e, \mathcal{Z}) = \frac{1}{n}\sum_{i=1}^n \mathbf{1}(e_i \leq e).$$</p>
<p>한 선택 세트에 대한 CDF가 다른 CDF를 지배(majorizes)(또는 일치)할 때마다 파라미터 선택이 우월(또는 무관)하다는 결론이 나옵니다.
이에 따라 :citet:<code>Radosavovic.Kosaraju.Girshick.ea.2020</code>는 네트워크의 모든 단계 $i$에 대해 공유 네트워크 병목 비율 $k_i = k$를 실험했습니다.
이것은 병목 비율을 지배하는 4개의 파라미터 중 3개를 제거합니다.
이것이 성능에 (부정적인) 영향을 미치는지 평가하기 위해 제한된 분포와 제한되지 않은 분포에서 네트워크를 추출하고 해당 CDF를 비교할 수 있습니다.
:numref:<code>fig_regnet-fig</code>의 첫 번째 패널에서 볼 수 있듯이 이 제약 조건은 네트워크 분포의 정확도에 전혀 영향을 미치지 않는 것으로 나타났습니다.
마찬가지로 네트워크의 다양한 단계에서 발생하는 동일한 그룹 너비 $g_i = g$를 선택할 수 있습니다.
다시 말하지만 :numref:<code>fig_regnet-fig</code>의 두 번째 패널에서 볼 수 있듯이 성능에는 영향을 미치지 않습니다.
두 단계를 합치면 자유 파라미터 수가 6개 줄어듭니다.</p>
<p><img src="../img/regnet-fig.png" alt="설계 공간의 오류 경험적 분포 함수 비교. $\textrm{AnyNet}\mathit{A}$는 원래 설계 공간입니다. $\textrm{AnyNet}\mathit{B}$는 병목 비율을 묶고, $\textrm{AnyNet}\mathit{C}$는 그룹 너비도 묶으며, $\textrm{AnyNet}\mathit{D}$는 단계 전반에 걸쳐 네트워크 깊이를 늘립니다. 왼쪽에서 오른쪽으로: (i) 병목 비율을 묶는 것은 성능에 영향을 미치지 않습니다; (ii) 그룹 너비를 묶는 것은 성능에 영향을 미치지 않습니다; (iii) 단계 전반에 걸쳐 네트워크 너비(채널)를 늘리면 성능이 향상됩니다; (iv) 단계 전반에 걸쳐 네트워크 깊이를 늘리면 성능이 향상됩니다. 그림 제공: :citet:Radosavovic.Kosaraju.Girshick.ea.2020." />
:label:<code>fig_regnet-fig</code></p>
<p>다음으로 우리는 단계의 너비와 깊이에 대한 수많은 잠재적 선택을 줄이는 방법을 찾습니다.
더 깊이 들어갈수록 채널 수가 증가해야 한다는 것은 합리적인 가정입니다. 즉, $c_i \geq c_{i-1}$ (:numref:<code>fig_regnet-fig</code>의 표기법에 따르면 $w_{i+1} \geq w_i$), 이는 $\textrm{AnyNetX}<em>D$를 산출합니다.
마찬가지로 단계가 진행됨에 따라 더 깊어져야 한다고 가정하는 것도 똑같이 합리적입니다. 즉, $d_i \geq d</em>{i-1}$, 이는 $\textrm{AnyNetX}_E$를 산출합니다.
이것은 각각 :numref:<code>fig_regnet-fig</code>의 세 번째와 네 번째 패널에서 실험적으로 검증할 수 있습니다.</p>
<h2 id="regnet"><a class="header" href="#regnet">RegNet</a></h2>
<p>결과 $\textrm{AnyNetX}_E$ 설계 공간은 해석하기 쉬운 설계 원칙을 따르는 단순한 네트워크로 구성됩니다:</p>
<ul>
<li>모든 단계 $i$에 대해 병목 비율 $k_i = k$를 공유합니다.</li>
<li>모든 단계 $i$에 대해 그룹 너비 $g_i = g$를 공유합니다.</li>
<li>단계 전반에 걸쳐 네트워크 너비를 늘립니다: $c_{i} \leq c_{i+1}$.</li>
<li>단계 전반에 걸쳐 네트워크 깊이를 늘립니다: $d_{i} \leq d_{i+1}$.</li>
</ul>
<p>이것은 우리에게 마지막 선택 세트를 남깁니다: 최종 $\textrm{AnyNetX}_E$ 설계 공간의 위 파라미터에 대한 특정 값을 선택하는 방법입니다.
$	extrm{AnyNetX}_E$의 분포에서 가장 성능이 좋은 네트워크를 연구함으로써 다음을 관찰할 수 있습니다: 네트워크의 너비는 이상적으로 네트워크 전반에 걸쳐 블록 인덱스와 함께 선형적으로 증가합니다. 즉, $c_j \approx c_0 + c_a j$, 여기서 $j$는 블록 인덱스이고 기울기 $c_a &gt; 0$입니다.
단계별로만 다른 블록 너비를 선택할 수 있으므로, 이 의존성과 일치하도록 설계된 조각별 상수 함수에 도달합니다.
또한 실험은 병목 비율 $k = 1$이 가장 잘 수행됨을 보여줍니다. 즉, 병목 현상을 전혀 사용하지 않는 것이 좋습니다.</p>
<p>관심 있는 독자는 :citet:<code>Radosavovic.Kosaraju.Girshick.ea.2020</code>를 정독하여 다양한 계산량에 대한 특정 네트워크 설계의 추가 세부 사항을 검토할 것을 권장합니다.
예를 들어 효과적인 32레이어 RegNetX 변형은 $k = 1$(병목 없음), $g = 16$(그룹 너비 16), 첫 번째 및 두 번째 단계에 대해 각각 $c_1 = 32$ 및 $c_2 = 80$ 채널, 깊이는 $d_1=4$ 및 $d_2=6$ 블록으로 선택됩니다.
설계에서 얻은 놀라운 통찰력은 더 큰 규모의 네트워크를 조사할 때에도 여전히 적용된다는 것입니다.
더 좋은 점은 전역 채널 활성화를 가진 Squeeze-and-Excitation(SE) 네트워크 설계(RegNetY)에도 적용된다는 것입니다 :cite:<code>Hu.Shen.Sun.2018</code>.</p>
<pre><code class="language-{.python .input}">%%tab pytorch, mxnet, tensorflow
class RegNetX32(AnyNet):
    def __init__(self, lr=0.1, num_classes=10):
        stem_channels, groups, bot_mul = 32, 16, 1
        depths, channels = (4, 6), (32, 80)
        super().__init__(
            ((depths[0], channels[0], groups, bot_mul),
             (depths[1], channels[1], groups, bot_mul)),
            stem_channels, lr, num_classes)
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
class RegNetX32(AnyNet):
    lr: float = 0.1
    num_classes: int = 10
    stem_channels: int = 32
    arch: tuple = ((4, 32, 16, 1), (6, 80, 16, 1))
</code></pre>
<p>각 RegNetX 단계가 점진적으로 해상도를 줄이고 출력 채널을 늘리는 것을 볼 수 있습니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet, pytorch
RegNetX32().layer_summary((1, 1, 96, 96))
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
RegNetX32().layer_summary((1, 96, 96, 1))
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
RegNetX32(training=False).layer_summary((1, 96, 96, 1))
</code></pre>
<h2 id="훈련-training"><a class="header" href="#훈련-training">훈련 (Training)</a></h2>
<p>Fashion-MNIST 데이터셋에서 32레이어 RegNetX를 훈련하는 것은 이전과 같습니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet, pytorch, jax
model = RegNetX32(lr=0.05)
trainer = d2l.Trainer(max_epochs=10, num_gpus=1)
data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))
trainer.fit(model, data)
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
trainer = d2l.Trainer(max_epochs=10)
data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))
with d2l.try_gpu():
    model = RegNetX32(lr=0.01)
    trainer.fit(model, data)
</code></pre>
<h2 id="토론-discussion"><a class="header" href="#토론-discussion">토론 (Discussion)</a></h2>
<p>비전에 대한 지역성 및 평행 이동 불변성(:numref:<code>sec_why-conv</code>)과 같은 바람직한 귀납적 편향(가정 또는 선호도)으로 인해 CNN은 이 분야에서 지배적인 아키텍처였습니다.
이것은 LeNet부터 Transformer(:numref:<code>sec_transformer</code>) :cite:<code>Dosovitskiy.Beyer.Kolesnikov.ea.2021,touvron2021training</code>가 정확도 측면에서 CNN을 능가하기 시작할 때까지 유지되었습니다.
비전 Transformer 측면의 최근 진전 중 많은 부분이 CNN으로 백포트(backported) <em>될 수</em> 있지만 :cite:<code>liu2022convnet</code>, 더 높은 계산 비용으로만 가능합니다.
마찬가지로 중요한 것은 최근의 하드웨어 최적화(NVIDIA Ampere 및 Hopper)가 Transformer에 유리한 격차를 넓혔다는 것입니다.</p>
<p>Transformer는 CNN보다 지역성 및 평행 이동 불변성에 대한 귀납적 편향 정도가 상당히 낮다는 점에 주목할 가치가 있습니다.
학습된 구조가 우세했던 것은 무엇보다도 최대 50억 개의 이미지가 있는 LAION-400m 및 LAION-5B :cite:<code>schuhmann2022laion</code>와 같은 대규모 이미지 컬렉션의 가용성 때문입니다.
놀랍게도 이 맥락에서 더 관련성 있는 작업 중 일부는 MLP를 포함하기도 합니다 :cite:<code>tolstikhin2021mlp</code>.</p>
<p>요약하자면, 비전 Transformer(:numref:<code>sec_vision-transformer</code>)는 이제 대규모 이미지 분류에서 최첨단 성능을 주도하며 <em>확장성이 귀납적 편향을 이긴다</em>는 것을 보여줍니다 :cite:<code>Dosovitskiy.Beyer.Kolesnikov.ea.2021</code>.
여기에는 다중 헤드 자체 주의(:numref:<code>sec_multihead-attention</code>)가 있는 대규모 Transformer 사전 훈련(:numref:<code>sec_large-pretraining-transformers</code>)이 포함됩니다.
우리는 독자들이 훨씬 더 자세한 토론을 위해 이 장들에 뛰어들기를 권합니다.</p>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>단계 수를 4개로 늘리십시오. 더 잘 수행되는 더 깊은 RegNetX를 설계할 수 있습니까?</li>
<li>ResNeXt 블록을 ResNet 블록으로 교체하여 RegNet을 De-ResNeXt-ify하십시오. 새 모델은 어떻게 수행됩니까?</li>
<li>RegNetX의 설계 원칙을 <em>위반</em>하여 "VioNet" 패밀리의 여러 인스턴스를 구현하십시오. 그들은 어떻게 수행됩니까? ($d_i$, $c_i$, $g_i$, $b_i$) 중 가장 중요한 요소는 무엇입니까?</li>
<li>당신의 목표는 "완벽한" MLP를 설계하는 것입니다. 위에서 소개한 설계 원칙을 사용하여 좋은 아키텍처를 찾을 수 있습니까? 작은 네트워크에서 큰 네트워크로 외삽하는 것이 가능합니까?</li>
</ol>
<p>:begin_tab:<code>mxnet</code>
<a href="https://discuss.d2l.ai/t/7462">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/7463">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>tensorflow</code>
<a href="https://discuss.d2l.ai/t/8738">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>jax</code>
<a href="https://discuss.d2l.ai/t/18009">토론</a>
:end_tab:</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_convolutional-modern/densenet.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_recurrent-neural-networks/index.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_convolutional-modern/densenet.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_recurrent-neural-networks/index.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
