<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/resnet.html" class="active"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <pre><code class="language-{.python .input}">%load_ext d2lbook.tab
tab.interact_select(['mxnet', 'pytorch', 'tensorflow', 'jax'])
</code></pre>
<h1 id="잔차-네트워크-resnet와-resnext-residual-networks-resnet-and-resnext"><a class="header" href="#잔차-네트워크-resnet와-resnext-residual-networks-resnet-and-resnext">잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></h1>
<p>:label:<code>sec_resnet</code></p>
<p>점점 더 깊은 네트워크를 설계함에 따라 레이어를 추가하는 것이 네트워크의 복잡성과 표현력을 어떻게 증가시킬 수 있는지 이해하는 것이 필수적이 되었습니다.
더 중요한 것은 레이어를 추가하는 것이 네트워크를 단순히 다르게 만드는 것이 아니라 엄격하게 더 표현력 있게 만드는 네트워크를 설계하는 능력입니다.
약간의 진전을 이루려면 약간의 수학이 필요합니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
from d2l import mxnet as d2l
from mxnet import np, npx, init
from mxnet.gluon import nn
npx.set_np()
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
from d2l import torch as d2l
import torch
from torch import nn
from torch.nn import functional as F
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
import tensorflow as tf
from d2l import tensorflow as d2l
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
from d2l import jax as d2l
from flax import linen as nn
from jax import numpy as jnp
import jax
</code></pre>
<h2 id="함수-클래스-function-classes"><a class="header" href="#함수-클래스-function-classes">함수 클래스 (Function Classes)</a></h2>
<p>특정 네트워크 아키텍처(학습률 및 기타 하이퍼파라미터 설정과 함께)가 도달할 수 있는 함수 클래스 $\mathcal{F}$를 고려하십시오.
즉, 모든 $f \in \mathcal{F}$에 대해 적절한 데이터셋에 대한 훈련을 통해 얻을 수 있는 파라미터 세트(예: 가중치 및 편향)가 존재합니다.
$f^<em>$가 우리가 정말로 찾고 싶은 "진실" 함수라고 가정해 봅시다.
그것이 $\mathcal{F}$에 있다면 우리는 좋은 상태이지만 일반적으로 그렇게 운이 좋지는 않을 것입니다.
대신 우리는 $\mathcal{F}$ 내에서 최선의 선택인 $f^</em>_\mathcal{F}$를 찾으려고 노력할 것입니다.
예를 들어,
특성 $\mathbf{X}$와 레이블 $\mathbf{y}$가 있는 데이터셋이 주어지면,
우리는 다음 최적화 문제를 해결하여 그것을 찾으려고 시도할 수 있습니다:</p>
<p>$$f^*_\mathcal{F} \stackrel{\textrm{def}}{=} \mathop{\mathrm{argmin}}_f L(\mathbf{X}, \mathbf{y}, f) \textrm{ subject to } f \in \mathcal{F}.$$</p>
<p>우리는 정규화 :cite:<code>tikhonov1977solutions,morozov2012methods</code>가 $\mathcal{F}$의 복잡도를 제어하고 일관성을 달성할 수 있음을 알고 있으므로, 더 큰 크기의 훈련 데이터는 일반적으로 더 나은 $f^<em>_\mathcal{F}$로 이어집니다.
우리가 다른 더 강력한 아키텍처 $\mathcal{F}'$를 설계하면 더 나은 결과를 얻어야 한다고 가정하는 것이 합리적입니다. 즉, 우리는 $f^</em><em>{\mathcal{F}'}$가 $f^*</em>{\mathcal{F}}$보다 "더 낫기"를 기대합니다. 그러나 $\mathcal{F} \not\subseteq \mathcal{F}'$이면 이런 일이 일어날 것이라는 보장이 없습니다. 사실 $f^<em>_{\mathcal{F}'}$는 더 나쁠 수도 있습니다.
:numref:<code>fig_functionclasses</code>에서 설명한 것처럼, 중첩되지 않은 함수 클래스의 경우 더 큰 함수 클래스가 항상 "진실" 함수 $f^</em>$에 더 가까이 이동하는 것은 아닙니다. 예를 들어,
:numref:<code>fig_functionclasses</code>의 왼쪽에서 $\mathcal{F}_3$은 $\mathcal{F}_1$보다 $f^<em>$에 가깝지만, $\mathcal{F}_6$은 멀어지고 복잡도를 더 높이면 $f^</em>$와의 거리를 줄일 수 있다는 보장이 없습니다.
:numref:<code>fig_functionclasses</code>의 오른쪽과 같이 $\mathcal{F}_1 \subseteq \cdots \subseteq \mathcal{F}_6$인 중첩 함수 클래스를 사용하면 중첩되지 않은 함수 클래스의 앞서 언급한 문제를 피할 수 있습니다.</p>
<p><img src="../img/functionclasses.svg" alt="중첩되지 않은 함수 클래스의 경우, 더 큰(영역으로 표시됨) 함수 클래스가 &quot;진실&quot; 함수($\mathit{f}^*$)에 더 가까워진다는 보장이 없습니다. 중첩 함수 클래스에서는 이런 일이 발생하지 않습니다." />
:label:<code>fig_functionclasses</code></p>
<p>따라서 더 큰 함수 클래스가 더 작은 함수 클래스를 포함하는 경우에만 이를 늘리면 네트워크의 표현력이 엄격하게 증가한다는 것이 보장됩니다.
심층 신경망의 경우,
새로 추가된 레이어를 항등 함수 $f(\mathbf{x}) = \mathbf{x}$로 훈련할 수 있다면 새 모델은 원래 모델만큼 효과적일 것입니다. 새 모델이 훈련 데이터셋에 맞는 더 나은 솔루션을 얻을 수 있으므로, 추가된 레이어는 훈련 오류를 줄이는 것을 더 쉽게 만들 수 있습니다.</p>
<p>이것은 :citet:<code>He.Zhang.Ren.ea.2016</code>가 매우 깊은 컴퓨터 비전 모델을 작업할 때 고려한 질문이었습니다.
제안된 <em>잔차 네트워크</em> (<em>ResNet</em>)의 핵심에는 모든 추가 레이어가 그 요소 중 하나로 항등 함수를 더 쉽게 포함해야 한다는 아이디어가 있습니다.
이러한 고려 사항은 다소 심오하지만 *잔차 블록(residual block)*이라는 놀랍도록 간단한 해결책으로 이어졌습니다.
이를 통해 ResNet은 2015년 ImageNet 대규모 시각 인식 챌린지에서 우승했습니다. 이 디자인은 심층 신경망을 구축하는 방법에 지대한 영향을 미쳤습니다. 예를 들어 잔차 블록은 순환 네트워크에 추가되었습니다 :cite:<code>prakash2016neural,kim2017residual</code>. 마찬가지로 Transformer :cite:<code>Vaswani.Shazeer.Parmar.ea.2017</code>는 이를 사용하여 많은 레이어의 네트워크를 효율적으로 쌓습니다. 그래프 신경망 :cite:<code>Kipf.Welling.2016</code>에도 사용되며 기본 개념으로서 컴퓨터 비전에서 광범위하게 사용되었습니다 :cite:<code>Redmon.Farhadi.2018,Ren.He.Girshick.ea.2015</code>.
잔차 네트워크 이전에 고속도로 네트워크(highway networks) :cite:<code>srivastava2015highway</code>가 있었는데, 항등 함수 주변의 우아한 파라미터화는 없지만 동기의 일부를 공유합니다.</p>
<h2 id="잔차-블록"><a class="header" href="#잔차-블록">(<strong>잔차 블록</strong>)</a></h2>
<p>:label:<code>subsec_residual-blks</code></p>
<p>:numref:<code>fig_residual_block</code>에 묘사된 대로 신경망의 국소 부분에 집중해 봅시다. 입력을 $\mathbf{x}$로 표시합니다.
우리는 학습을 통해 얻고자 하는 기저 매핑 $f(\mathbf{x})$가 상단의 활성화 함수에 입력으로 사용된다고 가정합니다.
왼쪽에서,
점선 상자 안의 부분은 $f(\mathbf{x})$를 직접 학습해야 합니다.
오른쪽에서,
점선 상자 안의 부분은 <em>잔차 매핑(residual mapping)</em> $g(\mathbf{x}) = f(\mathbf{x}) - \mathbf{x}$를 학습해야 하며, 여기서 잔차 블록이라는 이름이 유래했습니다.
항등 매핑 $f(\mathbf{x}) = \mathbf{x}$가 원하는 기저 매핑인 경우, 잔차 매핑은 $g(\mathbf{x}) = 0$이 되므로 학습하기가 더 쉽습니다:
점선 상자 안의 상부 가중치 레이어(예: 완전 연결 레이어 및 합성곱 레이어)의 가중치와 편향을 0으로 밀어 넣기만 하면 됩니다.
오른쪽 그림은 ResNet의 <em>잔차 블록</em>을 보여주며, 레이어 입력 $\mathbf{x}$를 덧셈 연산자로 전달하는 실선을 <em>잔차 연결(residual connection)</em> (또는 <em>숏컷 연결(shortcut connection)</em>)이라고 합니다.
잔차 블록을 사용하면 입력이 레이어를 가로질러 잔차 연결을 통해 더 빠르게 순전파될 수 있습니다.
사실,
잔차 블록은 다중 분기 Inception 블록의 특수한 경우로 생각할 수 있습니다:
그중 하나가 항등 매핑인 두 개의 분기가 있습니다.</p>
<p><img src="../img/residual-block.svg" alt="일반 블록(왼쪽)에서 점선 상자 안의 부분은 매핑 $\mathit{f}(\mathbf{x})$를 직접 학습해야 합니다. 잔차 블록(오른쪽)에서 점선 상자 안의 부분은 잔차 매핑 $\mathit{g}(\mathbf{x}) = \mathit{f}(\mathbf{x}) - \mathbf{x}$를 학습해야 하므로 항등 매핑 $\mathit{f}(\mathbf{x}) = \mathbf{x}$를 학습하기가 더 쉽습니다." />
:label:<code>fig_residual_block</code></p>
<p>ResNet은 VGG의 전체 $3\times 3$ 합성곱 레이어 설계를 가지고 있습니다. 잔차 블록에는 동일한 수의 출력 채널을 가진 두 개의 $3\times 3$ 합성곱 레이어가 있습니다. 각 합성곱 레이어 뒤에는 배치 정규화 레이어와 ReLU 활성화 함수가 옵니다. 그런 다음 이 두 합성곱 연산을 건너뛰고 최종 ReLU 활성화 함수 바로 앞에 입력을 직접 더합니다.
이러한 종류의 설계는 두 합성곱 레이어의 출력이 입력과 동일한 모양이어야 함께 더할 수 있음을 요구합니다. 채널 수를 변경하려면 덧셈 연산을 위해 입력을 원하는 모양으로 변환하는 추가 $1\times 1$ 합성곱 레이어를 도입해야 합니다. 아래 코드를 살펴보겠습니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
class Residual(nn.Block):  #@save
    """ResNet 모델의 잔차 블록."""
    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):
        super().__init__(**kwargs)
        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1,
                               strides=strides)
        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2D(num_channels, kernel_size=1,
                                   strides=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm()
        self.bn2 = nn.BatchNorm()

    def forward(self, X):
        Y = npx.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        return npx.relu(Y + X)
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
class Residual(nn.Module):  #@save
    """ResNet 모델의 잔차 블록."""
    def __init__(self, num_channels, use_1x1conv=False, strides=1):
        super().__init__()
        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,
                                   stride=strides)
        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,
                                       stride=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.LazyBatchNorm2d()
        self.bn2 = nn.LazyBatchNorm2d()

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return F.relu(Y)
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
class Residual(tf.keras.Model):  #@save
    """ResNet 모델의 잔차 블록."""
    def __init__(self, num_channels, use_1x1conv=False, strides=1):
        super().__init__()
        self.conv1 = tf.keras.layers.Conv2D(num_channels, padding='same',
                                            kernel_size=3, strides=strides)
        self.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=3,
                                            padding='same')
        self.conv3 = None
        if use_1x1conv:
            self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=1,
                                                strides=strides)
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.bn2 = tf.keras.layers.BatchNormalization()

    def call(self, X):
        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3 is not None:
            X = self.conv3(X)
        Y += X
        return tf.keras.activations.relu(Y)
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
class Residual(nn.Module):  #@save
    """ResNet 모델의 잔차 블록."""
    num_channels: int
    use_1x1conv: bool = False
    strides: tuple = (1, 1)
    training: bool = True

    def setup(self):
        self.conv1 = nn.Conv(self.num_channels, kernel_size=(3, 3),
                             padding='same', strides=self.strides)
        self.conv2 = nn.Conv(self.num_channels, kernel_size=(3, 3),
                             padding='same')
        if self.use_1x1conv:
            self.conv3 = nn.Conv(self.num_channels, kernel_size=(1, 1),
                                 strides=self.strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm(not self.training)
        self.bn2 = nn.BatchNorm(not self.training)

    def __call__(self, X):
        Y = nn.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return nn.relu(Y)
</code></pre>
<p>이 코드는 두 가지 유형의 네트워크를 생성합니다: <code>use_1x1conv=False</code>일 때마다 ReLU 비선형성을 적용하기 전에 입력을 출력에 더하는 것과, 더하기 전에 $1 \times 1$ 합성곱을 통해 채널과 해상도를 조정하는 것입니다. :numref:<code>fig_resnet_block</code>은 이를 보여줍니다.</p>
<p><img src="../img/resnet-block.svg" alt="덧셈 연산을 위해 입력을 원하는 모양으로 변환하는 $1 \times 1$ 합성곱이 있거나 없는 ResNet 블록." />
:label:<code>fig_resnet_block</code></p>
<p>이제 $1 \times 1$ 합성곱이 필요하지 않은 [<strong>입력과 출력의 모양이 같은 상황</strong>]을 살펴보겠습니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet, pytorch
if tab.selected('mxnet'):
    blk = Residual(3)
    blk.initialize()
if tab.selected('pytorch'):
    blk = Residual(3)
X = d2l.randn(4, 3, 6, 6)
blk(X).shape
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
blk = Residual(3)
X = d2l.normal((4, 6, 6, 3))
Y = blk(X)
Y.shape
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
blk = Residual(3)
X = jax.random.normal(d2l.get_key(), (4, 6, 6, 3))
blk.init_with_output(d2l.get_key(), X)[0].shape
</code></pre>
<p>[<strong>출력 채널 수를 늘리면서 출력 높이와 너비를 절반으로 줄이는</strong>] 옵션도 있습니다.
이 경우 <code>use_1x1conv=True</code>를 통해 $1 \times 1$ 합성곱을 사용합니다. 이것은 <code>strides=2</code>를 통해 공간 차원을 줄이기 위해 각 ResNet 블록의 시작 부분에서 유용합니다.</p>
<pre><code class="language-{.python .input}">%%tab pytorch, mxnet, tensorflow
blk = Residual(6, use_1x1conv=True, strides=2)
if tab.selected('mxnet'):
    blk.initialize()
blk(X).shape
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
blk = Residual(6, use_1x1conv=True, strides=(2, 2))
blk.init_with_output(d2l.get_key(), X)[0].shape
</code></pre>
<h2 id="resnet-모델"><a class="header" href="#resnet-모델">[<strong>ResNet 모델</strong>]</a></h2>
<p>ResNet의 처음 두 레이어는 앞서 설명한 GoogLeNet의 것과 동일합니다: 64개의 출력 채널과 스트라이드 2가 있는 $7\times 7$ 합성곱 레이어 다음에는 스트라이드 2가 있는 $3\times 3$ 최대 풀링 레이어가 이어집니다. 차이점은 ResNet의 각 합성곱 레이어 뒤에 추가된 배치 정규화 레이어입니다.</p>
<pre><code class="language-{.python .input}">%%tab pytorch, mxnet, tensorflow
class ResNet(d2l.Classifier):
    def b1(self):
        if tab.selected('mxnet'):
            net = nn.Sequential()
            net.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3),
                    nn.BatchNorm(), nn.Activation('relu'),
                    nn.MaxPool2D(pool_size=3, strides=2, padding=1))
            return net
        if tab.selected('pytorch'):
            return nn.Sequential(
                nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),
                nn.LazyBatchNorm2d(), nn.ReLU(),
                nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
        if tab.selected('tensorflow'):
            return tf.keras.models.Sequential([
                tf.keras.layers.Conv2D(64, kernel_size=7, strides=2,
                                       padding='same'),
                tf.keras.layers.BatchNormalization(),
                tf.keras.layers.Activation('relu'),
                tf.keras.layers.MaxPool2D(pool_size=3, strides=2,
                                          padding='same')])
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
class ResNet(d2l.Classifier):
    arch: tuple
    lr: float = 0.1
    num_classes: int = 10
    training: bool = True

    def setup(self):
        self.net = self.create_net()

    def b1(self):
        return nn.Sequential([
            nn.Conv(64, kernel_size=(7, 7), strides=(2, 2), padding='same'),
            nn.BatchNorm(not self.training), nn.relu,
            lambda x: nn.max_pool(x, window_shape=(3, 3), strides=(2, 2),
                                  padding='same')])
</code></pre>
<p>GoogLeNet은 Inception 블록으로 구성된 4개의 모듈을 사용합니다.
그러나 ResNet은 잔차 블록으로 구성된 4개의 모듈을 사용하며, 각 모듈은 동일한 수의 출력 채널을 가진 여러 잔차 블록을 사용합니다.
첫 번째 모듈의 채널 수는 입력 채널 수와 동일합니다. 스트라이드 2의 최대 풀링 레이어가 이미 사용되었으므로 높이와 너비를 줄일 필요가 없습니다. 후속 각 모듈의 첫 번째 잔차 블록에서 채널 수는 이전 모듈의 채널 수에 비해 두 배가 되고 높이와 너비는 반으로 줄어듭니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
@d2l.add_to_class(ResNet)
def block(self, num_residuals, num_channels, first_block=False):
    blk = nn.Sequential()
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.add(Residual(num_channels, use_1x1conv=True, strides=2))
        else:
            blk.add(Residual(num_channels))
    return blk
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
@d2l.add_to_class(ResNet)
def block(self, num_residuals, num_channels, first_block=False):
    blk = []
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.append(Residual(num_channels, use_1x1conv=True, strides=2))
        else:
            blk.append(Residual(num_channels))
    return nn.Sequential(*blk)
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
@d2l.add_to_class(ResNet)
def block(self, num_residuals, num_channels, first_block=False):
    blk = tf.keras.models.Sequential()
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.add(Residual(num_channels, use_1x1conv=True, strides=2))
        else:
            blk.add(Residual(num_channels))
    return blk
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
@d2l.add_to_class(ResNet)
def block(self, num_residuals, num_channels, first_block=False):
    blk = []
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.append(Residual(num_channels, use_1x1conv=True,
                                strides=(2, 2), training=self.training))
        else:
            blk.append(Residual(num_channels, training=self.training))
    return nn.Sequential(blk)
</code></pre>
<p>그런 다음 모든 모듈을 ResNet에 추가합니다. 여기서 각 모듈에는 두 개의 잔차 블록이 사용됩니다. 마지막으로 GoogLeNet과 마찬가지로 전역 평균 풀링 레이어를 추가하고 완전 연결 레이어 출력을 추가합니다.</p>
<pre><code class="language-{.python .input}">%%tab pytorch, mxnet, tensorflow
@d2l.add_to_class(ResNet)
def __init__(self, arch, lr=0.1, num_classes=10):
    super(ResNet, self).__init__()
    self.save_hyperparameters()
    if tab.selected('mxnet'):
        self.net = nn.Sequential()
        self.net.add(self.b1())
        for i, b in enumerate(arch):
            self.net.add(self.block(*b, first_block=(i==0)))
        self.net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))
        self.net.initialize(init.Xavier())
    if tab.selected('pytorch'):
        self.net = nn.Sequential(self.b1())
        for i, b in enumerate(arch):
            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))
        self.net.add_module('last', nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),
            nn.LazyLinear(num_classes)))
        self.net.apply(d2l.init_cnn)
    if tab.selected('tensorflow'):
        self.net = tf.keras.models.Sequential(self.b1())
        for i, b in enumerate(arch):
            self.net.add(self.block(*b, first_block=(i==0)))
        self.net.add(tf.keras.models.Sequential([
            tf.keras.layers.GlobalAvgPool2D(),
            tf.keras.layers.Dense(units=num_classes)]))
</code></pre>
<pre><code class="language-{.python .input}"># %%tab jax
@d2l.add_to_class(ResNet)
def create_net(self):
    net = nn.Sequential([self.b1()])
    for i, b in enumerate(self.arch):
        net.layers.extend([self.block(*b, first_block=(i==0))])
    net.layers.extend([nn.Sequential([
        # Flax는 GlobalAvg2D 레이어를 제공하지 않습니다
        lambda x: nn.avg_pool(x, window_shape=x.shape[1:3],
                              strides=x.shape[1:3], padding='valid'),
        lambda x: x.reshape((x.shape[0], -1)),
        nn.Dense(self.num_classes)])])
    return net
</code></pre>
<p>각 모듈에는 4개의 합성곱 레이어가 있습니다($1\times 1$ 합성곱 레이어 제외). 첫 번째 $7\times 7$ 합성곱 레이어와 마지막 완전 연결 레이어와 함께 총 18개의 레이어가 있습니다. 따라서 이 모델은 일반적으로 ResNet-18로 알려져 있습니다.
모듈에서 채널 수와 잔차 블록 수를 다르게 구성하여 더 깊은 152-레이어 ResNet-152와 같은 다양한 ResNet 모델을 만들 수 있습니다. ResNet의 주요 아키텍처는 GoogLeNet과 유사하지만 ResNet의 구조는 더 간단하고 수정하기 쉽습니다. 이러한 모든 요인으로 인해 ResNet은 빠르고 광범위하게 사용되었습니다. :numref:<code>fig_resnet18</code>은 전체 ResNet-18을 보여줍니다.</p>
<p><img src="../img/resnet18-90.svg" alt="ResNet-18 아키텍처." />
:label:<code>fig_resnet18</code></p>
<p>ResNet을 훈련하기 전에 [<strong>ResNet의 다양한 모듈에서 입력 모양이 어떻게 변하는지 관찰</strong>]해 보겠습니다. 모든 이전 아키텍처와 마찬가지로 전역 평균 풀링 레이어가 모든 특성을 집계하는 지점까지 해상도는 감소하는 반면 채널 수는 증가합니다.</p>
<pre><code class="language-{.python .input}">%%tab pytorch, mxnet, tensorflow
class ResNet18(ResNet):
    def __init__(self, lr=0.1, num_classes=10):
        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),
                       lr, num_classes)
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
class ResNet18(ResNet):
    arch: tuple = ((2, 64), (2, 128), (2, 256), (2, 512))
    lr: float = 0.1
    num_classes: int = 10
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch, mxnet
ResNet18().layer_summary((1, 1, 96, 96))
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
ResNet18().layer_summary((1, 96, 96, 1))
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
ResNet18(training=False).layer_summary((1, 96, 96, 1))
</code></pre>
<h2 id="훈련-training"><a class="header" href="#훈련-training">[<strong>훈련 (Training)</strong>]</a></h2>
<p>이전과 마찬가지로 Fashion-MNIST 데이터셋에서 ResNet을 훈련합니다. ResNet은 꽤 강력하고 유연한 아키텍처입니다. 훈련 및 검증 손실을 포착한 플롯은 두 그래프 사이에 상당한 격차를 보여주며 훈련 손실이 훨씬 낮습니다. 이 정도의 유연성을 가진 네트워크의 경우, 더 많은 훈련 데이터가 격차를 줄이고 정확도를 높이는 데 뚜렷한 이점을 제공할 것입니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet, pytorch, jax
model = ResNet18(lr=0.01)
trainer = d2l.Trainer(max_epochs=10, num_gpus=1)
data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))
if tab.selected('pytorch'):
    model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)
trainer.fit(model, data)
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
trainer = d2l.Trainer(max_epochs=10)
data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))
with d2l.try_gpu():
    model = ResNet18(lr=0.01)
    trainer.fit(model, data)
</code></pre>
<h2 id="resnext"><a class="header" href="#resnext">ResNeXt</a></h2>
<p>:label:<code>subsec_resnext</code></p>
<p>ResNet 설계에서 직면하는 과제 중 하나는 주어진 블록 내에서 비선형성과 차원성 사이의 트레이드오프입니다. 즉, 레이어 수를 늘리거나 합성곱의 너비를 늘려 비선형성을 더할 수 있습니다. 대안 전략은 블록 간에 정보를 전달할 수 있는 채널 수를 늘리는 것입니다. 불행히도 후자는 $c_\textrm{i}$ 채널을 섭취하고 $c_\textrm{o}$ 채널을 방출하는 계산 비용이 $\mathcal{O}(c_\textrm{i} \cdot c_\textrm{o})$에 비례하므로 이차적 페널티가 따릅니다(:numref:<code>sec_channels</code>의 논의 참조).</p>
<p>:numref:<code>fig_inception</code>의 Inception 블록에서 영감을 얻을 수 있습니다. 정보가 별도의 그룹으로 블록을 통해 흐릅니다. 다중 독립 그룹 아이디어를 :numref:<code>fig_resnet_block</code>의 ResNet 블록에 적용하여 ResNeXt의 설계가 이루어졌습니다 :cite:<code>Xie.Girshick.Dollar.ea.2017</code>.
다른 점은 Inception의 뒤죽박죽 변환과 달리,
ResNeXt는 모든 분기에서 <em>동일한</em> 변환을 채택하여 각 분기의 수동 튜닝 필요성을 최소화합니다.</p>
<p><img src="../img/resnext-block.svg" alt="ResNeXt 블록. $\mathit{g}$ 그룹이 있는 그룹화된 합성곱을 사용하는 것은 조밀한 합성곱보다 $\mathit{g}$배 빠릅니다. 중간 채널 수 $\mathit{b}$가 $\mathit{c}$보다 작으면 병목 잔차 블록입니다." />
:label:<code>fig_resnext_block</code></p>
<p>$c_\textrm{i}$에서 $c_\textrm{o}$ 채널로의 합성곱을 $c_\textrm{i}/g$ 크기의 $g$ 그룹 중 하나로 나누어 $c_\textrm{o}/g$ 크기의 $g$ 출력을 생성하는 것을 적절하게도 *그룹화된 합성곱(grouped convolution)*이라고 합니다. 계산 비용(비례적으로)은 $\mathcal{O}(c_\textrm{i} \cdot c_\textrm{o})$에서 $\mathcal{O}(g \cdot (c_\textrm{i}/g) \cdot (c_\textrm{o}/g)) = \mathcal{O}(c_\textrm{i} \cdot c_\textrm{o} / g)$로 줄어듭니다. 즉, $g$배 더 빠릅니다. 더 좋은 점은 출력을 생성하는 데 필요한 파라미터 수도 $c_\textrm{i} \times c_\textrm{o}$ 행렬에서 $(c_\textrm{i}/g) \times (c_\textrm{o}/g)$ 크기의 $g$개의 더 작은 행렬로 줄어들어 역시 $g$배 감소한다는 것입니다. 다음에서는 $c_\textrm{i}$와 $c_\textrm{o}$가 모두 $g$로 나누어떨어진다고 가정합니다.</p>
<p>이 설계의 유일한 과제는 $g$ 그룹 간에 정보가 교환되지 않는다는 것입니다. :numref:<code>fig_resnext_block</code>의 ResNeXt 블록은 두 가지 방식으로 이를 수정합니다: $3 \times 3$ 커널을 사용한 그룹화된 합성곱이 두 개의 $1 \times 1$ 합성곱 사이에 끼어 있습니다. 두 번째 것은 채널 수를 다시 변경하는 이중 역할을 합니다. 이점은 $1 \times 1$ 커널에 대해 $\mathcal{O}(c \cdot b)$ 비용만 지불하고 $3 \times 3$ 커널에 대해 $\mathcal{O}(b^2 / g)$ 비용으로 해결할 수 있다는 것입니다. :numref:<code>subsec_residual-blks</code>의 잔차 블록 구현과 유사하게 잔차 연결은 $1 \times 1$ 합성곱으로 대체(따라서 일반화)됩니다.</p>
<p>:numref:<code>fig_resnext_block</code>의 오른쪽 그림은 결과 네트워크 블록에 대한 훨씬 더 간결한 요약을 제공합니다. 이것은 또한 :numref:<code>sec_cnn-design</code>의 일반적인 현대 CNN 설계에서 중요한 역할을 할 것입니다. 그룹화된 합성곱 아이디어는 AlexNet 구현 :cite:<code>Krizhevsky.Sutskever.Hinton.2012</code>으로 거슬러 올라갑니다. 제한된 메모리를 가진 두 개의 GPU에 네트워크를 분산할 때 구현은 각 GPU를 부작용 없이 자체 채널로 처리했습니다.</p>
<p><code>ResNeXtBlock</code> 클래스의 다음 구현은 <code>groups</code> ($g$)를 인수로 취하며, <code>bot_channels</code> ($b$) 중간(병목) 채널을 갖습니다. 마지막으로 표현의 높이와 너비를 줄여야 할 때 <code>use_1x1conv=True, strides=2</code>로 설정하여 스트라이드 $2$를 추가합니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
class ResNeXtBlock(nn.Block):  #@save
    """ResNeXt 블록."""
    def __init__(self, num_channels, groups, bot_mul,
                 use_1x1conv=False, strides=1, **kwargs):
        super().__init__(**kwargs)
        bot_channels = int(round(num_channels * bot_mul))
        self.conv1 = nn.Conv2D(bot_channels, kernel_size=1, padding=0,
                               strides=1)
        self.conv2 = nn.Conv2D(bot_channels, kernel_size=3, padding=1, 
                               strides=strides, groups=bot_channels//groups)
        self.conv3 = nn.Conv2D(num_channels, kernel_size=1, padding=0,
                               strides=1)
        self.bn1 = nn.BatchNorm()
        self.bn2 = nn.BatchNorm()
        self.bn3 = nn.BatchNorm()
        if use_1x1conv:
            self.conv4 = nn.Conv2D(num_channels, kernel_size=1,
                                   strides=strides)
            self.bn4 = nn.BatchNorm()
        else:
            self.conv4 = None

    def forward(self, X):
        Y = npx.relu(self.bn1(self.conv1(X)))
        Y = npx.relu(self.bn2(self.conv2(Y)))
        Y = self.bn3(self.conv3(Y))
        if self.conv4:
            X = self.bn4(self.conv4(X))
        return npx.relu(Y + X)
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
class ResNeXtBlock(nn.Module):  #@save
    """ResNeXt 블록."""
    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,
                 strides=1):
        super().__init__()
        bot_channels = int(round(num_channels * bot_mul))
        self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)
        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,
                                   stride=strides, padding=1,
                                   groups=bot_channels//groups)
        self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)
        self.bn1 = nn.LazyBatchNorm2d()
        self.bn2 = nn.LazyBatchNorm2d()
        self.bn3 = nn.LazyBatchNorm2d()
        if use_1x1conv:
            self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1, 
                                       stride=strides)
            self.bn4 = nn.LazyBatchNorm2d()
        else:
            self.conv4 = None

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = F.relu(self.bn2(self.conv2(Y)))
        Y = self.bn3(self.conv3(Y))
        if self.conv4:
            X = self.bn4(self.conv4(X))
        return F.relu(Y + X)
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
class ResNeXtBlock(tf.keras.Model):  #@save
    """ResNeXt 블록."""
    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,
                 strides=1):
        super().__init__()
        bot_channels = int(round(num_channels * bot_mul))
        self.conv1 = tf.keras.layers.Conv2D(bot_channels, 1, strides=1)
        self.conv2 = tf.keras.layers.Conv2D(bot_channels, 3, strides=strides,
                                            padding="same",
                                            groups=bot_channels//groups)
        self.conv3 = tf.keras.layers.Conv2D(num_channels, 1, strides=1)
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.bn3 = tf.keras.layers.BatchNormalization()
        if use_1x1conv:
            self.conv4 = tf.keras.layers.Conv2D(num_channels, 1,
                                                strides=strides)
            self.bn4 = tf.keras.layers.BatchNormalization()
        else:
            self.conv4 = None

    def call(self, X):
        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))
        Y = tf.keras.activations.relu(self.bn2(self.conv2(Y)))
        Y = self.bn3(self.conv3(Y))
        if self.conv4:
            X = self.bn4(self.conv4(X))
        return tf.keras.activations.relu(Y + X)
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
class ResNeXtBlock(nn.Module):  #@save
    """ResNeXt 블록."""
    num_channels: int
    groups: int
    bot_mul: int
    use_1x1conv: bool = False
    strides: tuple = (1, 1)
    training: bool = True

    def setup(self):
        bot_channels = int(round(self.num_channels * self.bot_mul))
        self.conv1 = nn.Conv(bot_channels, kernel_size=(1, 1),
                               strides=(1, 1))
        self.conv2 = nn.Conv(bot_channels, kernel_size=(3, 3),
                               strides=self.strides, padding='same',
                               feature_group_count=bot_channels//self.groups)
        self.conv3 = nn.Conv(self.num_channels, kernel_size=(1, 1),
                               strides=(1, 1))
        self.bn1 = nn.BatchNorm(not self.training)
        self.bn2 = nn.BatchNorm(not self.training)
        self.bn3 = nn.BatchNorm(not self.training)
        if self.use_1x1conv:
            self.conv4 = nn.Conv(self.num_channels, kernel_size=(1, 1),
                                       strides=self.strides)
            self.bn4 = nn.BatchNorm(not self.training)
        else:
            self.conv4 = None

    def __call__(self, X):
        Y = nn.relu(self.bn1(self.conv1(X)))
        Y = nn.relu(self.bn2(self.conv2(Y)))
        Y = self.bn3(self.conv3(Y))
        if self.conv4:
            X = self.bn4(self.conv4(X))
        return nn.relu(Y + X)
</code></pre>
<p>사용법은 앞에서 논의한 <code>ResNetBlock</code>의 사용법과 전적으로 유사합니다. 예를 들어 (<code>use_1x1conv=False, strides=1</code>)을 사용하면 입력과 출력의 모양이 같습니다. 대안으로 <code>use_1x1conv=True, strides=2</code>를 설정하면 출력 높이와 너비가 절반으로 줄어듭니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet, pytorch
blk = ResNeXtBlock(32, 16, 1)
if tab.selected('mxnet'):
    blk.initialize()
X = d2l.randn(4, 32, 96, 96)
blk(X).shape
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
blk = ResNeXtBlock(32, 16, 1)
X = d2l.normal((4, 96, 96, 32))
Y = blk(X)
Y.shape
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
blk = ResNeXtBlock(32, 16, 1)
X = jnp.zeros((4, 96, 96, 32))
blk.init_with_output(d2l.get_key(), X)[0].shape
</code></pre>
<h2 id="요약-및-토론-summary-and-discussion"><a class="header" href="#요약-및-토론-summary-and-discussion">요약 및 토론 (Summary and Discussion)</a></h2>
<p>중첩된 함수 클래스는 용량을 추가할 때 미묘하게 <em>다른</em> 함수 클래스 대신 엄격하게 <em>더 강력한</em> 함수 클래스를 얻을 수 있도록 하므로 바람직합니다. 이를 달성하는 한 가지 방법은 추가 레이어가 단순히 입력을 출력으로 통과시키도록 하는 것입니다. 잔차 연결은 이를 가능하게 합니다. 결과적으로 이는 단순 함수의 귀납적 편향을 $f(\mathbf{x}) = 0$ 형태에서 $f(\mathbf{x}) = \mathbf{x}$와 같은 형태로 변경합니다.</p>
<p>잔차 매핑은 가중치 레이어의 파라미터를 0으로 미는 것과 같이 항등 함수를 더 쉽게 학습할 수 있습니다. 우리는 잔차 블록을 사용하여 효과적인 <em>심층</em> 신경망을 훈련할 수 있습니다. 입력은 레이어 전체의 잔차 연결을 통해 더 빠르게 순전파될 수 있습니다. 결과적으로 훨씬 더 깊은 네트워크를 훈련할 수 있습니다. 예를 들어 원래 ResNet 논문 :cite:<code>He.Zhang.Ren.ea.2016</code>은 최대 152개 레이어를 허용했습니다. 잔차 네트워크의 또 다른 이점은 훈련 과정 <em>중</em>에 항등 함수로 초기화된 레이어를 추가할 수 있다는 것입니다. 결국 레이어의 기본 동작은 데이터를 변경하지 않고 통과시키는 것입니다. 이는 경우에 따라 매우 큰 네트워크의 훈련을 가속화할 수 있습니다.</p>
<p>잔차 연결 이전에,
게이팅 유닛이 있는 우회 경로가 도입되어
100개 이상의 레이어를 가진 고속도로 네트워크를 효과적으로 훈련했습니다
:cite:<code>srivastava2015highway</code>.
우회 경로로 항등 함수를 사용하여
ResNet은 여러 컴퓨터 비전 작업에서 놀라울 정도로 잘 수행되었습니다.
잔차 연결은 합성곱 또는 순차적 성격의 후속 심층 신경망 설계에 큰 영향을 미쳤습니다.
나중에 소개하겠지만,
Transformer 아키텍처 :cite:<code>Vaswani.Shazeer.Parmar.ea.2017</code>는
잔차 연결을 채택(다른 설계 선택과 함께)하며
언어, 비전, 음성, 강화 학습과 같이 다양한 분야에
널리 퍼져 있습니다.</p>
<p>ResNeXt는 합성곱 신경망 설계가 시간이 지남에 따라 어떻게 진화했는지 보여주는 예입니다: 계산을 더 절약하고 활성화 크기(채널 수)와 절충함으로써 저렴한 비용으로 더 빠르고 정확한 네트워크를 가능하게 합니다. 그룹화된 합성곱을 보는 다른 방법은 합성곱 가중치에 대한 블록 대각 행렬을 생각하는 것입니다. 더 효율적인 네트워크로 이어지는 꽤 많은 "트릭"이 있다는 점에 유의하십시오. 예를 들어 ShiftNet :cite:<code>wu2018shift</code>은 단순히 채널에 이동된 활성화를 추가하여 $3 \times 3$ 합성곱의 효과를 모방하여 이번에는 계산 비용 없이 향상된 함수 복잡성을 제공합니다.</p>
<p>지금까지 논의한 설계의 공통적인 특징은 네트워크 설계가 상당히 수동적이며 주로 "올바른" 네트워크 하이퍼파라미터를 찾기 위해 설계자의 독창성에 의존한다는 것입니다. 분명히 실현 가능하지만 인간 시간 측면에서 비용이 많이 들고 결과가 어떤 의미에서 최적이라는 보장이 없습니다. :numref:<code>sec_cnn-design</code>에서는 더 자동화된 방식으로 고품질 네트워크를 얻기 위한 여러 전략을 논의할 것입니다. 특히 RegNetX/Y 모델 :cite:<code>Radosavovic.Kosaraju.Girshick.ea.2020</code>로 이어진 <em>네트워크 설계 공간</em>의 개념을 검토할 것입니다.</p>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>:numref:<code>fig_inception</code>의 Inception 블록과 잔차 블록의 주요 차이점은 무엇입니까? 계산, 정확도, 설명할 수 있는 함수 클래스 측면에서 어떻게 비교됩니까?</li>
<li>네트워크의 다양한 변형을 구현하려면 ResNet 논문 :cite:<code>He.Zhang.Ren.ea.2016</code>의 표 1을 참조하십시오.</li>
<li>더 깊은 네트워크를 위해 ResNet은 모델 복잡성을 줄이기 위해 "병목" 아키텍처를 도입합니다. 구현해 보십시오.</li>
<li>ResNet의 후속 버전에서 저자는 "합성곱, 배치 정규화, 활성화" 구조를 "배치 정규화, 활성화, 합성곱" 구조로 변경했습니다. 이 개선을 직접 수행하십시오. 자세한 내용은 :citet:<code>He.Zhang.Ren.ea.2016*1</code>의 그림 1을 참조하십시오.</li>
<li>함수 클래스가 중첩되더라도 왜 함수의 복잡성을 무한정 늘릴 수 없습니까?</li>
</ol>
<p>:begin_tab:<code>mxnet</code>
<a href="https://discuss.d2l.ai/t/85">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/86">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>tensorflow</code>
<a href="https://discuss.d2l.ai/t/8737">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>jax</code>
<a href="https://discuss.d2l.ai/t/18006">토론</a>
:end_tab:</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_convolutional-modern/batch-norm.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_convolutional-modern/densenet.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_convolutional-modern/batch-norm.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_convolutional-modern/densenet.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
