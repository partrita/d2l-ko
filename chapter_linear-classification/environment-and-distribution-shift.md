# 환경과 분포 이동 (Environment and Distribution Shift)
:label:`sec_environment-and-distribution-shift`

이전 섹션들에서 우리는 다양한 데이터셋에 모델을 맞추며 머신러닝의 여러 실습 응용 사례를 살펴보았습니다. 하지만 데이터가 애초에 어디에서 왔는지, 혹은 모델의 출력으로 궁극적으로 무엇을 하려는지에 대해서는 한 번도 멈춰 서서 생각해보지 않았습니다. 데이터를 가진 머신러닝 개발자들은 이러한 근본적인 문제를 고려하기 위해 멈추지 않고 모델 개발에 서두르는 경우가 너무 많습니다.

실패한 많은 머신러닝 배포 사례가 이러한 고려의 부재로 거슬러 올라갈 수 있습니다. 때때로 모델은 테스트 세트 정확도로 측정했을 때 훌륭하게 수행되는 것처럼 보이지만, 데이터 분포가 갑자기 바뀌는 배포 상황에서는 처참하게 실패합니다. 더 교묘하게는, 모델의 배포 자체가 데이터 분포를 교란시키는 촉매제가 될 수도 있습니다. 예를 들어, 대출을 갚을 사람과 연체할 사람을 예측하도록 모델을 훈련시켰는데, 신청자의 신발 선택이 연체 위험과 관련이 있다는 것을 발견했다고 가정해 봅시다(옥스퍼드화는 상환을, 운동화는 연체를 나타냄). 이후 우리는 옥스퍼드화를 신은 모든 신청자에게 대출을 승인하고 운동화를 신은 모든 신청자에게 거절하고 싶어질 수도 있습니다.

이 경우, 패턴 인식에서 의사 결정으로의 신중하지 못한 도약과 환경에 대한 비판적 고려의 부재는 재앙적인 결과를 초래할 수 있습니다. 우선, 우리가 신발을 기준으로 결정을 내리기 시작하자마자 고객들은 이를 알아차리고 행동을 바꿀 것입니다. 머지않아 신용도에 어떠한 개선도 없이 모든 신청자가 옥스퍼드화를 신게 될 것입니다. 이를 이해하기 위해 잠시 시간을 내어 보십시오. 머신러닝의 많은 응용 분야에서 유사한 문제가 넘쳐나기 때문입니다: 환경에 모델 기반 결정을 도입함으로써 모델을 망가뜨릴 수 있습니다.

우리가 한 섹션에서 이러한 주제를 완벽하게 다룰 수는 없지만, 여기서는 일반적인 우려 사항들을 드러내고 이러한 상황을 조기에 감지하고 피해를 완화하며 머신러닝을 책임감 있게 사용하는 데 필요한 비판적 사고를 자극하는 것을 목표로 합니다. 해결책 중 일부는 간단하지만("올바른" 데이터를 요청하기), 일부는 기술적으로 어렵고(강화 학습 시스템 구현), 또 다른 일부는 통계적 예측의 영역을 벗어나 알고리즘의 윤리적 적용에 관한 어려운 철학적 질문들과 씨름해야 합니다.

## 분포 이동의 유형 (Types of Distribution Shift)

먼저, 데이터 분포가 바뀔 수 있는 다양한 방식과 모델 성능을 구제하기 위해 무엇을 할 수 있는지 고려하며 수동적인 예측 설정을 고수해 봅시다. 고전적인 설정 중 하나에서, 우리는 훈련 데이터가 어떤 분포 $p_S(\mathbf{x},y)$에서 샘플링되었지만 테스트 데이터는 어떤 다른 분포 $p_T(\mathbf{x},y)$에서 추출된 레이블 없는 예제들로 구성될 것이라고 가정합니다. 이미 우리는 냉혹한 현실에 직면해야 합니다. $p_S$와 $p_T$가 서로 어떻게 관련되어 있는지에 대한 가정이 없다면 강건한 분류기를 학습하는 것은 불가능합니다.

개와 고양이를 구별하려는 이진 분류 문제를 생각해 보십시오. 분포가 임의의 방식으로 바뀔 수 있다면, 입력에 대한 분포는 일정하지만($p_S(\mathbf{x}) = p_T(\mathbf{x})$) 레이블이 모두 뒤집히는($p_S(y \mid \mathbf{x}) = 1 - p_T(y \mid \mathbf{x})$) 병적인 경우를 허용하게 됩니다. 다시 말해, 신이 갑자기 미래의 모든 "고양이"는 이제 개이고 우리가 이전에 "개"라고 불렀던 것은 이제 고양이라고 결정한다면(입력 분포 $p(\mathbf{x})$의 변화 없이), 우리는 이 설정을 분포가 전혀 바뀌지 않은 설정과 구별할 수 없습니다.

다행히 미래에 데이터가 변할 수 있는 방식에 대한 몇 가지 제한적인 가정 하에서, 원칙에 입각한 알고리즘은 변화를 감지하고 때로는 즉석에서 적응하여 원래 분류기의 정확도를 향상시킬 수 있습니다.

### 공변량 이동 (Covariate Shift)

분포 이동의 범주 중에서 공변량 이동(covariate shift)이 가장 널리 연구되었을 것입니다. 여기서 우리는 입력의 분포는 시간이 지남에 따라 변할 수 있지만, 레이블링 함수 즉 조건부 분포 $P(y \mid \mathbf{x})$는 변하지 않는다고 가정합니다. 통계학자들은 이 문제가 공변량(특성) 분포의 변화로 인해 발생하기 때문에 이를 *공변량 이동*이라고 부릅니다. 인과 관계를 끌어들이지 않고도 분포 이동에 대해 추론할 수 있는 경우도 있지만, 공변량 이동은 $\mathbf{x}$가 $y$를 유발한다고 믿는 설정에서 호출하기에 자연스러운 가정입니다.

개와 고양이를 구별하는 도전을 고려해 보십시오. 우리의 훈련 데이터는 :numref:`fig_cat-dog-train`과 같은 이미지들로 구성될 수 있습니다.

![개와 고양이를 구별하기 위한 훈련 데이터 (그림: Lafeez Hossain / 500px / Getty Images; ilkermetinkursova / iStock / Getty Images Plus; GlobalP / iStock / Getty Images Plus; Musthafa Aboobakuru / 500px / Getty Images).](../img/cat-dog-train.png)
:label:`fig_cat-dog-train`


테스트 시에 우리는 :numref:`fig_cat-dog-test`에 있는 이미지들을 분류하라는 요청을 받습니다.

![개와 고양이를 구별하기 위한 테스트 데이터 (그림: SIBAS_minich / iStock / Getty Images Plus; Ghrzuzudu / iStock / Getty Images Plus; id-work / DigitalVision Vectors / Getty Images; Yime / iStock / Getty Images Plus).](../img/cat-dog-test.png)
:label:`fig_cat-dog-test`

훈련 세트는 사진으로 구성된 반면 테스트 세트는 만화만 포함하고 있습니다. 새로운 도메인에 어떻게 적응할 것인지에 대한 일관된 계획 없이 테스트 세트와 상당히 다른 특성을 가진 데이터셋에서 훈련하는 것은 문제를 일으킬 수 있습니다.

### 레이블 이동 (Label Shift)

*레이블 이동(Label shift)*은 반대 문제를 설명합니다. 여기서 우리는 레이블 주변 분포 $P(y)$는 바뀔 수 있지만 클래스 조건부 분포 $P(\mathbf{x} \mid y)$는 도메인 간에 고정되어 있다고 가정합니다. 레이블 이동은 $y$가 $\mathbf{x}$를 유발한다고 믿을 때 내리기 합리적인 가정입니다. 예를 들어, 진단의 상대적 유병률이 시간이 지남에 따라 변하더라도 증상(또는 다른 징후)이 주어졌을 때 진단을 예측하고 싶을 수 있습니다. 질병이 증상을 유발하기 때문에 여기서 레이블 이동이 적절한 가정입니다. 일부 퇴행적인 경우에는 레이블 이동과 공변량 이동 가정이 동시에 성립할 수 있습니다. 예를 들어 레이블이 결정론적일 때 $y$가 $\mathbf{x}$를 유발하더라도 공변량 이동 가정이 충족될 것입니다. 흥미롭게도 이러한 경우 레이블 이동 가정에서 비롯된 방법으로 작업하는 것이 종종 유리합니다. 딥러닝에서 입력처럼 보이는 객체(종종 고차원)와 대조적으로 레이블처럼 보이는 객체(종종 저차원)를 조작하는 경향이 있기 때문입니다.

### 개념 이동 (Concept Shift)

우리는 레이블의 정의 자체가 바뀔 수 있을 때 발생하는 관련 문제인 *개념 이동(concept shift)*에 직면할 수도 있습니다. 이것은 이상하게 들릴 수 있습니다. 고양이는 고양이 아닌가요? 하지만 다른 범주들은 시간이 지남에 따라 사용법이 변할 수 있습니다. 정신 질환에 대한 진단 기준, 유행하는 것, 직함 등은 모두 상당한 양의 개념 이동을 겪습니다. 미국 전역을 돌아다니며 지리에 따라 데이터 소스를 옮겨보면, :numref:`fig_popvssoda`에 표시된 것처럼 *탄산음료*의 이름 분포에 관한 상당한 개념 이동을 발견하게 될 것입니다.

![미국 내 탄산음료 명칭에 대한 개념 이동 (CC-BY: Alan McConchie, PopVsSoda.com).](../img/popvssoda.png)
:width:`400px`
:label:`fig_popvssoda`

만약 우리가 기계 번역 시스템을 구축한다면 분포 $P(y \mid \mathbf{x})$는 우리 위치에 따라 달라질 수 있습니다. 이 문제는 발견하기 까다로울 수 있습니다. 변화가 시간적 또는 지리적 의미에서 점진적으로만 일어난다는 지식을 활용할 수 있기를 바랄 수 있습니다.

## 분포 이동의 예시 (Examples of Distribution Shift)

형식주의와 알고리즘을 탐구하기 전에, 공변량이나 개념 이동이 명확하지 않을 수 있는 몇 가지 구체적인 상황을 논의해 보겠습니다.


### 의료 진단 (Medical Diagnostics)

암을 탐지하는 알고리즘을 설계하고 싶다고 상상해 보십시오. 건강한 사람과 아픈 사람으로부터 데이터를 수집하고 알고리즘을 훈련합니다. 잘 작동하여 높은 정확도를 제공하며 여러분은 의료 진단 분야에서 성공적인 경력을 쌓을 준비가 되었다고 결론 내립니다. *잠시만요.*

훈련 데이터를 생성한 분포와 실제 현장에서 마주하게 될 분포는 상당히 다를 수 있습니다. 수년 전 우리 저자들 중 일부와 함께 일했던 불운한 스타트업에 이런 일이 일어났습니다. 그들은 주로 노인 남성에게 영향을 미치는 질병에 대한 혈액 검사를 개발하고 있었고 환자들로부터 수집한 혈액 샘플을 사용하여 이를 연구하기를 원했습니다. 하지만 이미 시스템에 있는 아픈 환자들보다 건강한 남성들로부터 혈액 샘플을 얻는 것이 훨씬 더 어렵습니다. 이를 보완하기 위해 스타트업은 대학 캠퍼스의 학생들로부터 혈액 기증을 받아 검사 개발의 건강한 대조군으로 사용했습니다. 그러고 나서 우리에게 질병을 탐지하기 위한 분류기를 구축하는 데 도움을 줄 수 있는지 물었습니다.

우리가 그들에게 설명했듯이, 건강한 집단과 아픈 집단을 거의 완벽한 정확도로 구별하는 것은 실제로 쉬운 일일 것입니다. 하지만 그것은 실험 대상자들이 나이, 호르몬 수치, 신체 활동, 식단, 알코올 섭취량, 그리고 질병과 무관한 더 많은 요인에서 차이가 났기 때문입니다. 실제 환자들의 경우에는 그렇지 않을 가능성이 높았습니다. 그들의 샘플링 절차 때문에 우리는 극단적인 공변량 이동을 예상할 수 있었습니다. 게다가 이 사례는 일반적인 방법으로는 교정될 가능성이 낮았습니다. 요컨대 그들은 상당한 액수의 돈을 낭비했습니다.



### 자율 주행차 (Self-Driving Cars)

어떤 회사가 자율 주행차 개발을 위해 머신러닝을 활용하고 싶어 한다고 합시다. 여기서 핵심 구성 요소 중 하나는 도로변 감지기입니다. 실제 주석이 달린 데이터는 얻기 비싸기 때문에, 그들은 게임 렌더링 엔진의 합성 데이터를 추가 훈련 데이터로 사용하겠다는 (똑똑하지만 의심스러운) 아이디어를 냈습니다. 이는 렌더링 엔진에서 추출한 "테스트 데이터"에서는 정말 잘 작동했습니다. 아뿔싸, 실제 차 안에서는 재앙이었습니다. 알고 보니 도로변이 매우 단순한 텍스처로 렌더링되어 있었습니다. 더 중요한 것은 *모든* 도로변이 *동일한* 텍스처로 렌더링되어 있었고 도로변 감지기는 이 "특성"을 매우 빠르게 학습해버린 것이었습니다.

미군이 숲속의 탱크를 처음 탐지하려고 했을 때도 비슷한 일이 일어났습니다. 그들은 탱크가 없는 숲의 항공 사진을 찍은 다음, 탱크를 숲으로 운전해 들여보내고 또 다른 사진 세트를 찍었습니다. 분류기는 *완벽하게* 작동하는 것처럼 보였습니다. 불행히도 그것은 단순히 그림자가 있는 나무와 그림자가 없는 나무를 구별하는 법을 배운 것뿐이었습니다. 첫 번째 사진 세트는 이른 아침에 찍혔고 두 번째 세트는 정오에 찍혔기 때문입니다.

### 비정상 분포 (Nonstationary Distributions)

분포가 천천히 변하고(비정상 분포, nonstationary distribution라고도 함) 모델이 적절하게 업데이트되지 않을 때 훨씬 더 미묘한 상황이 발생합니다. 다음은 몇 가지 전형적인 사례입니다.

* 전산 광고 모델을 훈련시킨 후 자주 업데이트하지 않는 경우(예: iPad라는 생소한 새 기기가 막 출시되었다는 사실을 반영하는 것을 잊음).
* 스팸 필터를 구축합니다. 지금까지 본 모든 스팸을 탐지하는 데는 잘 작동합니다. 하지만 스팸 메일 발송자들이 영리해져서 우리가 이전에 본 적 없는 새로운 메시지를 만들어냅니다.
* 제품 추천 시스템을 구축합니다. 겨울 내내 잘 작동하다가 크리스마스가 한참 지난 후에도 계속 산타 모자를 추천합니다.

### 더 많은 일화들

* 얼굴 감지기를 구축합니다. 모든 벤치마크에서 잘 작동합니다. 불행히도 테스트 데이터에서는 실패합니다. 문제가 되는 예제는 얼굴이 전체 이미지를 채우는 근접 촬영 사진들입니다(훈련 세트에는 그런 데이터가 없었습니다).
* 미국 시장용 웹 검색 엔진을 구축하고 이를 영국에 배포하려고 합니다.
* 대규모 데이터셋을 컴파일하여 이미지 분류기를 훈련합니다. 여기서 방대한 클래스 집합 중 각각은 데이터셋에서 동일하게 대표됩니다. 예를 들어 1000개의 카테고리가 각각 1000개의 이미지로 표현됩니다. 그러고 나서 이 시스템을 실제 세계에 배포하는데, 실제 사진의 레이블 분포는 분명히 불균등합니다.






## 분포 이동의 교정 (Correction of Distribution Shift)

우리가 논의했듯이 훈련 및 테스트 분포 $P(\mathbf{x}, y)$가 다른 경우가 많습니다. 어떤 경우에는 운이 좋아 공변량, 레이블 또는 개념 이동에도 불구하고 모델이 작동합니다. 다른 경우에는 이동에 대처하기 위한 원칙적인 전략을 채택함으로써 더 잘할 수 있습니다. 이 섹션의 나머지는 상당히 더 기술적으로 변합니다. 성급한 독자는 이 내용이 이후 개념의 전제 조건이 아니므로 다음 섹션으로 넘어가도 좋습니다.

### 경험적 위험과 위험 (Empirical Risk and Risk)
:label:`subsec_empirical-risk-and-risk`

먼저 모델 훈련 중에 정확히 무슨 일이 일어나고 있는지 되새겨 봅시다: 우리는 훈련 데이터 $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$의 특성과 관련 레이블을 반복하며 매 미니배치 후에 모델 $f$의 파라미터를 업데이트합니다. 단순함을 위해 정규화는 고려하지 않으므로 주로 훈련에서의 손실을 최소화합니다:

$$\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n l(f(\mathbf{x}_i), y_i),$$
:eqlabel:`eq_empirical-risk-min`

여기서 $l$은 관련 레이블 $y_i$가 주어졌을 때 예측 $f(\mathbf{x}_i)$가 "얼마나 나쁜지" 측정하는 손실 함수입니다. 통계학자들은 :eqref:`eq_empirical-risk-min`의 항을 *경험적 위험(empirical risk)*이라고 부릅니다. *경험적 위험*은 실제 분포 $p(\mathbf{x},y)$에서 추출된 전체 데이터 모집단에 대한 손실의 기댓값인 *위험(risk)*을 근사하기 위한 훈련 데이터에 대한 평균 손실입니다:

$$E_{p(\mathbf{x}, y)} [l(f(\mathbf{x}), y)] = \int\int l(f(\mathbf{x}), y) p(\mathbf{x}, y) \;d\mathbf{x}dy.$$
:eqlabel:`eq_true-risk`

하지만 실제로는 일반적으로 전체 데이터 모집단을 얻을 수 없습니다. 따라서 :eqref:`eq_empirical-risk-min`에서 경험적 위험을 최소화하는 *경험적 위험 최소화(empirical risk minimization)*는 위험을 대략적으로 최소화하기를 바라는 머신러닝의 실질적인 전략입니다.



### 공변량 이동 교정 (Covariate Shift Correction)
:label:`subsec_covariate-shift-correction`

레이블이 지정된 데이터 $(\mathbf{x}_i, y_i)$가 있는 어떤 종속성 $P(y \mid \mathbf{x})$를 추정하고 싶다고 가정해 봅시다. 불행히도 관찰값 $\mathbf{x}_i$는 *타겟 분포* $p(\mathbf{x})$가 아닌 어떤 *소스 분포* $q(\mathbf{x})$에서 추출되었습니다. 다행히 종속성 가정은 조건부 분포가 변하지 않음을 의미합니다: $p(y \mid \mathbf{x}) = q(y \mid \mathbf{x})$. 소스 분포 $q(\mathbf{x})$가 "틀렸다면", 위험에서 다음과 같은 간단한 항등식을 사용하여 이를 교정할 수 있습니다:

$$
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}
$$

즉, 우리는 각 데이터 예제에 대해 올바른 분포에서 추출되었을 확률과 잘못된 분포에서 추출되었을 확률의 비율로 가중치를 다시 부여해야 합니다:

$$\beta_i \stackrel{\textrm{def}}{=} \frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}.$$

각 데이터 예제 $(\mathbf{x}_i, y_i)$에 대해 가중치 $\beta_i$를 대입하면, *가중 경험적 위험 최소화(weighted empirical risk minimization)*를 사용하여 모델을 훈련할 수 있습니다:

$$\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n \beta_i l(f(\mathbf{x}_i), y_i).$$
:eqlabel:`eq_weighted-empirical-risk-min`



아쉽게도 우리는 그 비율을 모르기 때문에 유용한 일을 하기 전에 이를 추정해야 합니다. 최소 노름(minimum-norm)이나 최대 엔트로피 원리를 사용하여 기댓값 연산자를 직접 재조정하려는 몇 가지 화려한 연산자 이론적 접근 방식을 포함하여 많은 방법을 사용할 수 있습니다. 이러한 접근 방식의 경우, 두 분포 모두에서 추출된 샘플이 필요합니다. 즉, 테스트 데이터에 대한 접근을 통한 "진짜" $p$와 훈련 세트를 생성하는 데 사용된 $q$ (후자는 당연히 사용 가능함)입니다. 하지만 우리는 특성 $\mathbf{x} \sim p(\mathbf{x})$만 필요하며 레이블 $y \sim p(y)$에 접근할 필요는 없다는 점에 유의하십시오.

이 경우 원본만큼 좋은 결과를 제공하는 매우 효과적인 접근 방식이 존재합니다. 바로 이진 분류를 위한 소프트맥스 회귀(:numref:`sec_softmax` 참조)의 특수한 경우인 로지스틱 회귀입니다. 추정 확률 비율을 계산하는 데 필요한 것은 이것뿐입니다. 우리는 $p(\mathbf{x})$에서 추출된 데이터와 $q(\mathbf{x})$에서 추출된 데이터를 구별하는 분류기를 학습합니다. 두 분포를 구별하는 것이 불가능하다면 관련 인스턴스가 두 분포 중 어느 쪽에서 왔을 가능성도 동일하다는 것을 의미합니다. 반면에 잘 구별될 수 있는 인스턴스는 그에 따라 상당히 과중하게 가중되거나 가볍게 가중되어야 합니다.

단순함을 위해 각각 $p(\mathbf{x})$와 $q(\mathbf{x})$ 분포에서 동일한 수의 인스턴스를 가졌다고 가정합시다. 이제 $p$에서 추출된 데이터에 대해서는 레이블 $z$를 1로, $q$에서 추출된 데이터에 대해서는 -1로 표시합시다. 그러면 혼합 데이터셋에서의 확률은 다음과 같이 주어집니다.

$$P(z=1 \mid \mathbf{x}) = \frac{p(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})} \textrm{ 이고 따라서 } \frac{P(z=1 \mid \mathbf{x})}{P(z=-1 \mid \mathbf{x})} = \frac{p(\mathbf{x})}{q(\mathbf{x})}.$$

따라서 $P(z=1 \mid \mathbf{x})=\frac{1}{1+\exp(-h(\mathbf{x}))}$ ($h$는 파라미터화된 함수)인 로지스틱 회귀 접근 방식을 사용하면 다음과 같이 됩니다.

$$
\beta_i = \frac{1/(1 + \exp(-h(\mathbf{x}_i)))}{\exp(-h(\mathbf{x}_i))/(1 + \exp(-h(\mathbf{x}_i)))} = \exp(h(\mathbf{x}_i)).
$$

결과적으로 우리는 두 가지 문제를 해결해야 합니다: 첫째, 두 분포에서 추출된 데이터를 구별하는 문제, 그리고 항들에 $\beta_i$로 가중치를 부여하는 :eqref:`eq_weighted-empirical-risk-min`의 가중 경험적 위험 최소화 문제입니다.

이제 교정 알고리즘을 설명할 준비가 되었습니다. 훈련 세트 $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$와 레이블 없는 테스트 세트 $\{\mathbf{u}_1, \ldots, \mathbf{u}_m\}$가 있다고 가정해 봅시다. 공변량 이동의 경우, 모든 $1 \leq i \leq n$에 대해 $\mathbf{x}_i$는 어떤 소스 분포에서 추출되었고 모든 $1 \leq i \leq m$에 대해 $\mathbf{u}_i$는 타겟 분포에서 추출되었다고 가정합니다. 공변량 이동을 교정하기 위한 전형적인 알고리즘은 다음과 같습니다:

1. 이진 분류 훈련 세트를 만듭니다: $\{(\mathbf{x}_1, -1), \ldots, (\mathbf{x}_n, -1), (\mathbf{u}_1, 1), \ldots, (\mathbf{u}_m, 1)\}$.
2. 로지스틱 회귀를 사용하여 이진 분류기를 훈련하여 함수 $h$를 얻습니다.
3. $\beta_i = \exp(h(\mathbf{x}_i))$ 또는 어떤 상수 $c$에 대해 더 나은 $\beta_i = \min(\exp(h(\mathbf{x}_i)), c)$를 사용하여 훈련 데이터에 가중치를 부여합니다.
4. :eqref:`eq_weighted-empirical-risk-min`에서 $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$에 대해 훈련하기 위해 가중치 $\beta_i$를 사용합니다.

위 알고리즘은 한 가지 결정적인 가정에 의존한다는 점에 유의하십시오. 이 체계가 작동하려면 타겟(예: 테스트 시) 분포의 각 데이터 예제가 훈련 시에 발생할 확률이 0이 아니어야 합니다. $p(\mathbf{x}) > 0$이지만 $q(\mathbf{x}) = 0$인 지점을 발견하면 해당 중요도 가중치는 무한대가 되어야 하기 때문입니다.






### 레이블 이동 교정 (Label Shift Correction)

우리가 $k$개의 범주를 가진 분류 작업을 다루고 있다고 가정해 봅시다. :numref:`subsec_covariate-shift-correction`과 동일한 표기법을 사용하여, $q$와 $p$는 각각 소스 분포(예: 훈련 시)와 타겟 분포(예: 테스트 시)입니다. 레이블의 분포가 시간이 지남에 따라 바뀐다고 가정해 봅시다: $q(y) \neq p(y)$, 하지만 클래스 조건부 분포는 동일하게 유지됩니다: $q(\mathbf{x} \mid y)=p(\mathbf{x} \mid y)$. 소스 분포 $q(y)$가 "틀렸다면", :eqref:`eq_true-risk`에 정의된 위험의 다음과 같은 항등식에 따라 이를 교정할 수 있습니다:

$$
\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(\mathbf{x} \mid y)p(y) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(\mathbf{x} \mid y)q(y)\frac{p(y)}{q(y)} \;d\mathbf{x}dy.
\end{aligned}
$$



여기서 우리의 중요도 가중치는 레이블 우도 비율에 해당할 것입니다:

$$\beta_i \stackrel{\textrm{def}}{=} \frac{p(y_i)}{q(y_i)}.$$

레이블 이동의 좋은 점 중 하나는 소스 분포에 대해 상당히 좋은 모델을 가지고 있다면, 주변 차원을 다루지 않고도 이러한 가중치의 일관된 추정치를 얻을 수 있다는 것입니다. 딥러닝에서 입력은 이미지와 같은 고차원 객체인 경향이 있는 반면, 레이블은 범주와 같은 더 단순한 객체인 경우가 많기 때문입니다.

타겟 레이블 분포를 추정하기 위해, 먼저 (일반적으로 훈련 데이터로 훈련된) 합리적으로 우수한 기성 분류기를 가져와 검증 세트(훈련 분포에서 가져옴)를 사용하여 그 "혼동(confusion)" 행렬을 계산합니다. *혼동 행렬* $\mathbf{C}$는 단순히 $k \times k$ 행렬이며, 각 열은 레이블 범주(실제 값)에 대응하고 각 행은 우리 모델의 예측 범주에 대응합니다. 각 셀의 값 $c_{ij}$는 검증 세트에서 실제 레이블이 $j$이고 우리 모델이 $i$라고 예측한 전체 예측의 비율입니다.

이제 복잡한 실시간 주석 파이프라인에 투자하지 않는 한 실제 현장에서 마주치는 예제들에 대한 레이블을 볼 수 없으므로 타겟 데이터에서 혼동 행렬을 직접 계산할 수는 없습니다. 하지만 우리가 할 수 있는 일은 테스트 시의 모든 모델 예측을 평균하여 평균 모델 출력 $\mu(\hat{\mathbf{y}}) \in \mathbb{R}^k$를 얻는 것입니다. 여기서 $i$번째 원소 $\mu(\hat{y}_i)$는 우리 모델이 $i$라고 예측한 테스트 세트의 전체 예측 비율입니다.

몇 가지 완만한 조건 하에서(우리 분류기가 애초에 상당히 정확했고, 타겟 데이터가 우리가 이전에 본 범주들만 포함하고 있으며, 레이블 이동 가정이 애초에 성립한다면 - 여기서 가장 강력한 가정임), 우리는 간단한 선형 시스템을 풀어 테스트 세트 레이블 분포를 추정할 수 있음이 밝혀졌습니다.

$$\mathbf{C} p(\mathbf{y}) = \mu(\hat{\mathbf{y}}),$$

추정치로서 모든 $1 \leq i \leq k$에 대해 $\sum_{j=1}^k c_{ij} p(y_j) = \mu(\hat{y}_i)$가 성립하기 때문입니다. 여기서 $p(y_j)$는 $k$차원 레이블 분포 벡터 $p(\mathbf{y})$의 $j$번째 원소입니다. 우리 분류기가 처음부터 충분히 정확하다면 혼동 행렬 $\mathbf{C}$는 가역적일 것이며, $p(\mathbf{y}) = \mathbf{C}^{-1} \mu(\hat{\mathbf{y}})$라는 해를 얻게 됩니다.

소스 데이터에서 레이블을 관찰하므로 분포 $q(y)$를 추정하기 쉽습니다. 그런 다음 레이블 $y_i$를 가진 임의의 훈련 예제 $i$에 대해, 추정된 $p(y_i)/q(y_i)$의 비율을 취하여 가중치 $\beta_i$를 계산하고, 이를 :eqref:`eq_weighted-empirical-risk-min`의 가중 경험적 위험 최소화에 대입할 수 있습니다.


### 개념 이동 교정 (Concept Shift Correction)

개념 이동은 원칙적인 방식으로 수정하기가 훨씬 더 어렵습니다. 예를 들어 문제가 갑자기 고양이와 개를 구별하는 것에서 흰색과 검은색 동물을 구별하는 것으로 바뀌는 상황에서, 단순히 새로운 레이블을 수집하고 처음부터 다시 훈련하는 것보다 훨씬 더 잘할 수 있다고 가정하는 것은 비합리적일 것입니다. 다행히 실제로는 그러한 극단적인 이동은 드뭅니다. 대신 보통 일어나는 일은 작업이 천천히 계속해서 바뀌는 것입니다. 상황을 더 구체적으로 만들기 위해 몇 가지 예시를 들어보겠습니다:

* 전산 광고에서 새로운 제품이 출시되고 오래된 제품은 인기가 없어집니다. 이는 광고와 그 인기에 대한 분포가 점진적으로 변한다는 것을 의미하며, 어떠한 클릭률 예측기도 그에 따라 점진적으로 변해야 합니다.
* 교통 카메라 렌즈가 환경적 마모로 인해 점진적으로 노후화되어 이미지 품질에 점진적으로 영향을 미칩니다.
* 뉴스 콘텐츠가 점진적으로 바뀝니다(즉, 대부분의 뉴스는 그대로 유지되지만 새로운 이야기가 나타납니다).

이러한 경우, 네트워크를 훈련하는 데 사용했던 것과 동일한 접근 방식을 사용하여 데이터의 변화에 적응하게 할 수 있습니다. 즉, 처음부터 훈련하는 대신 기존 네트워크 가중치를 사용하고 새로운 데이터로 몇 가지 업데이트 단계를 수행하면 됩니다.


## 학습 문제의 분류 (A Taxonomy of Learning Problems)

분포의 변화를 다루는 방법에 대한 지식을 갖추었으니, 이제 머신러닝 문제 공식화의 다른 측면들을 고려해 볼 수 있습니다.


### 배치 학습 (Batch Learning)

*배치 학습(batch learning)*에서는 동일한 분포에서 추출된 새로운 데이터 $(\mathbf{x}, y)$의 점수를 매기기 위해 모델 $f(\mathbf{x})$를 훈련하는 데 사용하는 훈련 특성과 레이블 $\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}$에 접근할 수 있습니다. 이것은 우리가 여기서 논의하는 모든 문제에 대한 기본 가정입니다. 예를 들어, 많은 고양이와 개 사진을 기반으로 고양이 감지기를 훈련할 수 있습니다. 일단 훈련을 마치면, 고양이만 들여보내는 스마트 캣도어 컴퓨터 비전 시스템의 일부로 이를 출시합니다. 이는 고객의 집에 설치된 후 (극단적인 상황이 없는 한) 다시는 업데이트되지 않습니다.


### 온라인 학습 (Online Learning)

이제 데이터 $(\mathbf{x}_i, y_i)$가 한 번에 한 샘플씩 도착한다고 상상해 보십시오. 더 구체적으로, 먼저 $\mathbf{x}_i$를 관찰한 다음 추정치 $f(\mathbf{x}_i)$를 내놓아야 한다고 가정합시다. 이를 수행한 후에야 $y_i$를 관찰하고 우리의 결정에 따라 보상을 받거나 손실을 입게 됩니다. 많은 실제 문제들이 이 범주에 속합니다. 예를 들어, 내일의 주가를 예측해야 하며, 그 추정치에 기반하여 거래를 할 수 있고 하루가 끝날 때 우리의 추정치가 이익을 냈는지 알게 됩니다. 즉, *온라인 학습(online learning)*에서는 새로운 관찰이 주어질 때마다 지속적으로 모델을 개선하는 다음과 같은 주기를 갖습니다:

$$\begin{aligned}&\textrm{모델 } f_t \longrightarrow \textrm{데이터 }  \mathbf{x}_t \longrightarrow \textrm{추정치 } f_t(\mathbf{x}_t) \longrightarrow\\ \textrm{관}&\textrm{찰 } y_t \longrightarrow \textrm{손실 } l(y_t, f_t(\mathbf{x}_t)) \longrightarrow \textrm{모델 } f_{t+1}\end{aligned}$$

### 밴딧 (Bandits)

*밴딧(Bandits)*은 위 문제의 특수한 경우입니다. 대부분의 학습 문제에서는 파라미터를 학습하고자 하는 연속적으로 파라미터화된 함수 $f$(예: 심층 네트워크)를 가지고 있지만, *밴딧* 문제에서는 우리가 당길 수 있는 팔의 수가 유한합니다. 즉, 우리가 취할 수 있는 행동의 수가 유한합니다. 이 더 단순한 문제에 대해 최적성 측면에서 더 강력한 이론적 보장을 얻을 수 있다는 사실은 그리 놀랍지 않습니다. 이 문제가 종종 (혼란스럽게도) 별개의 학습 설정인 것처럼 다루어지기 때문에 주로 나열했습니다.


### 제어 (Control)

많은 경우 환경은 우리가 한 일을 기억합니다. 반드시 적대적인 방식은 아니지만 단순히 기억할 것이고 응답은 이전에 일어난 일에 달려 있을 것입니다. 예를 들어 커피 보일러 컨트롤러는 이전에 보일러를 가열했는지 여부에 따라 다른 온도를 관찰할 것입니다. PID(비례-적분-미분) 제어 알고리즘이 거기서 인기 있는 선택입니다. 마찬가지로 뉴스 사이트에서의 사용자 행동은 우리가 이전에 그들에게 무엇을 보여주었는지에 달려 있을 것입니다(예: 그들은 대부분의 뉴스를 한 번만 읽을 것입니다). 많은 그러한 알고리즘은 자신의 결정이 덜 무작위적으로 보이게 하기 위해 자신이 행동하는 환경의 모델을 형성합니다. 최근에는 더 나은 얽힘 해제(disentangling) 및 재구성 품질을 달성하고, 생성된 텍스트의 다양성과 생성된 이미지의 재구성 품질을 개선하기 위해 하이퍼파라미터를 자동으로 튜닝하는 데 제어 이론(예: PID 변형)이 사용되기도 했습니다 :cite:`Shao.Yao.Sun.ea.2020`.




### 강화 학습 (Reinforcement Learning)

기억이 있는 환경의 더 일반적인 경우로, 환경이 우리와 협력하려고 노력하는 상황(협력 게임, 특히 비제로섬 게임의 경우)이나 환경이 이기려고 노력하는 상황을 만날 수 있습니다. 체스, 바둑, 백개먼 또는 스타크래프트는 *강화 학습(reinforcement learning)*의 일부 사례들입니다. 마찬가지로 자율 주행차를 위한 훌륭한 컨트롤러를 구축하고 싶을 수도 있습니다. 다른 차들은 자율 주행차의 주행 스타일에 대해 피하려 하거나, 사고를 유발하려 하거나, 협력하려 하는 등 비자명한 방식으로 대응할 가능성이 높습니다.

### 환경 고려하기 (Considering the Environment)

위의 서로 다른 상황들 사이의 한 가지 핵심적인 구분은, 정지된 환경의 경우 전반적으로 작동했을 전략이 적응할 수 있는 환경에서는 전반적으로 작동하지 않을 수도 있다는 것입니다. 예를 들어 거래자가 발견한 차익 거래 기회는 그것이 활용되자마자 사라질 가능성이 높습니다. 환경이 변하는 속도와 방식은 우리가 동원할 수 있는 알고리즘의 유형을 크게 결정합니다. 예를 들어 상황이 천천히만 변할 수 있다는 것을 안다면, 어떠한 추정치도 천천히만 변하도록 강제할 수 있습니다. 환경이 즉각적으로 변할 수 있지만 아주 드물게만 변한다는 것을 안다면, 그에 대한 여유를 둘 수 있습니다. 이러한 종류의 지식은 개념 이동을 다루는 야심 찬 데이터 과학자에게 결정적입니다. 즉, 해결하려는 문제가 시간이 지남에 따라 변할 수 있을 때입니다.




## 머신러닝에서의 공정성, 책임성, 투명성 (Fairness, Accountability, and Transparency in Machine Learning)

마지막으로, 머신러닝 시스템을 배포할 때 여러분은 단순히 예측 모델을 최적화하는 것이 아니라는 점을 기억하는 것이 중요합니다. 여러분은 일반적으로 결정을 (부분적으로 또는 완전히) 자동화하는 데 사용될 도구를 제공하는 것입니다. 이러한 기술 시스템은 결과적인 결정의 대상이 되는 개인의 삶에 영향을 미칠 수 있습니다. 예측을 고려하는 것에서 결정을 내리는 것으로의 도약은 새로운 기술적 질문뿐만 아니라 신중하게 고려해야 할 일련의 윤리적 질문을 제기합니다. 의료 진단 시스템을 배포하는 경우, 어떤 집단에 대해서는 작동하고 어떤 집단에 대해서는 작동하지 않을 수 있는지 알아야 합니다. 하위 집단의 복지에 대한 예측 가능한 위험을 간과하는 것은 우리가 열등한 치료를 제공하게 만들 수 있습니다. 더욱이 일단 의사 결정 시스템을 고려하게 되면, 우리는 한 걸음 물러나 우리 기술을 어떻게 평가하는지 재고해야 합니다. 이러한 범위 변화의 다른 결과들 중에서, 우리는 *정확도*가 적절한 척도인 경우가 드물다는 것을 발견할 것입니다. 예를 들어 예측을 행동으로 옮길 때, 우리는 종종 다양한 방식으로 오차를 범하는 것의 잠재적 비용 민감도를 고려하기를 원할 것입니다. 이미지를 잘못 분류하는 한 가지 방식이 인종적 차별로 인식될 수 있는 반면, 다른 범주로의 오분류는 무해하다면, 의사 결정 프로토콜을 설계할 때 사회적 가치를 고려하여 그에 따라 임계값을 조정하고 싶을 수 있습니다. 또한 예측 시스템이 피드백 루프로 이어지는 방식에 대해서도 주의하고 싶습니다. 예를 들어, 범죄 예측이 높은 지역에 순찰 대원을 할당하는 예측 치안 시스템을 생각해 보십시오. 걱정스러운 패턴이 어떻게 나타날 수 있는지 쉽게 알 수 있습니다:

 1. 범죄가 더 많은 동네에 더 많은 순찰이 배치됩니다.
 2. 결과적으로 이 동네에서 더 많은 범죄가 발견되어 미래의 반복을 위한 훈련 데이터에 입력됩니다.
 3. 더 많은 양성 사례에 노출된 모델은 이 동네에서 더 많은 범죄를 예측합니다.
 4. 다음 반복에서 업데이트된 모델은 동일한 동네를 훨씬 더 집중적으로 타겟팅하여 더 많은 범죄가 발견되게 됩니다.

종종 모델의 예측이 훈련 데이터와 결합되는 다양한 메커니즘은 모델링 과정에서 고려되지 않습니다. 이는 연구자들이 *폭주하는 피드백 루프(runaway feedback loops)*라고 부르는 상황으로 이어질 수 있습니다. 게다가 우리는 애초에 올바른 문제를 다루고 있는지에 대해서도 주의하고 싶습니다. 예측 알고리즘은 이제 정보의 보급을 중재하는 데 있어 막대한 역할을 합니다. 개인이 마주하는 뉴스가 그들이 *좋아요*를 누른 페이스북 페이지 세트에 의해 결정되어야 할까요? 이것들은 머신러닝 커리어를 쌓으며 마주칠 수 있는 수많은 시급한 윤리적 딜레마 중 몇 가지에 불과합니다.


## 요약 (Summary)

많은 경우 훈련 세트와 테스트 세트는 동일한 분포에서 오지 않습니다. 이를 분포 이동이라고 합니다. 위험은 실제 분포에서 추출된 전체 데이터 모집단에 대한 손실의 기댓값입니다. 하지만 이 전체 모집단은 대개 사용할 수 없습니다. 경험적 위험은 위험을 근사하기 위해 훈련 데이터에 대한 평균 손실을 구하는 것입니다. 실제로는 경험적 위험 최소화를 수행합니다.

관련 가정 하에서, 공변량 이동과 레이블 이동은 테스트 시에 감지되고 교정될 수 있습니다. 이러한 편향을 고려하지 못하는 것은 테스트 시에 문제가 될 수 있습니다. 어떤 경우에는 환경이 자동화된 행동을 기억하고 놀라운 방식으로 대응할 수 있습니다. 모델을 구축할 때 이러한 가능성을 고려해야 하며, 우리 모델과 환경이 예기치 못한 방식으로 얽히게 될 가능성을 열어두고 운영 중인 시스템을 계속 모니터링해야 합니다.

## 연습 문제 (Exercises)

1. 검색 엔진의 동작을 변경하면 어떤 일이 일어날 수 있을까요? 사용자는 어떻게 할까요? 광고주는 어떨까요?
2. 공변량 이동 감지기를 구현하십시오. 힌트: 분류기를 구축하십시오.
3. 공변량 이동 교정기를 구현하십시오.
4. 분포 이동 외에 경험적 위험이 위험을 근사하는 방식에 영향을 줄 수 있는 다른 요소는 무엇일까요?


[토론](https://discuss.d2l.ai/t/105)