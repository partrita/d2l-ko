# 소프트맥스 회귀 (Softmax Regression)
:label:`sec_softmax`

:numref:`sec_linear_regression`에서 우리는 선형 회귀를 소개하고, :numref:`sec_linear_scratch`에서 밑바닥부터 구현했으며, :numref:`sec_linear_concise`에서 딥러닝 프레임워크의 고수준 API를 사용하여 구현했습니다.

회귀는 *얼마나 많이?*라는 질문에 답하고 싶을 때 사용하는 도구입니다. 
주택이 판매될 가격(달러), 야구팀의 승수, 환자가 퇴원하기 전까지 입원해 있을 일수 등을 예측하고 싶다면 아마도 회귀 모델을 찾고 있을 것입니다. 
하지만 회귀 모델 내에서도 중요한 구분이 있습니다. 
예를 들어, 주택 가격은 결코 음수가 될 수 없으며 변화는 종종 기준 가격에 대해 *상대적*일 수 있습니다. 
따라서 가격의 로그에 대해 회귀를 수행하는 것이 더 효과적일 수 있습니다. 
마찬가지로 환자가 병원에서 보내는 일수는 *이산형 음이 아닌* 확률 변수입니다. 
따라서 최소 평균 제곱(least mean squares)이 이상적인 접근 방식이 아닐 수도 있습니다. 
이러한 종류의 사건 발생 시간(time-to-event) 모델링은 *생존 모델링(survival modeling)*이라는 전문 하위 분야에서 다루는 다른 많은 복잡한 문제를 동반합니다.

여기서 요점은 여러분을 압도하려는 것이 아니라, 단순히 제곱 오차를 최소화하는 것보다 추정에는 훨씬 더 많은 것이 있음을 알려드리는 것입니다. 
그리고 더 넓게는 지도 학습에는 회귀보다 훨씬 더 많은 것이 있습니다. 
이 섹션에서는 *얼마나 많이?*라는 질문을 제쳐두고 대신 *어떤 범주?*라는 질문에 집중하는 *분류(classification)* 문제에 초점을 맞춥니다.



* 이 이메일은 스팸 폴더에 속할까요, 아니면 받은 편지함에 속할까요?
* 이 고객은 구독 서비스에 가입할 가능성이 높을까요, 아니면 가입하지 않을 가능성이 높을까요?
* 이 이미지는 당나귀, 개, 고양이, 수탉 중 무엇을 묘사하고 있을까요?
* Aston이 다음에 볼 가능성이 가장 높은 영화는 무엇일까요?
* 책의 다음 섹션 중 어느 섹션을 읽을 예정인가요?

구어체로 머신러닝 실무자들은 *분류*라는 단어를 두 가지 미묘하게 다른 문제를 설명하기 위해 중복해서 사용합니다: 
(i) 예제를 범주(클래스)에 하드 할당(hard assignments)하는 데만 관심이 있는 문제; 
(ii) 소프트 할당(soft assignments)을 하고자 하는 문제, 즉 각 범주가 적용될 확률을 평가하는 문제. 
종종 하드 할당에만 신경 쓸 때도 소프트 할당을 하는 모델을 사용하기 때문에 이 구분은 모호해지는 경향이 있습니다.

더 나아가 둘 이상의 레이블이 참일 수 있는 경우도 있습니다. 
예를 들어, 뉴스 기사는 엔터테인먼트, 비즈니스, 우주 비행 주제를 동시에 다룰 수 있지만 의학이나 스포츠 주제는 다루지 않을 수 있습니다. 
따라서 이를 위의 범주 중 하나로만 분류하는 것은 그다지 유용하지 않을 것입니다. 
이 문제는 흔히 [다중 레이블 분류(multi-label classification)](https://en.wikipedia.org/wiki/Multi-label_classification)로 알려져 있습니다. 
개요는 :citet:`Tsoumakas.Katakis.2007`를, 이미지 태깅 시 효과적인 알고리즘은 :citet:`Huang.Xu.Yu.2015`를 참조하십시오.

## 분류 (Classification)
:label:`subsec_classification-problem`

맛보기로 간단한 이미지 분류 문제부터 시작해 봅시다. 
여기서 각 입력은 $2\times2$ 그레이스케일 이미지로 구성됩니다. 
각 픽셀 값을 단일 스칼라로 표현하여 4개의 특성 $x_1, x_2, x_3, x_4$를 얻을 수 있습니다. 
더 나아가 각 이미지가 "고양이", "닭", "개"라는 범주 중 하나에 속한다고 가정해 봅시다.

다음으로 레이블을 어떻게 표현할지 선택해야 합니다. 
두 가지 분명한 선택지가 있습니다. 
아마도 가장 자연스러운 충동은 $y \in \{1, 2, 3\}$을 선택하는 것일 것입니다. 여기서 정수는 각각 {\textrm{개}, \textrm{고양이}, \textrm{닭}}을 나타냅니다. 
이는 컴퓨터에 그러한 정보를 *저장*하는 훌륭한 방법입니다. 
만약 범주들 사이에 어떤 자연스러운 순서가 있다면, 
예를 들어 {\textrm{아기}, \textrm{유아}, \textrm{청소년}, \textrm{청년}, \textrm{성인}, \textrm{노인}}을 예측하려고 한다면, 이를 [서순 회귀(ordinal regression)](https://en.wikipedia.org/wiki/Ordinal_regression) 문제로 던지고 레이블을 이 형식으로 유지하는 것이 타당할 수도 있습니다. 
다양한 유형의 순위 지정 손실 함수(ranking loss functions)에 대한 개요는 :citet:`Moon.Smola.Chang.ea.2010`를, 둘 이상의 모드(mode)를 가진 응답을 다루는 베이지안 접근 방식은 :citet:`Beutel.Murray.Faloutsos.ea.2014`를 참조하십시오.

일반적으로 분류 문제에는 클래스 간에 자연스러운 순서가 없습니다. 
다행히도 통계학자들은 오래전에 범주형 데이터를 표현하는 간단한 방법인 *원-핫 인코딩(one-hot encoding)*을 발명했습니다. 
원-핫 인코딩은 범주의 수만큼의 성분을 가진 벡터입니다. 
특정 인스턴스의 범주에 해당하는 성분은 1로 설정되고 다른 모든 성분은 0으로 설정됩니다. 
우리 예제에서 레이블 $y$는 3차원 벡터가 되며, (1, 0, 0)은 "고양이", (0, 1, 0)은 "닭", (0, 0, 1)은 "개"에 해당합니다:

$$y \in \{(1, 0, 0), (0, 1, 0), (0, 0, 1)\}.$$ 

### 선형 모델 (Linear Model)

가능한 모든 클래스와 관련된 조건부 확률을 추정하려면, 클래스당 하나씩 여러 개의 출력을 가진 모델이 필요합니다. 
선형 모델로 분류를 다루려면 출력 수만큼의 아핀 함수가 필요할 것입니다. 
엄밀히 말하면 마지막 범주는 1에서 다른 범주들의 합을 뺀 값이어야 하므로 하나가 적게 필요하지만, 대칭성을 위해 약간 중복된 파라미터화를 사용합니다. 
각 출력은 고유한 아핀 함수에 대응합니다. 
우리 예제에서 4개의 특성과 3개의 가능한 출력 범주가 있으므로, 가중치를 나타내기 위해 12개의 스칼라($w$와 아래첨자)가 필요하고 편향을 나타내기 위해 3개의 스칼라($b$와 아래첨자)가 필요합니다. 결과는 다음과 같습니다:

$$ 
\begin{aligned}
o_1 &= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\
o_2 &= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\
o_3 &= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.
\end{aligned}
$$ 

이에 대응하는 신경망 다이어그램은 :numref:`fig_softmaxreg`에 나와 있습니다. 
선형 회귀와 마찬가지로 단일 레이어 신경망을 사용합니다. 
그리고 각 출력 $o_1, o_2, o_3$의 계산이 모든 입력 $x_1, x_2, x_3, x_4$에 의존하므로, 출력 레이어는 *완전 연결 레이어(fully connected layer)*로 설명될 수도 있습니다.

![소프트맥스 회귀는 단일 레이어 신경망입니다.](../img/softmaxreg.svg)
:label:`fig_softmaxreg`

더 간결한 표기법을 위해 벡터와 행렬을 사용합니다: $\mathbf{o} = \mathbf{W} \mathbf{x} + \mathbf{b}$는 수학과 코드에 훨씬 더 적합합니다. 
우리는 모든 가중치를 $3 \times 4$ 행렬에 모으고 모든 편향을 벡터 $\mathbf{b} \in \mathbb{R}^3$에 모았습니다.

### 소프트맥스 (The Softmax)
:label:`subsec_softmax_operation`

적절한 손실 함수를 가정하고, $\mathbf{o}$와 레이블 $\mathbf{y}$ 사이의 차이를 직접 최소화하려고 시도할 수 있습니다. 
분류를 벡터 값 회귀 문제로 취급하는 것이 놀라울 정도로 잘 작동하는 것으로 밝혀졌지만, 그럼에도 불구하고 다음과 같은 면에서 불만족스럽습니다:

* 출력 $o_i$가 우리가 확률에 기대하는 방식대로 합이 1이 된다는 보장이 없습니다.
* 출력의 합이 1이 되더라도 출력 $o_i$가 음수가 아니거나 1을 초과하지 않는다는 보장이 없습니다.

두 측면 모두 추정 문제를 해결하기 어렵게 만들고 솔루션을 이상값에 매우 취약하게 만듭니다. 
예를 들어 침실 수와 누군가가 집을 살 가능성 사이에 양의 선형 종속성이 있다고 가정하면, 대저택을 사는 경우에는 확률이 1을 초과할 수도 있습니다! 
따라서 우리는 출력을 "구겨 넣을(squish)" 메커니즘이 필요합니다.

이 목표를 달성할 수 있는 방법은 많습니다. 
예를 들어, 출력이 $\mathbf{o}$인 경우 $\mathbf{y}$의 오염된 버전이라고 가정할 수 있습니다. 여기서 오염은 정규 분포에서 추출된 노이즈 $\boldsymbol{\epsilon}$을 더함으로써 발생합니다. 
즉, $\mathbf{y} = \mathbf{o} + \boldsymbol{\epsilon}$이며, 여기서 $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$입니다. 
이것은 :citet:`Fechner.1860`에 의해 처음 도입된 소위 [프로빗 모델(probit model)](https://en.wikipedia.org/wiki/Probit_model)입니다. 
매력적이기는 하지만, 소프트맥스와 비교했을 때 그렇게 잘 작동하지도 않고 특히 좋은 최적화 문제로 이어지지도 않습니다.

이 목표를 달성하는(그리고 비음수성을 보장하는) 또 다른 방법은 지수 함수 $P(y = i) \propto \exp o_i$를 사용하는 것입니다. 
이는 $o_i$가 증가함에 따라 조건부 클래스 확률이 증가해야 한다는 요구 사항을 실제로 만족하며, 단조롭고 모든 확률이 음수가 아닙니다. 
그런 다음 각 값을 그들의 합으로 나눔으로써 합이 1이 되도록 이러한 값을 변환할 수 있습니다. 
이 과정을 *정규화(normalization)*라고 합니다. 
이 두 부분을 합치면 *소프트맥스(softmax)* 함수를 얻게 됩니다:

$$\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o}) \quad \textrm{여기서}\quad \hat{y}_i = \frac{\exp(o_i)}{\sum_j \exp(o_j)}.$$ 
:eqlabel:`eq_softmax_y_and_o`

$\mathbf{o}$의 가장 큰 좌표가 $\hat{\mathbf{y}}$에 따른 가장 가능성 있는 클래스에 대응한다는 점에 유의하십시오. 
게다가 소프트맥스 연산은 인수들 사이의 순서를 보존하기 때문에, 어떤 클래스에 가장 높은 확률이 할당되었는지 결정하기 위해 소프트맥스를 계산할 필요는 없습니다. 따라서 다음과 같습니다:

$$ 
\operatorname*{argmax}_j \hat y_j = \operatorname*{argmax}_j o_j.
$$ 


소프트맥스에 대한 아이디어는 물리학의 아이디어를 차용한 :citet:`Gibbs.1902`로 거슬러 올라갑니다. 
더 거슬러 올라가면 현대 통계 물리학의 아버지인 볼츠만(Boltzmann)은 가스 분자의 에너지 상태에 대한 분포를 모델링하기 위해 이 트릭을 사용했습니다. 
특히 그는 가스의 분자와 같은 열역학적 앙상블에서 에너지 상태의 유병률이 $\exp(-E/kT)$에 비례한다는 것을 발견했습니다. 
여기서 $E$는 상태의 에너지이고, $T$는 온도이며, $k$는 볼츠만 상수입니다. 
통계학자들이 통계 시스템의 "온도"를 높이거나 낮추는 것에 대해 이야기할 때, 그들은 더 낮거나 높은 에너지 상태를 선호하기 위해 $T$를 변경하는 것을 의미합니다. 
깁스(Gibbs)의 아이디어를 따르면 에너지는 오차와 같습니다. 
에너지 기반 모델 :cite:`Ranzato.Boureau.Chopra.ea.2007`은 딥러닝의 문제를 설명할 때 이 관점을 사용합니다.

### 벡터화 (Vectorization)
:label:`subsec_softmax_vectorization`

계산 효율성을 높이기 위해 데이터 미니배치에서 계산을 벡터화합니다. 
차원(입력 수)이 $d$인 $n$개 예제로 구성된 미니배치 $\mathbf{X} \in \mathbb{R}^{n \times d}$가 주어졌다고 가정합시다. 
또한 출력에 $q$개의 범주가 있다고 가정합시다. 
그러면 가중치는 $\mathbf{W} \in \mathbb{R}^{d \times q}$를 만족하고 편향은 $\mathbf{b} \in \mathbb{R}^{1\times q}$를 만족합니다.

$$ 
\begin{aligned}
\mathbf{O} &= \mathbf{X} \mathbf{W} + \mathbf{b}, \\
\hat{\mathbf{Y}} & = \mathrm{softmax}(\mathbf{O}).
\end{aligned}
$$ 
:eqlabel:`eq_minibatch_softmax_reg`

이는 지배적인 연산을 행렬-행렬 곱 $\mathbf{X} \mathbf{W}$로 가속화합니다. 
게다가 $\mathbf{X}$의 각 행이 데이터 예제를 나타내므로, 소프트맥스 연산 자체는 *행별(rowwise)*로 계산될 수 있습니다: $\mathbf{O}$의 각 행에 대해 모든 항목을 지수화한 다음 합계로 정규화합니다. 
하지만 큰 숫자의 지수와 로그를 취할 때는 수치적 오버플로(overflow)나 언더플로(underflow)를 유발할 수 있으므로 주의해야 합니다. 
딥러닝 프레임워크는 이를 자동으로 처리합니다.

## 손실 함수 (Loss Function)
:label:`subsec_softmax-regression-loss-func`

이제 특성 $\mathbf{x}$에서 확률 $\mathbf{\hat{y}}$로의 매핑이 있으므로, 이 매핑의 정확도를 최적화할 방법이 필요합니다. 
우리는 :numref:`subsec_normal_distribution_and_squared_loss`에서 평균 제곱 오차 손실에 대한 확률적 정당성을 제공할 때 만났던 것과 동일한 방법인 최대 우도 추정(maximum likelihood estimation)에 의존할 것입니다.

### 로그 우도 (Log-Likelihood)

소프트맥스 함수는 벡터 $\hat{\mathbf{y}}$를 제공하며, 이를 $\hat{y}_1$ = $P(y=\textrm{고양이} \mid \mathbf{x})$와 같이 임의의 입력 $\mathbf{x}$가 주어졌을 때 각 클래스의 (추정된) 조건부 확률로 해석할 수 있습니다. 
다음에서는 특성 $\mathbf{X}$가 있는 데이터셋에 대해 레이블 $\mathbf{Y}$가 원-핫 인코딩 레이블 벡터를 사용하여 표현된다고 가정합니다. 
특성이 주어졌을 때 모델에 따라 실제 클래스가 얼마나 가능성이 있는지 확인함으로써 추정치를 실제와 비교할 수 있습니다:

$$ 
P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}).
$$ 

각 레이블이 각각의 분포 $P(\mathbf{y}\mid\mathbf{x}^{(i)})$에서 독립적으로 추출되었다고 가정하므로 인수 분해를 사용할 수 있습니다. 
항들의 곱을 최대화하는 것은 다루기 어렵기 때문에, 음의 로그를 취하여 음의 로그 우도를 최소화하는 등가 문제로 변환합니다:

$$ 
-\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})
= \sum_{i=1}^n l(\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)}),
$$ 

여기서 $q$개 클래스에 대한 임의의 레이블 $\mathbf{y}$와 모델 예측 $\hat{\mathbf{y}}$ 쌍에 대해 손실 함수 $l$은 다음과 같습니다.

$$ l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j. $$ 
:eqlabel:`eq_l_cross_entropy`

나중에 설명할 이유들로 인해, :eqref:`eq_l_cross_entropy`의 손실 함수를 흔히 *크로스 엔트로피 손실(cross-entropy loss)*이라고 합니다. 
$\mathbf{y}$는 길이가 $q$인 원-핫 벡터이므로, 모든 좌표 $j$에 대한 합은 한 항을 제외하고 모두 사라집니다. 
$\hat{\mathbf{y}}$가 확률 벡터일 때마다 손실 $l(\mathbf{y}, \hat{\mathbf{y}})$는 아래로 $0$에 의해 제한된다는 점에 유의하십시오: 어떤 항목도 $1$보다 크지 않으므로 그들의 음의 로그는 $0$보다 낮을 수 없습니다; $l(\mathbf{y}, \hat{\mathbf{y}}) = 0$은 실제 레이블을 *확실성*을 가지고 예측할 때만 가능합니다. 
이는 파라미터의 어떤 유한한 설정에서도 결코 일어날 수 없습니다. 소프트맥스 출력을 $1$로 가져가려면 해당 입력 $o_i$를 무한대로(또는 $j \neq i$인 다른 모든 출력 $o_j$를 음의 무한대로) 가져가야 하기 때문입니다. 
설령 우리 모델이 출력 확률 $0$을 할당할 수 있더라도, 그렇게 높은 확신을 가지고 할당했을 때 발생하는 오차는 무한한 손실($-\log 0 = \infty$)을 초래할 것입니다.


### 소프트맥스와 크로스 엔트로피 손실 (Softmax and Cross-Entropy Loss)
:label:`subsec_softmax_and_derivatives`

소프트맥스 함수와 그에 대응하는 크로스 엔트로피 손실은 매우 흔하기 때문에, 이들이 어떻게 계산되는지 조금 더 잘 이해할 가치가 있습니다. 
:eqref:`eq_softmax_y_and_o`를 :eqref:`eq_l_cross_entropy`의 손실 정의에 대입하고 소프트맥스의 정의를 사용하면 다음을 얻습니다.

$$ 
\begin{aligned}
l(\mathbf{y}, \hat{\mathbf{y}}) &=  - \sum_{j=1}^q y_j \log \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \\
&= \sum_{j=1}^q y_j \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j \\
&= \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j.
\end{aligned}
$$ 

무슨 일이 일어나고 있는지 조금 더 잘 이해하기 위해, 임의의 로짓(logit) $o_j$에 대한 도함수를 고려해 봅시다. 우리는 다음을 얻습니다.

$$ 
\partial_{o_j} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \mathrm{softmax}(\mathbf{o})_j - y_j.
$$ 

즉, 도함수는 소프트맥스 연산으로 표현되는 우리 모델에 의해 할당된 확률과, 원-핫 레이블 벡터의 원소들로 표현되는 실제 일어난 일 사이의 차이입니다. 
이런 의미에서 이는 회귀에서 보았던 것과 매우 유사한데, 거기서 기울기는 관찰 $y$와 추정치 $\hat{y}$ 사이의 차이였습니다. 
이것은 우연이 아닙니다. 임의의 지수족(exponential family) 모델에서 로그 우도의 기울기는 정확히 이 항으로 주어집니다. 이 사실은 실제로 기울기를 계산하는 것을 쉽게 만듭니다.

이제 단일 결과가 아니라 결과에 대한 전체 분포를 관찰하는 경우를 고려해 봅시다. 
레이블 $\mathbf{y}$에 대해 이전과 동일한 표현을 사용할 수 있습니다. 
유일한 차이점은 $(0, 0, 1)$과 같은 이진 항목만 포함된 벡터 대신, $(0.1, 0.2, 0.7)$과 같은 일반적인 확률 벡터를 갖는다는 것입니다. 
:eqref:`eq_l_cross_entropy`에서 손실 $l$을 정의하기 위해 이전에 사용했던 수학은 여전히 잘 작동하며, 해석만 약간 더 일반적입니다. 
이는 레이블에 대한 분포에 대한 손실의 기대값입니다. 
이 손실을 *크로스 엔트로피 손실*이라고 하며 분류 문제에서 가장 흔히 사용되는 손실 중 하나입니다. 
우리는 정보 이론의 기초만 도입함으로써 이 이름을 명확히 할 수 있습니다. 
간단히 말해, 이는 우리가 예측한 일($\hat{\mathbf{y}}$)에 대해 우리가 본 것($\mathbf{y}$)을 인코딩하는 데 필요한 비트 수를 측정합니다. 
다음에서 매우 기본적인 설명을 제공합니다. 정보 이론에 대한 자세한 내용은 :citet:`Cover.Thomas.1999` 또는 :citet:`mackay2003information`를 참조하십시오.



## 정보 이론 기초 (Information Theory Basics)
:label:`subsec_info_theory_basics`

많은 딥러닝 논문들이 정보 이론의 직관과 용어를 사용합니다. 
이를 이해하기 위해서는 공통된 언어가 필요합니다. 
이것은 생존 가이드입니다. 
*정보 이론(Information theory)*은 정보(데이터라고도 함)를 인코딩, 디코딩, 전송 및 조작하는 문제를 다룹니다.

### 엔트로피 (Entropy)

정보 이론의 핵심 아이디어는 데이터에 포함된 정보의 양을 정량화하는 것입니다. 
이는 데이터를 압축하는 능력에 한계를 둡니다. 
분포 $P$에 대해 그 *엔트로피(entropy)* $H[P]$는 다음과 같이 정의됩니다:

$$H[P] = \sum_j - P(j) \log P(j).$$ 
:eqlabel:`eq_softmax_reg_entropy`

정보 이론의 근본적인 정리 중 하나는 분포 $P$에서 무작위로 추출된 데이터를 인코딩하기 위해 이를 인코딩하는 데 최소 $H[P]$ "나츠(nats)"가 필요하다는 것입니다 :cite:`Shannon.1948`. 
"나츠"가 무엇인지 궁금하다면, 이는 밑이 2인 코드 대신 밑이 $e$인 코드를 사용할 때의 비트(bit)와 동등한 것입니다. 
따라서 1 나츠는 $\frac{1}{\log(2)} \approx 1.44$ 비트입니다.


### 놀람 (Surprisal)

압축이 예측과 무슨 상관이 있는지 궁금할 수 있습니다. 
우리가 압축하고 싶은 데이터 스트림이 있다고 상상해 보십시오. 
우리가 다음 토큰을 예측하는 것이 항상 쉽다면, 이 데이터는 압축하기 쉽습니다. 
스트림의 모든 토큰이 항상 동일한 값을 갖는 극단적인 예를 들어봅시다. 
그것은 매우 지루한 데이터 스트림입니다! 
지루할 뿐만 아니라 예측하기도 쉽습니다. 
토큰이 항상 동일하기 때문에 스트림의 내용을 전달하기 위해 어떠한 정보도 전송할 필요가 없습니다. 
예측하기 쉬우면 압축하기 쉽습니다.

하지만 우리가 모든 사건을 완벽하게 예측할 수 없다면, 때때로 놀랄 수도 있습니다. 
사건에 낮은 확률이 할당될 때 우리의 놀람은 더 큽니다. 
클로드 섀넌(Claude Shannon)은 사건 $j$에 (주관적) 확률 $P(j)$를 할당했을 때 그 사건을 관찰하는 사람의 *놀람(surprisal)*을 정량화하기 위해 $\log \frac{1}{P(j)} = -\log P(j)$를 정했습니다. 
:eqref:`eq_softmax_reg_entropy`에 정의된 엔트로피는 데이터 생성 프로세스와 진정으로 일치하는 올바른 확률을 할당했을 때의 *기대 놀람(expected surprisal)*입니다.


### 크로스 엔트로피 다시 보기 (Cross-Entropy Revisited)

엔트로피가 실제 확률을 아는 사람이 경험하는 놀람의 수준이라면, 크로스 엔트로피란 무엇일까요? 
$P$에서 $Q$로의 크로스 엔트로피(cross-entropy) $H(P, Q)$는, 확률 $P$에 따라 실제로 생성된 데이터를 보았을 때 주관적 확률 $Q$를 가진 관찰자의 기대 놀람입니다. 
이는 $H(P, Q) \stackrel{\textrm{def}}{=} \sum_j - P(j) \log Q(j)$로 주어집니다. 
가장 낮은 크로스 엔트로피는 $P=Q$일 때 달성됩니다. 
이 경우 $P$에서 $Q$로의 크로스 엔트로피는 $H(P, P)= H(P)$입니다.

요컨대, 우리는 크로스 엔트로피 분류 목표를 두 가지 방식으로 생각할 수 있습니다: (i) 관찰된 데이터의 우도를 최대화하는 것; (ii) 레이블을 전달하는 데 필요한 우리의 놀람(따라서 비트 수)을 최소화하는 것.

## 요약 및 토론 (Summary and Discussion)

이 섹션에서 우리는 *이산형* 출력 공간에 대해 최적화할 수 있게 해주는 첫 번째 비자명한 손실 함수를 만났습니다. 
이 설계의 핵심은 우리가 확률론적 접근 방식을 취하여 이산 범주를 확률 분포에서 추출된 인스턴스로 취급했다는 것입니다. 
부수적인 효과로, 일반적인 신경망 레이어의 출력을 유효한 이산 확률 분포로 변환하는 편리한 활성화 함수인 소프트맥스를 만났습니다. 
우리는 소프트맥스와 결합된 크로스 엔트로피 손실의 도함수가 기대 행동과 그 예측 사이의 차이를 취함으로써 제곱 오차의 도함수와 매우 유사하게 동작한다는 것을 보았습니다. 
그리고 비록 겉핥기만 할 수 있었지만, 통계 물리학 및 정보 이론과의 흥미로운 연결도 만났습니다.

비록 이것이 여러분이 나아가는 데 충분하고 여러분의 흥미를 끌기에 충분하기를 바라지만, 여기서는 깊이 파고들지 못했습니다. 
무엇보다도 계산적인 고려 사항을 건너뛰었습니다. 
구체적으로 $d$개의 입력과 $q$개의 출력이 있는 완전 연결 레이어의 경우 파라미터화 및 계산 비용은 $\mathcal{O}(dq)$이며, 이는 실제 상황에서 감당하기 힘들 정도로 높을 수 있습니다. 
다행히 $d$개의 입력을 $q$개의 출력으로 변환하는 이 비용은 근사 및 압축을 통해 줄일 수 있습니다. 
예를 들어 Deep Fried Convnets :cite:`Yang.Moczulski.Denil.ea.2015`는 순열, 푸리에 변환 및 스케일링의 조합을 사용하여 비용을 2차(quadratic)에서 로그-선형(log-linear)으로 줄입니다. 
유사한 기술이 더 발전된 구조적 행렬 근사(structural matrix approximations)에도 적용됩니다 :cite:`sindhwani2015structured`. 
마지막으로 쿼터니언(quaternion)과 유사한 분해를 사용하여 비용을 $\mathcal{O}(\frac{dq}{n})$으로 줄일 수 있는데, 이 역시 압축 계수 $n$을 기반으로 계산 및 저장 비용을 위해 약간의 정확도를 희생할 의향이 있다면 가능합니다 :cite:`Zhang.Tay.Zhang.ea.2021`. 
이는 활발한 연구 분야입니다. 
도전적인 점은 우리가 반드시 가장 간결한 표현이나 가장 적은 부동 소수점 연산 수를 추구하는 것이 아니라, 현대 GPU에서 가장 효율적으로 실행될 수 있는 솔루션을 추구한다는 것입니다.

## 연습 문제 (Exercises)

1. 지수족(exponential families)과 소프트맥스 사이의 연결을 좀 더 깊이 탐구할 수 있습니다.
    1. 소프트맥스에 대한 크로스 엔트로피 손실 $l(\mathbf{y},\hat{\mathbf{y}})$의 2계 도함수를 계산하십시오.
    2. $\mathrm{softmax}(\mathbf{o})$에 의해 주어지는 분포의 분산을 계산하고 위에서 계산된 2계 도함수와 일치함을 보이십시오.
2. 동일한 확률로 발생하는 세 개의 클래스가 있다고 가정합니다. 즉, 확률 벡터는 $(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$입니다.
    1. 이에 대해 이진 코드를 설계하려고 할 때의 문제는 무엇입니까?
    2. 더 나은 코드를 설계할 수 있습니까? 힌트: 두 개의 독립적인 관찰을 인코딩하려고 하면 어떻게 될까요? $n$개의 관찰을 공동으로 인코딩하면 어떻게 될까요?
3. 물리적 전선을 통해 전송되는 신호를 인코딩할 때 엔지니어들은 항상 이진 코드를 사용하지는 않습니다. 예를 들어 [PAM-3](https://en.wikipedia.org/wiki/Ternary_signal)는 두 개의 레벨 {0, 1} 대신 세 개의 신호 레벨 $\{-1, 0, 1\}$을 사용합니다. {0, ..., 7} 범위의 정수를 전송하려면 몇 개의 3진(ternary) 유닛이 필요합니까? 전자공학 측면에서 이것이 왜 더 좋은 아이디어일까요?
4. [브래들리-테리 모델(Bradley--Terry model)](https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model)은 선호도를 파악하기 위해 로지스틱 모델을 사용합니다. 사용자가 사과와 오렌지 중에서 선택하기 위해 점수 $o_{\textrm{apple}}$과 $o_{\textrm{orange}}$를 가정합니다. 우리의 요구 사항은 점수가 클수록 관련 항목을 선택할 가능성이 높아야 하고 점수가 가장 큰 항목이 선택될 가능성이 가장 높아야 한다는 것입니다 :cite:`Bradley.Terry.1952`.
    1. 소프트맥스가 이 요구 사항을 만족함을 증명하십시오.
    2. 사과와 오렌지 중 어느 것도 선택하지 않는 기본 옵션을 허용하려면 어떻게 해야 할까요? 힌트: 이제 사용자에게는 세 가지 선택지가 있습니다.
5. 소프트맥스는 다음 매핑에서 그 이름을 얻었습니다: $\textrm{RealSoftMax}(a, b) = \log (\exp(a) + \exp(b))$.
    1. $\textrm{RealSoftMax}(a, b) > \mathrm{max}(a, b)$임을 증명하십시오.
    2. 두 함수 사이의 차이를 얼마나 작게 만들 수 있습니까? 힌트: 일반성을 잃지 않고 $b = 0$ 및 $a \geq b$로 설정할 수 있습니다.
    3. $\lambda > 0$일 때, $\lambda^{-1} \textrm{RealSoftMax}(\lambda a, \lambda b)$에 대해 이것이 성립함을 증명하십시오.
    4. $\lambda \to \infty$에 대해 $\lambda^{-1} \textrm{RealSoftMax}(\lambda a, \lambda b) \to \mathrm{max}(a, b)$임을 보이십시오.
    5. 유사한 softmin 함수를 구성하십시오.
    6. 이를 둘 이상의 숫자로 확장하십시오.
6. 함수 $g(\mathbf{x}) \stackrel{\textrm{def}}{=} \log \sum_i \exp x_i$는 때때로 [로그-분할 함수(log-partition function)](https://en.wikipedia.org/wiki/Partition_function_(mathematics))라고도 불립니다.
    1. 함수가 볼록(convex)함을 증명하십시오. 힌트: 이를 위해 1계 도함수가 소프트맥스 함수의 확률에 해당한다는 사실을 사용하고 2계 도함수가 분산임을 보이십시오.
    2. $g$가 이동 불변(translation invariant)임을 보이십시오. 즉, $g(\mathbf{x} + b) = g(\mathbf{x})$.
    3. 좌표 $x_i$ 중 일부가 매우 크면 어떻게 됩니까? 모두 매우 작으면 어떻게 됩니까?
    4. $b = \mathrm{max}_i x_i$를 선택하면 수치적으로 안정적인 구현을 얻게 됨을 보이십시오.
7. 어떤 확률 분포 $P$가 있다고 가정합니다. $\alpha > 0$에 대해 $Q(i) \propto P(i)^\alpha$인 다른 분포 $Q$를 선택한다고 가정합시다.
    1. 어떤 $\alpha$ 선택이 온도를 두 배로 높이는 것에 해당합니까? 어떤 선택이 온도를 절반으로 줄이는 것에 해당합니까?
    2. 온도가 0에 가까워지게 하면 어떻게 됩니까?
    3. 온도가 $\infty$에 가까워지게 하면 어떻게 됩니까?

[토론](https://discuss.d2l.ai/t/46)