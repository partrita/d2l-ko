<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>소프트맥스 회귀 (Softmax Regression) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../chapter_linear-classification/softmax-regression.html" class="active"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="소프트맥스-회귀-softmax-regression"><a class="header" href="#소프트맥스-회귀-softmax-regression">소프트맥스 회귀 (Softmax Regression)</a></h1>
<p>:label:<code>sec_softmax</code></p>
<p>:numref:<code>sec_linear_regression</code>에서 우리는 선형 회귀를 소개하고, :numref:<code>sec_linear_scratch</code>에서 밑바닥부터 구현했으며, :numref:<code>sec_linear_concise</code>에서 딥러닝 프레임워크의 고수준 API를 사용하여 구현했습니다.</p>
<p>회귀는 *얼마나 많이?*라는 질문에 답하고 싶을 때 사용하는 도구입니다.
주택이 판매될 가격(달러), 야구팀의 승수, 환자가 퇴원하기 전까지 입원해 있을 일수 등을 예측하고 싶다면 아마도 회귀 모델을 찾고 있을 것입니다.
하지만 회귀 모델 내에서도 중요한 구분이 있습니다.
예를 들어, 주택 가격은 결코 음수가 될 수 없으며 변화는 종종 기준 가격에 대해 <em>상대적</em>일 수 있습니다.
따라서 가격의 로그에 대해 회귀를 수행하는 것이 더 효과적일 수 있습니다.
마찬가지로 환자가 병원에서 보내는 일수는 <em>이산형 음이 아닌</em> 확률 변수입니다.
따라서 최소 평균 제곱(least mean squares)이 이상적인 접근 방식이 아닐 수도 있습니다.
이러한 종류의 사건 발생 시간(time-to-event) 모델링은 *생존 모델링(survival modeling)*이라는 전문 하위 분야에서 다루는 다른 많은 복잡한 문제를 동반합니다.</p>
<p>여기서 요점은 여러분을 압도하려는 것이 아니라, 단순히 제곱 오차를 최소화하는 것보다 추정에는 훨씬 더 많은 것이 있음을 알려드리는 것입니다.
그리고 더 넓게는 지도 학습에는 회귀보다 훨씬 더 많은 것이 있습니다.
이 섹션에서는 *얼마나 많이?*라는 질문을 제쳐두고 대신 *어떤 범주?*라는 질문에 집중하는 <em>분류(classification)</em> 문제에 초점을 맞춥니다.</p>
<ul>
<li>이 이메일은 스팸 폴더에 속할까요, 아니면 받은 편지함에 속할까요?</li>
<li>이 고객은 구독 서비스에 가입할 가능성이 높을까요, 아니면 가입하지 않을 가능성이 높을까요?</li>
<li>이 이미지는 당나귀, 개, 고양이, 수탉 중 무엇을 묘사하고 있을까요?</li>
<li>Aston이 다음에 볼 가능성이 가장 높은 영화는 무엇일까요?</li>
<li>책의 다음 섹션 중 어느 섹션을 읽을 예정인가요?</li>
</ul>
<p>구어체로 머신러닝 실무자들은 <em>분류</em>라는 단어를 두 가지 미묘하게 다른 문제를 설명하기 위해 중복해서 사용합니다:
(i) 예제를 범주(클래스)에 하드 할당(hard assignments)하는 데만 관심이 있는 문제;
(ii) 소프트 할당(soft assignments)을 하고자 하는 문제, 즉 각 범주가 적용될 확률을 평가하는 문제.
종종 하드 할당에만 신경 쓸 때도 소프트 할당을 하는 모델을 사용하기 때문에 이 구분은 모호해지는 경향이 있습니다.</p>
<p>더 나아가 둘 이상의 레이블이 참일 수 있는 경우도 있습니다.
예를 들어, 뉴스 기사는 엔터테인먼트, 비즈니스, 우주 비행 주제를 동시에 다룰 수 있지만 의학이나 스포츠 주제는 다루지 않을 수 있습니다.
따라서 이를 위의 범주 중 하나로만 분류하는 것은 그다지 유용하지 않을 것입니다.
이 문제는 흔히 <a href="https://en.wikipedia.org/wiki/Multi-label_classification">다중 레이블 분류(multi-label classification)</a>로 알려져 있습니다.
개요는 :citet:<code>Tsoumakas.Katakis.2007</code>를, 이미지 태깅 시 효과적인 알고리즘은 :citet:<code>Huang.Xu.Yu.2015</code>를 참조하십시오.</p>
<h2 id="분류-classification"><a class="header" href="#분류-classification">분류 (Classification)</a></h2>
<p>:label:<code>subsec_classification-problem</code></p>
<p>맛보기로 간단한 이미지 분류 문제부터 시작해 봅시다.
여기서 각 입력은 $2\times2$ 그레이스케일 이미지로 구성됩니다.
각 픽셀 값을 단일 스칼라로 표현하여 4개의 특성 $x_1, x_2, x_3, x_4$를 얻을 수 있습니다.
더 나아가 각 이미지가 "고양이", "닭", "개"라는 범주 중 하나에 속한다고 가정해 봅시다.</p>
<p>다음으로 레이블을 어떻게 표현할지 선택해야 합니다.
두 가지 분명한 선택지가 있습니다.
아마도 가장 자연스러운 충동은 $y \in {1, 2, 3}$을 선택하는 것일 것입니다. 여기서 정수는 각각 {\textrm{개}, \textrm{고양이}, \textrm{닭}}을 나타냅니다.
이는 컴퓨터에 그러한 정보를 <em>저장</em>하는 훌륭한 방법입니다.
만약 범주들 사이에 어떤 자연스러운 순서가 있다면,
예를 들어 {\textrm{아기}, \textrm{유아}, \textrm{청소년}, \textrm{청년}, \textrm{성인}, \textrm{노인}}을 예측하려고 한다면, 이를 <a href="https://en.wikipedia.org/wiki/Ordinal_regression">서순 회귀(ordinal regression)</a> 문제로 던지고 레이블을 이 형식으로 유지하는 것이 타당할 수도 있습니다.
다양한 유형의 순위 지정 손실 함수(ranking loss functions)에 대한 개요는 :citet:<code>Moon.Smola.Chang.ea.2010</code>를, 둘 이상의 모드(mode)를 가진 응답을 다루는 베이지안 접근 방식은 :citet:<code>Beutel.Murray.Faloutsos.ea.2014</code>를 참조하십시오.</p>
<p>일반적으로 분류 문제에는 클래스 간에 자연스러운 순서가 없습니다.
다행히도 통계학자들은 오래전에 범주형 데이터를 표현하는 간단한 방법인 *원-핫 인코딩(one-hot encoding)*을 발명했습니다.
원-핫 인코딩은 범주의 수만큼의 성분을 가진 벡터입니다.
특정 인스턴스의 범주에 해당하는 성분은 1로 설정되고 다른 모든 성분은 0으로 설정됩니다.
우리 예제에서 레이블 $y$는 3차원 벡터가 되며, (1, 0, 0)은 "고양이", (0, 1, 0)은 "닭", (0, 0, 1)은 "개"에 해당합니다:</p>
<p>$$y \in {(1, 0, 0), (0, 1, 0), (0, 0, 1)}.$$</p>
<h3 id="선형-모델-linear-model"><a class="header" href="#선형-모델-linear-model">선형 모델 (Linear Model)</a></h3>
<p>가능한 모든 클래스와 관련된 조건부 확률을 추정하려면, 클래스당 하나씩 여러 개의 출력을 가진 모델이 필요합니다.
선형 모델로 분류를 다루려면 출력 수만큼의 아핀 함수가 필요할 것입니다.
엄밀히 말하면 마지막 범주는 1에서 다른 범주들의 합을 뺀 값이어야 하므로 하나가 적게 필요하지만, 대칭성을 위해 약간 중복된 파라미터화를 사용합니다.
각 출력은 고유한 아핀 함수에 대응합니다.
우리 예제에서 4개의 특성과 3개의 가능한 출력 범주가 있으므로, 가중치를 나타내기 위해 12개의 스칼라($w$와 아래첨자)가 필요하고 편향을 나타내기 위해 3개의 스칼라($b$와 아래첨자)가 필요합니다. 결과는 다음과 같습니다:</p>
<p>$$
\begin{aligned}
o_1 &amp;= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,<br />
o_2 &amp;= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,<br />
o_3 &amp;= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.
\end{aligned}
$$</p>
<p>이에 대응하는 신경망 다이어그램은 :numref:<code>fig_softmaxreg</code>에 나와 있습니다.
선형 회귀와 마찬가지로 단일 레이어 신경망을 사용합니다.
그리고 각 출력 $o_1, o_2, o_3$의 계산이 모든 입력 $x_1, x_2, x_3, x_4$에 의존하므로, 출력 레이어는 *완전 연결 레이어(fully connected layer)*로 설명될 수도 있습니다.</p>
<p><img src="../img/softmaxreg.svg" alt="소프트맥스 회귀는 단일 레이어 신경망입니다." />
:label:<code>fig_softmaxreg</code></p>
<p>더 간결한 표기법을 위해 벡터와 행렬을 사용합니다: $\mathbf{o} = \mathbf{W} \mathbf{x} + \mathbf{b}$는 수학과 코드에 훨씬 더 적합합니다.
우리는 모든 가중치를 $3 \times 4$ 행렬에 모으고 모든 편향을 벡터 $\mathbf{b} \in \mathbb{R}^3$에 모았습니다.</p>
<h3 id="소프트맥스-the-softmax"><a class="header" href="#소프트맥스-the-softmax">소프트맥스 (The Softmax)</a></h3>
<p>:label:<code>subsec_softmax_operation</code></p>
<p>적절한 손실 함수를 가정하고, $\mathbf{o}$와 레이블 $\mathbf{y}$ 사이의 차이를 직접 최소화하려고 시도할 수 있습니다.
분류를 벡터 값 회귀 문제로 취급하는 것이 놀라울 정도로 잘 작동하는 것으로 밝혀졌지만, 그럼에도 불구하고 다음과 같은 면에서 불만족스럽습니다:</p>
<ul>
<li>출력 $o_i$가 우리가 확률에 기대하는 방식대로 합이 1이 된다는 보장이 없습니다.</li>
<li>출력의 합이 1이 되더라도 출력 $o_i$가 음수가 아니거나 1을 초과하지 않는다는 보장이 없습니다.</li>
</ul>
<p>두 측면 모두 추정 문제를 해결하기 어렵게 만들고 솔루션을 이상값에 매우 취약하게 만듭니다.
예를 들어 침실 수와 누군가가 집을 살 가능성 사이에 양의 선형 종속성이 있다고 가정하면, 대저택을 사는 경우에는 확률이 1을 초과할 수도 있습니다!
따라서 우리는 출력을 "구겨 넣을(squish)" 메커니즘이 필요합니다.</p>
<p>이 목표를 달성할 수 있는 방법은 많습니다.
예를 들어, 출력이 $\mathbf{o}$인 경우 $\mathbf{y}$의 오염된 버전이라고 가정할 수 있습니다. 여기서 오염은 정규 분포에서 추출된 노이즈 $\boldsymbol{\epsilon}$을 더함으로써 발생합니다.
즉, $\mathbf{y} = \mathbf{o} + \boldsymbol{\epsilon}$이며, 여기서 $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$입니다.
이것은 :citet:<code>Fechner.1860</code>에 의해 처음 도입된 소위 <a href="https://en.wikipedia.org/wiki/Probit_model">프로빗 모델(probit model)</a>입니다.
매력적이기는 하지만, 소프트맥스와 비교했을 때 그렇게 잘 작동하지도 않고 특히 좋은 최적화 문제로 이어지지도 않습니다.</p>
<p>이 목표를 달성하는(그리고 비음수성을 보장하는) 또 다른 방법은 지수 함수 $P(y = i) \propto \exp o_i$를 사용하는 것입니다.
이는 $o_i$가 증가함에 따라 조건부 클래스 확률이 증가해야 한다는 요구 사항을 실제로 만족하며, 단조롭고 모든 확률이 음수가 아닙니다.
그런 다음 각 값을 그들의 합으로 나눔으로써 합이 1이 되도록 이러한 값을 변환할 수 있습니다.
이 과정을 *정규화(normalization)*라고 합니다.
이 두 부분을 합치면 <em>소프트맥스(softmax)</em> 함수를 얻게 됩니다:</p>
<p>$$\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o}) \quad \textrm{여기서}\quad \hat{y}_i = \frac{\exp(o_i)}{\sum_j \exp(o_j)}.$$
:eqlabel:<code>eq_softmax_y_and_o</code></p>
<p>$\mathbf{o}$의 가장 큰 좌표가 $\hat{\mathbf{y}}$에 따른 가장 가능성 있는 클래스에 대응한다는 점에 유의하십시오.
게다가 소프트맥스 연산은 인수들 사이의 순서를 보존하기 때문에, 어떤 클래스에 가장 높은 확률이 할당되었는지 결정하기 위해 소프트맥스를 계산할 필요는 없습니다. 따라서 다음과 같습니다:</p>
<p>$$
\operatorname*{argmax}_j \hat y_j = \operatorname*{argmax}_j o_j.
$$</p>
<p>소프트맥스에 대한 아이디어는 물리학의 아이디어를 차용한 :citet:<code>Gibbs.1902</code>로 거슬러 올라갑니다.
더 거슬러 올라가면 현대 통계 물리학의 아버지인 볼츠만(Boltzmann)은 가스 분자의 에너지 상태에 대한 분포를 모델링하기 위해 이 트릭을 사용했습니다.
특히 그는 가스의 분자와 같은 열역학적 앙상블에서 에너지 상태의 유병률이 $\exp(-E/kT)$에 비례한다는 것을 발견했습니다.
여기서 $E$는 상태의 에너지이고, $T$는 온도이며, $k$는 볼츠만 상수입니다.
통계학자들이 통계 시스템의 "온도"를 높이거나 낮추는 것에 대해 이야기할 때, 그들은 더 낮거나 높은 에너지 상태를 선호하기 위해 $T$를 변경하는 것을 의미합니다.
깁스(Gibbs)의 아이디어를 따르면 에너지는 오차와 같습니다.
에너지 기반 모델 :cite:<code>Ranzato.Boureau.Chopra.ea.2007</code>은 딥러닝의 문제를 설명할 때 이 관점을 사용합니다.</p>
<h3 id="벡터화-vectorization"><a class="header" href="#벡터화-vectorization">벡터화 (Vectorization)</a></h3>
<p>:label:<code>subsec_softmax_vectorization</code></p>
<p>계산 효율성을 높이기 위해 데이터 미니배치에서 계산을 벡터화합니다.
차원(입력 수)이 $d$인 $n$개 예제로 구성된 미니배치 $\mathbf{X} \in \mathbb{R}^{n \times d}$가 주어졌다고 가정합시다.
또한 출력에 $q$개의 범주가 있다고 가정합시다.
그러면 가중치는 $\mathbf{W} \in \mathbb{R}^{d \times q}$를 만족하고 편향은 $\mathbf{b} \in \mathbb{R}^{1\times q}$를 만족합니다.</p>
<p>$$
\begin{aligned}
\mathbf{O} &amp;= \mathbf{X} \mathbf{W} + \mathbf{b}, \
\hat{\mathbf{Y}} &amp; = \mathrm{softmax}(\mathbf{O}).
\end{aligned}
$$
:eqlabel:<code>eq_minibatch_softmax_reg</code></p>
<p>이는 지배적인 연산을 행렬-행렬 곱 $\mathbf{X} \mathbf{W}$로 가속화합니다.
게다가 $\mathbf{X}$의 각 행이 데이터 예제를 나타내므로, 소프트맥스 연산 자체는 *행별(rowwise)*로 계산될 수 있습니다: $\mathbf{O}$의 각 행에 대해 모든 항목을 지수화한 다음 합계로 정규화합니다.
하지만 큰 숫자의 지수와 로그를 취할 때는 수치적 오버플로(overflow)나 언더플로(underflow)를 유발할 수 있으므로 주의해야 합니다.
딥러닝 프레임워크는 이를 자동으로 처리합니다.</p>
<h2 id="손실-함수-loss-function"><a class="header" href="#손실-함수-loss-function">손실 함수 (Loss Function)</a></h2>
<p>:label:<code>subsec_softmax-regression-loss-func</code></p>
<p>이제 특성 $\mathbf{x}$에서 확률 $\mathbf{\hat{y}}$로의 매핑이 있으므로, 이 매핑의 정확도를 최적화할 방법이 필요합니다.
우리는 :numref:<code>subsec_normal_distribution_and_squared_loss</code>에서 평균 제곱 오차 손실에 대한 확률적 정당성을 제공할 때 만났던 것과 동일한 방법인 최대 우도 추정(maximum likelihood estimation)에 의존할 것입니다.</p>
<h3 id="로그-우도-log-likelihood"><a class="header" href="#로그-우도-log-likelihood">로그 우도 (Log-Likelihood)</a></h3>
<p>소프트맥스 함수는 벡터 $\hat{\mathbf{y}}$를 제공하며, 이를 $\hat{y}_1$ = $P(y=\textrm{고양이} \mid \mathbf{x})$와 같이 임의의 입력 $\mathbf{x}$가 주어졌을 때 각 클래스의 (추정된) 조건부 확률로 해석할 수 있습니다.
다음에서는 특성 $\mathbf{X}$가 있는 데이터셋에 대해 레이블 $\mathbf{Y}$가 원-핫 인코딩 레이블 벡터를 사용하여 표현된다고 가정합니다.
특성이 주어졌을 때 모델에 따라 실제 클래스가 얼마나 가능성이 있는지 확인함으로써 추정치를 실제와 비교할 수 있습니다:</p>
<p>$$
P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}).
$$</p>
<p>각 레이블이 각각의 분포 $P(\mathbf{y}\mid\mathbf{x}^{(i)})$에서 독립적으로 추출되었다고 가정하므로 인수 분해를 사용할 수 있습니다.
항들의 곱을 최대화하는 것은 다루기 어렵기 때문에, 음의 로그를 취하여 음의 로그 우도를 최소화하는 등가 문제로 변환합니다:</p>
<p>$$
-\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})
= \sum_{i=1}^n l(\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)}),
$$</p>
<p>여기서 $q$개 클래스에 대한 임의의 레이블 $\mathbf{y}$와 모델 예측 $\hat{\mathbf{y}}$ 쌍에 대해 손실 함수 $l$은 다음과 같습니다.</p>
<p>$$ l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j. $$
:eqlabel:<code>eq_l_cross_entropy</code></p>
<p>나중에 설명할 이유들로 인해, :eqref:<code>eq_l_cross_entropy</code>의 손실 함수를 흔히 *크로스 엔트로피 손실(cross-entropy loss)*이라고 합니다.
$\mathbf{y}$는 길이가 $q$인 원-핫 벡터이므로, 모든 좌표 $j$에 대한 합은 한 항을 제외하고 모두 사라집니다.
$\hat{\mathbf{y}}$가 확률 벡터일 때마다 손실 $l(\mathbf{y}, \hat{\mathbf{y}})$는 아래로 $0$에 의해 제한된다는 점에 유의하십시오: 어떤 항목도 $1$보다 크지 않으므로 그들의 음의 로그는 $0$보다 낮을 수 없습니다; $l(\mathbf{y}, \hat{\mathbf{y}}) = 0$은 실제 레이블을 <em>확실성</em>을 가지고 예측할 때만 가능합니다.
이는 파라미터의 어떤 유한한 설정에서도 결코 일어날 수 없습니다. 소프트맥스 출력을 $1$로 가져가려면 해당 입력 $o_i$를 무한대로(또는 $j \neq i$인 다른 모든 출력 $o_j$를 음의 무한대로) 가져가야 하기 때문입니다.
설령 우리 모델이 출력 확률 $0$을 할당할 수 있더라도, 그렇게 높은 확신을 가지고 할당했을 때 발생하는 오차는 무한한 손실($-\log 0 = \infty$)을 초래할 것입니다.</p>
<h3 id="소프트맥스와-크로스-엔트로피-손실-softmax-and-cross-entropy-loss"><a class="header" href="#소프트맥스와-크로스-엔트로피-손실-softmax-and-cross-entropy-loss">소프트맥스와 크로스 엔트로피 손실 (Softmax and Cross-Entropy Loss)</a></h3>
<p>:label:<code>subsec_softmax_and_derivatives</code></p>
<p>소프트맥스 함수와 그에 대응하는 크로스 엔트로피 손실은 매우 흔하기 때문에, 이들이 어떻게 계산되는지 조금 더 잘 이해할 가치가 있습니다.
:eqref:<code>eq_softmax_y_and_o</code>를 :eqref:<code>eq_l_cross_entropy</code>의 손실 정의에 대입하고 소프트맥스의 정의를 사용하면 다음을 얻습니다.</p>
<p>$$
\begin{aligned}
l(\mathbf{y}, \hat{\mathbf{y}}) &amp;=  - \sum_{j=1}^q y_j \log \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \
&amp;= \sum_{j=1}^q y_j \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j \
&amp;= \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j.
\end{aligned}
$$</p>
<p>무슨 일이 일어나고 있는지 조금 더 잘 이해하기 위해, 임의의 로짓(logit) $o_j$에 대한 도함수를 고려해 봅시다. 우리는 다음을 얻습니다.</p>
<p>$$
\partial_{o_j} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \mathrm{softmax}(\mathbf{o})_j - y_j.
$$</p>
<p>즉, 도함수는 소프트맥스 연산으로 표현되는 우리 모델에 의해 할당된 확률과, 원-핫 레이블 벡터의 원소들로 표현되는 실제 일어난 일 사이의 차이입니다.
이런 의미에서 이는 회귀에서 보았던 것과 매우 유사한데, 거기서 기울기는 관찰 $y$와 추정치 $\hat{y}$ 사이의 차이였습니다.
이것은 우연이 아닙니다. 임의의 지수족(exponential family) 모델에서 로그 우도의 기울기는 정확히 이 항으로 주어집니다. 이 사실은 실제로 기울기를 계산하는 것을 쉽게 만듭니다.</p>
<p>이제 단일 결과가 아니라 결과에 대한 전체 분포를 관찰하는 경우를 고려해 봅시다.
레이블 $\mathbf{y}$에 대해 이전과 동일한 표현을 사용할 수 있습니다.
유일한 차이점은 $(0, 0, 1)$과 같은 이진 항목만 포함된 벡터 대신, $(0.1, 0.2, 0.7)$과 같은 일반적인 확률 벡터를 갖는다는 것입니다.
:eqref:<code>eq_l_cross_entropy</code>에서 손실 $l$을 정의하기 위해 이전에 사용했던 수학은 여전히 잘 작동하며, 해석만 약간 더 일반적입니다.
이는 레이블에 대한 분포에 대한 손실의 기대값입니다.
이 손실을 <em>크로스 엔트로피 손실</em>이라고 하며 분류 문제에서 가장 흔히 사용되는 손실 중 하나입니다.
우리는 정보 이론의 기초만 도입함으로써 이 이름을 명확히 할 수 있습니다.
간단히 말해, 이는 우리가 예측한 일($\hat{\mathbf{y}}$)에 대해 우리가 본 것($\mathbf{y}$)을 인코딩하는 데 필요한 비트 수를 측정합니다.
다음에서 매우 기본적인 설명을 제공합니다. 정보 이론에 대한 자세한 내용은 :citet:<code>Cover.Thomas.1999</code> 또는 :citet:<code>mackay2003information</code>를 참조하십시오.</p>
<h2 id="정보-이론-기초-information-theory-basics"><a class="header" href="#정보-이론-기초-information-theory-basics">정보 이론 기초 (Information Theory Basics)</a></h2>
<p>:label:<code>subsec_info_theory_basics</code></p>
<p>많은 딥러닝 논문들이 정보 이론의 직관과 용어를 사용합니다.
이를 이해하기 위해서는 공통된 언어가 필요합니다.
이것은 생존 가이드입니다.
*정보 이론(Information theory)*은 정보(데이터라고도 함)를 인코딩, 디코딩, 전송 및 조작하는 문제를 다룹니다.</p>
<h3 id="엔트로피-entropy"><a class="header" href="#엔트로피-entropy">엔트로피 (Entropy)</a></h3>
<p>정보 이론의 핵심 아이디어는 데이터에 포함된 정보의 양을 정량화하는 것입니다.
이는 데이터를 압축하는 능력에 한계를 둡니다.
분포 $P$에 대해 그 <em>엔트로피(entropy)</em> $H[P]$는 다음과 같이 정의됩니다:</p>
<p>$$H[P] = \sum_j - P(j) \log P(j).$$
:eqlabel:<code>eq_softmax_reg_entropy</code></p>
<p>정보 이론의 근본적인 정리 중 하나는 분포 $P$에서 무작위로 추출된 데이터를 인코딩하기 위해 이를 인코딩하는 데 최소 $H[P]$ "나츠(nats)"가 필요하다는 것입니다 :cite:<code>Shannon.1948</code>.
"나츠"가 무엇인지 궁금하다면, 이는 밑이 2인 코드 대신 밑이 $e$인 코드를 사용할 때의 비트(bit)와 동등한 것입니다.
따라서 1 나츠는 $\frac{1}{\log(2)} \approx 1.44$ 비트입니다.</p>
<h3 id="놀람-surprisal"><a class="header" href="#놀람-surprisal">놀람 (Surprisal)</a></h3>
<p>압축이 예측과 무슨 상관이 있는지 궁금할 수 있습니다.
우리가 압축하고 싶은 데이터 스트림이 있다고 상상해 보십시오.
우리가 다음 토큰을 예측하는 것이 항상 쉽다면, 이 데이터는 압축하기 쉽습니다.
스트림의 모든 토큰이 항상 동일한 값을 갖는 극단적인 예를 들어봅시다.
그것은 매우 지루한 데이터 스트림입니다!
지루할 뿐만 아니라 예측하기도 쉽습니다.
토큰이 항상 동일하기 때문에 스트림의 내용을 전달하기 위해 어떠한 정보도 전송할 필요가 없습니다.
예측하기 쉬우면 압축하기 쉽습니다.</p>
<p>하지만 우리가 모든 사건을 완벽하게 예측할 수 없다면, 때때로 놀랄 수도 있습니다.
사건에 낮은 확률이 할당될 때 우리의 놀람은 더 큽니다.
클로드 섀넌(Claude Shannon)은 사건 $j$에 (주관적) 확률 $P(j)$를 할당했을 때 그 사건을 관찰하는 사람의 *놀람(surprisal)*을 정량화하기 위해 $\log \frac{1}{P(j)} = -\log P(j)$를 정했습니다.
:eqref:<code>eq_softmax_reg_entropy</code>에 정의된 엔트로피는 데이터 생성 프로세스와 진정으로 일치하는 올바른 확률을 할당했을 때의 *기대 놀람(expected surprisal)*입니다.</p>
<h3 id="크로스-엔트로피-다시-보기-cross-entropy-revisited"><a class="header" href="#크로스-엔트로피-다시-보기-cross-entropy-revisited">크로스 엔트로피 다시 보기 (Cross-Entropy Revisited)</a></h3>
<p>엔트로피가 실제 확률을 아는 사람이 경험하는 놀람의 수준이라면, 크로스 엔트로피란 무엇일까요?
$P$에서 $Q$로의 크로스 엔트로피(cross-entropy) $H(P, Q)$는, 확률 $P$에 따라 실제로 생성된 데이터를 보았을 때 주관적 확률 $Q$를 가진 관찰자의 기대 놀람입니다.
이는 $H(P, Q) \stackrel{\textrm{def}}{=} \sum_j - P(j) \log Q(j)$로 주어집니다.
가장 낮은 크로스 엔트로피는 $P=Q$일 때 달성됩니다.
이 경우 $P$에서 $Q$로의 크로스 엔트로피는 $H(P, P)= H(P)$입니다.</p>
<p>요컨대, 우리는 크로스 엔트로피 분류 목표를 두 가지 방식으로 생각할 수 있습니다: (i) 관찰된 데이터의 우도를 최대화하는 것; (ii) 레이블을 전달하는 데 필요한 우리의 놀람(따라서 비트 수)을 최소화하는 것.</p>
<h2 id="요약-및-토론-summary-and-discussion"><a class="header" href="#요약-및-토론-summary-and-discussion">요약 및 토론 (Summary and Discussion)</a></h2>
<p>이 섹션에서 우리는 <em>이산형</em> 출력 공간에 대해 최적화할 수 있게 해주는 첫 번째 비자명한 손실 함수를 만났습니다.
이 설계의 핵심은 우리가 확률론적 접근 방식을 취하여 이산 범주를 확률 분포에서 추출된 인스턴스로 취급했다는 것입니다.
부수적인 효과로, 일반적인 신경망 레이어의 출력을 유효한 이산 확률 분포로 변환하는 편리한 활성화 함수인 소프트맥스를 만났습니다.
우리는 소프트맥스와 결합된 크로스 엔트로피 손실의 도함수가 기대 행동과 그 예측 사이의 차이를 취함으로써 제곱 오차의 도함수와 매우 유사하게 동작한다는 것을 보았습니다.
그리고 비록 겉핥기만 할 수 있었지만, 통계 물리학 및 정보 이론과의 흥미로운 연결도 만났습니다.</p>
<p>비록 이것이 여러분이 나아가는 데 충분하고 여러분의 흥미를 끌기에 충분하기를 바라지만, 여기서는 깊이 파고들지 못했습니다.
무엇보다도 계산적인 고려 사항을 건너뛰었습니다.
구체적으로 $d$개의 입력과 $q$개의 출력이 있는 완전 연결 레이어의 경우 파라미터화 및 계산 비용은 $\mathcal{O}(dq)$이며, 이는 실제 상황에서 감당하기 힘들 정도로 높을 수 있습니다.
다행히 $d$개의 입력을 $q$개의 출력으로 변환하는 이 비용은 근사 및 압축을 통해 줄일 수 있습니다.
예를 들어 Deep Fried Convnets :cite:<code>Yang.Moczulski.Denil.ea.2015</code>는 순열, 푸리에 변환 및 스케일링의 조합을 사용하여 비용을 2차(quadratic)에서 로그-선형(log-linear)으로 줄입니다.
유사한 기술이 더 발전된 구조적 행렬 근사(structural matrix approximations)에도 적용됩니다 :cite:<code>sindhwani2015structured</code>.
마지막으로 쿼터니언(quaternion)과 유사한 분해를 사용하여 비용을 $\mathcal{O}(\frac{dq}{n})$으로 줄일 수 있는데, 이 역시 압축 계수 $n$을 기반으로 계산 및 저장 비용을 위해 약간의 정확도를 희생할 의향이 있다면 가능합니다 :cite:<code>Zhang.Tay.Zhang.ea.2021</code>.
이는 활발한 연구 분야입니다.
도전적인 점은 우리가 반드시 가장 간결한 표현이나 가장 적은 부동 소수점 연산 수를 추구하는 것이 아니라, 현대 GPU에서 가장 효율적으로 실행될 수 있는 솔루션을 추구한다는 것입니다.</p>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>지수족(exponential families)과 소프트맥스 사이의 연결을 좀 더 깊이 탐구할 수 있습니다.
<ol>
<li>소프트맥스에 대한 크로스 엔트로피 손실 $l(\mathbf{y},\hat{\mathbf{y}})$의 2계 도함수를 계산하십시오.</li>
<li>$\mathrm{softmax}(\mathbf{o})$에 의해 주어지는 분포의 분산을 계산하고 위에서 계산된 2계 도함수와 일치함을 보이십시오.</li>
</ol>
</li>
<li>동일한 확률로 발생하는 세 개의 클래스가 있다고 가정합니다. 즉, 확률 벡터는 $(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$입니다.
<ol>
<li>이에 대해 이진 코드를 설계하려고 할 때의 문제는 무엇입니까?</li>
<li>더 나은 코드를 설계할 수 있습니까? 힌트: 두 개의 독립적인 관찰을 인코딩하려고 하면 어떻게 될까요? $n$개의 관찰을 공동으로 인코딩하면 어떻게 될까요?</li>
</ol>
</li>
<li>물리적 전선을 통해 전송되는 신호를 인코딩할 때 엔지니어들은 항상 이진 코드를 사용하지는 않습니다. 예를 들어 <a href="https://en.wikipedia.org/wiki/Ternary_signal">PAM-3</a>는 두 개의 레벨 {0, 1} 대신 세 개의 신호 레벨 ${-1, 0, 1}$을 사용합니다. {0, ..., 7} 범위의 정수를 전송하려면 몇 개의 3진(ternary) 유닛이 필요합니까? 전자공학 측면에서 이것이 왜 더 좋은 아이디어일까요?</li>
<li><a href="https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model">브래들리-테리 모델(Bradley--Terry model)</a>은 선호도를 파악하기 위해 로지스틱 모델을 사용합니다. 사용자가 사과와 오렌지 중에서 선택하기 위해 점수 $o_{\textrm{apple}}$과 $o_{\textrm{orange}}$를 가정합니다. 우리의 요구 사항은 점수가 클수록 관련 항목을 선택할 가능성이 높아야 하고 점수가 가장 큰 항목이 선택될 가능성이 가장 높아야 한다는 것입니다 :cite:<code>Bradley.Terry.1952</code>.
<ol>
<li>소프트맥스가 이 요구 사항을 만족함을 증명하십시오.</li>
<li>사과와 오렌지 중 어느 것도 선택하지 않는 기본 옵션을 허용하려면 어떻게 해야 할까요? 힌트: 이제 사용자에게는 세 가지 선택지가 있습니다.</li>
</ol>
</li>
<li>소프트맥스는 다음 매핑에서 그 이름을 얻었습니다: $\textrm{RealSoftMax}(a, b) = \log (\exp(a) + \exp(b))$.
<ol>
<li>$\textrm{RealSoftMax}(a, b) &gt; \mathrm{max}(a, b)$임을 증명하십시오.</li>
<li>두 함수 사이의 차이를 얼마나 작게 만들 수 있습니까? 힌트: 일반성을 잃지 않고 $b = 0$ 및 $a \geq b$로 설정할 수 있습니다.</li>
<li>$\lambda &gt; 0$일 때, $\lambda^{-1} \textrm{RealSoftMax}(\lambda a, \lambda b)$에 대해 이것이 성립함을 증명하십시오.</li>
<li>$\lambda \to \infty$에 대해 $\lambda^{-1} \textrm{RealSoftMax}(\lambda a, \lambda b) \to \mathrm{max}(a, b)$임을 보이십시오.</li>
<li>유사한 softmin 함수를 구성하십시오.</li>
<li>이를 둘 이상의 숫자로 확장하십시오.</li>
</ol>
</li>
<li>함수 $g(\mathbf{x}) \stackrel{\textrm{def}}{=} \log \sum_i \exp x_i$는 때때로 <a href="https://en.wikipedia.org/wiki/Partition_function_(mathematics)">로그-분할 함수(log-partition function)</a>라고도 불립니다.
<ol>
<li>함수가 볼록(convex)함을 증명하십시오. 힌트: 이를 위해 1계 도함수가 소프트맥스 함수의 확률에 해당한다는 사실을 사용하고 2계 도함수가 분산임을 보이십시오.</li>
<li>$g$가 이동 불변(translation invariant)임을 보이십시오. 즉, $g(\mathbf{x} + b) = g(\mathbf{x})$.</li>
<li>좌표 $x_i$ 중 일부가 매우 크면 어떻게 됩니까? 모두 매우 작으면 어떻게 됩니까?</li>
<li>$b = \mathrm{max}_i x_i$를 선택하면 수치적으로 안정적인 구현을 얻게 됨을 보이십시오.</li>
</ol>
</li>
<li>어떤 확률 분포 $P$가 있다고 가정합니다. $\alpha &gt; 0$에 대해 $Q(i) \propto P(i)^\alpha$인 다른 분포 $Q$를 선택한다고 가정합시다.
<ol>
<li>어떤 $\alpha$ 선택이 온도를 두 배로 높이는 것에 해당합니까? 어떤 선택이 온도를 절반으로 줄이는 것에 해당합니까?</li>
<li>온도가 0에 가까워지게 하면 어떻게 됩니까?</li>
<li>온도가 $\infty$에 가까워지게 하면 어떻게 됩니까?</li>
</ol>
</li>
</ol>
<p><a href="https://discuss.d2l.ai/t/46">토론</a></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_linear-classification/index.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_linear-classification/image-classification-dataset.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_linear-classification/index.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_linear-classification/image-classification-dataset.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
