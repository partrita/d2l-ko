<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>분포 (Distributions) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html" class="active"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="분포-distributions"><a class="header" href="#분포-distributions">분포 (Distributions)</a></h1>
<p>:label:<code>sec_distributions</code></p>
<p>이산형 및 연속형 설정 모두에서 확률을 다루는 방법을 배웠으므로, 이제 흔히 마주치는 몇 가지 일반적인 분포를 알아봅시다. 머신러닝 분야에 따라 이보다 훨씬 더 많은 분포에 익숙해져야 할 수도 있고, 딥러닝의 일부 분야에서는 아예 필요하지 않을 수도 있습니다. 하지만 이것은 익숙해지기에 좋은 기본 목록입니다. 먼저 몇 가지 일반적인 라이브러리를 가져옵시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
%matplotlib inline
from d2l import mxnet as d2l
from IPython import display
from math import erf, factorial
import numpy as np
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
%matplotlib inline
from d2l import torch as d2l
from IPython import display
from math import erf, factorial
import torch

torch.pi = torch.acos(torch.zeros(1)) * 2  # torch에서 pi 정의
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
%matplotlib inline
from d2l import tensorflow as d2l
from IPython import display
from math import erf, factorial
import tensorflow as tf
import tensorflow_probability as tfp

tf.pi = tf.acos(tf.zeros(1)) * 2  # TensorFlow에서 pi 정의
</code></pre>
<h2 id="베르누이-분포-bernoulli"><a class="header" href="#베르누이-분포-bernoulli">베르누이 분포 (Bernoulli)</a></h2>
<p>이것은 일반적으로 마주치는 가장 단순한 확률 변수입니다. 이 확률 변수는 $p$의 확률로 $1$이 나오고 $1-p$의 확률로 $0$이 나오는 동전 던지기를 인코딩합니다. 이 분포를 가진 확률 변수 $X$가 있다면 다음과 같이 씁니다.</p>
<p>$$
X sim 	extrm{Bernoulli}(p).
$$</p>
<p>누적 분포 함수는 다음과 같습니다.</p>
<p>$$F(x) = \begin{cases}
0 &amp; x &lt; 0, \
1-p &amp; 0 \le x &lt; 1, \
1 &amp; x &gt;= 1 .
\end{cases}$$
:eqlabel:<code>eq_bernoulli_cdf</code></p>
<p>확률 질량 함수(pmf)는 아래에 플롯되어 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab all
p = 0.3

d2l.set_figsize()
d2l.plt.stem([0, 1], [1 - p, p], use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<p>이제 누적 분포 함수 :eqref:<code>eq_bernoulli_cdf</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
x = np.arange(-1, 2, 0.01)

def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; 1 else 1 - p

d2l.plot(x, np.array([F(y) for y in x]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
x = torch.arange(-1, 2, 0.01)

def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; 1 else 1 - p

d2l.plot(x, torch.tensor([F(y) for y in x]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
x = tf.range(-1, 2, 0.01)

def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; 1 else 1 - p

d2l.plot(x, tf.constant([F(y) for y in x]), 'x', 'c.d.f.')
</code></pre>
<p>$X sim 	extrm{Bernoulli}(p)$이면 다음이 성립합니다.</p>
<ul>
<li>$\mu_X = p$,</li>
<li>$\sigma_X^2 = p(1-p)$.</li>
</ul>
<p>다음과 같이 베르누이 확률 변수로부터 임의의 모양의 배열을 샘플링할 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
1*(np.random.rand(10, 10) &lt; p)
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
1*(torch.rand(10, 10) &lt; p)
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
tf.cast(tf.random.uniform((10, 10)) &lt; p, dtype=tf.float32)
</code></pre>
<h2 id="이산-균등-분포-discrete-uniform"><a class="header" href="#이산-균등-분포-discrete-uniform">이산 균등 분포 (Discrete Uniform)</a></h2>
<p>다음으로 흔히 마주치는 확률 변수는 이산 균등 분포입니다. 여기서 논의를 위해 정수 ${1, 2, \ldots, n}$에서 지원된다고 가정하겠지만, 다른 어떤 값의 집합도 자유롭게 선택할 수 있습니다. 이 문맥에서 *균등(uniform)*이라는 단어의 의미는 모든 가능한 값이 동등하게 가능성이 높다는 것입니다. 각 값 $i sin {1, 2, 3, \ldots, n}$에 대한 확률은 $p_i = \frac{1}{n}$입니다. 이 분포를 가진 확률 변수 $X$를 다음과 같이 나타낼 것입니다.</p>
<p>$$
X sim U(n).
$$</p>
<p>누적 분포 함수는 다음과 같습니다.</p>
<p>$$F(x) = \begin{cases}
0 &amp; x &lt; 1, \
\frac{k}{n} &amp; k \le x &lt; k+1 \textrm{ 이며 } 1 \le k &lt; n, \
1 &amp; x &gt;= n .
\end{cases}$$
:eqlabel:<code>eq_discrete_uniform_cdf</code></p>
<p>먼저 확률 질량 함수를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab all
n = 5

d2l.plt.stem([i+1 for i in range(n)], n*[1 / n], use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<p>이제 누적 분포 함수 :eqref:<code>eq_discrete_uniform_cdf</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
x = np.arange(-1, 6, 0.01)

def F(x):
    return 0 if x &lt; 1 else 1 if x &gt; n else np.floor(x) / n

d2l.plot(x, np.array([F(y) for y in x]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
x = torch.arange(-1, 6, 0.01)

def F(x):
    return 0 if x &lt; 1 else 1 if x &gt; n else torch.floor(x) / n

d2l.plot(x, torch.tensor([F(y) for y in x]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
x = tf.range(-1, 6, 0.01)

def F(x):
    return 0 if x &lt; 1 else 1 if x &gt; n else tf.floor(x) / n

d2l.plot(x, [F(y) for y in x], 'x', 'c.d.f.')
</code></pre>
<p>$X sim U(n)$이면 다음이 성립합니다.</p>
<ul>
<li>$\mu_X = \frac{1+n}{2}$,</li>
<li>$\sigma_X^2 = \frac{n^2-1}{12}$.</li>
</ul>
<p>다음과 같이 이산 균등 확률 변수로부터 임의의 모양의 배열을 샘플링할 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
np.random.randint(1, n, size=(10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
torch.randint(1, n, size=(10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
tf.random.uniform((10, 10), 1, n, dtype=tf.int32)
</code></pre>
<h2 id="연속-균등-분포-continuous-uniform"><a class="header" href="#연속-균등-분포-continuous-uniform">연속 균등 분포 (Continuous Uniform)</a></h2>
<p>다음으로 연속 균등 분포에 대해 논의해 봅시다. 이 확률 변수 뒤에 숨겨진 아이디어는 이산 균등 분포에서 $n$을 늘리고 구간 $[a, b]$ 내에 맞도록 스케일을 조정하면, $[a, b]$ 내의 임의의 값을 모두 동일한 확률로 선택하는 연속 확률 변수에 접근하게 된다는 것입니다. 이 분포를 다음과 같이 나타낼 것입니다.</p>
<p>$$
X sim U(a, b).
$$</p>
<p>확률 밀도 함수(pdf)는 다음과 같습니다.</p>
<p>$$p(x) = \begin{cases}
\frac{1}{b-a} &amp; x sin [a, b], \
0 &amp; x \notsin [a, b].
\end{cases}$$
:eqlabel:<code>eq_cont_uniform_pdf</code></p>
<p>누적 분포 함수는 다음과 같습니다.</p>
<p>$$F(x) = \begin{cases}
0 &amp; x &lt; a, \
\frac{x-a}{b-a} &amp; x sin [a, b], \
1 &amp; x &gt;= b .
\end{cases}$$
:eqlabel:<code>eq_cont_uniform_cdf</code></p>
<p>먼저 확률 밀도 함수 :eqref:<code>eq_cont_uniform_pdf</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
a, b = 1, 3

x = np.arange(0, 4, 0.01)
p = (x &gt; a)*(x &lt; b)/(b - a)

d2l.plot(x, p, 'x', 'p.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
a, b = 1, 3

x = torch.arange(0, 4, 0.01)
p = (x &gt; a).type(torch.float32)*(x &lt; b).type(torch.float32)/(b-a)
d2l.plot(x, p, 'x', 'p.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
a, b = 1, 3

x = tf.range(0, 4, 0.01)
p = tf.cast(x &gt; a, tf.float32) * tf.cast(x &lt; b, tf.float32) / (b - a)
d2l.plot(x, p, 'x', 'p.d.f.')
</code></pre>
<p>이제 누적 분포 함수 :eqref:<code>eq_cont_uniform_cdf</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
def F(x):
    return 0 if x &lt; a else 1 if x &gt; b else (x - a) / (b - a)

d2l.plot(x, np.array([F(y) for y in x]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
def F(x):
    return 0 if x &lt; a else 1 if x &gt; b else (x - a) / (b - a)

d2l.plot(x, torch.tensor([F(y) for y in x]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
def F(x):
    return 0 if x &lt; a else 1 if x &gt; b else (x - a) / (b - a)

d2l.plot(x, [F(y) for y in x], 'x', 'c.d.f.')
</code></pre>
<p>$X sim U(a, b)$이면 다음이 성립합니다.</p>
<ul>
<li>$\mu_X = \frac{a+b}{2}$,</li>
<li>$\sigma_X^2 = \frac{(b-a)^2}{12}$.</li>
</ul>
<p>다음과 같이 균등 확률 변수로부터 임의의 모양의 배열을 샘플링할 수 있습니다. 기본적으로 $U(0,1)$에서 샘플링하므로 다른 범위를 원하면 스케일을 조정해야 합니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
(b - a) * np.random.rand(10, 10) + a
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
(b - a) * torch.rand(10, 10) + a
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
(b - a) * tf.random.uniform((10, 10)) + a
</code></pre>
<h2 id="이항-분포-binomial"><a class="header" href="#이항-분포-binomial">이항 분포 (Binomial)</a></h2>
<p>상황을 좀 더 복잡하게 만들어 <em>이항(binomial)</em> 확률 변수를 살펴봅시다. 이 확률 변수는 성공 확률이 $p$인 $n$개의 독립적인 실험 시퀀스를 수행하고, 우리가 얼마나 많은 성공을 볼 것으로 기대하는지 묻는 것에서 비롯됩니다.</p>
<p>이를 수학적으로 표현해 봅시다. 각 실험은 독립 확률 변수 $X_i$이며, 여기서 성공을 인코딩하기 위해 $1$을 사용하고 실패를 인코딩하기 위해 $0$을 사용합니다. 각각이 확률 $p$로 성공하는 독립적인 동전 던지기이므로, $X_i sim 	extrm{Bernoulli}(p)$라고 말할 수 있습니다. 그러면 이항 확률 변수는 다음과 같습니다.</p>
<p>$$
X = \sum_{i=1}^n X_i.
$$</p>
<p>이 경우 다음과 같이 씁니다.</p>
<p>$$
X sim 	extrm{Binomial}(n, p).
$$</p>
<p>누적 분포 함수를 얻으려면, 정확히 $k$번 성공하는 것이 $inom{n}{k} = \frac{n!}{k!(n-k)!}$가지 방식으로 발생할 수 있고 각 방식은 발생 확률 $p^k(1-p)^{n-k}$를 갖는다는 점에 유의해야 합니다. 따라서 누적 분포 함수는 다음과 같습니다.</p>
<p>$$F(x) = \begin{cases}
0 &amp; x &lt; 0, \
\sum_{m \le k} inom{n}{m} p^m(1-p)^{n-m}  &amp; k \le x &lt; k+1 \textrm{ 이며 } 0 \le k &lt; n, \
1 &amp; x &gt;= n .
\end{cases}$$
:eqlabel:<code>eq_binomial_cdf</code></p>
<p>먼저 확률 질량 함수를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
n, p = 10, 0.2

# 이항 계수 계산
def binom(n, k):
    comb = 1
    for i in range(min(k, n - k)):
        comb = comb * (n - i) // (i + 1)
    return comb

pmf = np.array([p**i * (1-p)**(n - i) * binom(n, i) for i in range(n + 1)])

d2l.plt.stem([i for i in range(n + 1)], pmf, use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
n, p = 10, 0.2

# 이항 계수 계산
def binom(n, k):
    comb = 1
    for i in range(min(k, n - k)):
        comb = comb * (n - i) // (i + 1)
    return comb

pmf = d2l.tensor([p**i * (1-p)**(n - i) * binom(n, i) for i in range(n + 1)])

d2l.plt.stem([i for i in range(n + 1)], pmf, use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
n, p = 10, 0.2

# 이항 계수 계산
def binom(n, k):
    comb = 1
    for i in range(min(k, n - k)):
        comb = comb * (n - i) // (i + 1)
    return comb

pmf = tf.constant([p**i * (1-p)**(n - i) * binom(n, i) for i in range(n + 1)])

d2l.plt.stem([i for i in range(n + 1)], pmf, use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<p>이제 누적 분포 함수 :eqref:<code>eq_binomial_cdf</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
x = np.arange(-1, 11, 0.01)
cmf = np.cumsum(pmf)

def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; n else cmf[int(x)]

d2l.plot(x, np.array([F(y) for y in x.tolist()]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
x = torch.arange(-1, 11, 0.01)
cmf = torch.cumsum(pmf, dim=0)

def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; n else cmf[int(x)]

d2l.plot(x, torch.tensor([F(y) for y in x.tolist()]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
x = tf.range(-1, 11, 0.01)
cmf = tf.cumsum(pmf)

def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; n else cmf[int(x)]

d2l.plot(x, [F(y) for y in x.numpy().tolist()], 'x', 'c.d.f.')
</code></pre>
<p>$X sim 	extrm{Binomial}(n, p)$이면 다음이 성립합니다.</p>
<ul>
<li>$\mu_X = np$,</li>
<li>$\sigma_X^2 = np(1-p)$.</li>
</ul>
<p>이는 $n$개의 베르누이 확률 변수의 합에 대한 기댓값의 선형성과, 독립 확률 변수 합의 분산은 분산의 합이라는 사실로부터 따릅니다. 이는 다음과 같이 샘플링될 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
np.random.binomial(n, p, size=(10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
m = torch.distributions.binomial.Binomial(n, p)
m.sample(sample_shape=(10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
m = tfp.distributions.Binomial(n, p)
m.sample(sample_shape=(10, 10))
</code></pre>
<h2 id="포아송-분포-poisson"><a class="header" href="#포아송-분포-poisson">포아송 분포 (Poisson)</a></h2>
<p>이제 사고 실험을 해봅시다. 우리는 버스 정류장에 서 있고 다음 1분 동안 몇 대의 버스가 도착할지 알고 싶습니다. 먼저 1분 윈도우 내에 버스가 도착할 확률인 $X^{(1)} sim 	extrm{Bernoulli}(p)$를 고려하는 것으로 시작하겠습니다. 도심에서 멀리 떨어진 버스 정류장의 경우, 이것은 꽤 좋은 근사일 수 있습니다. 우리는 1분 내에 한 대 이상의 버스를 결코 보지 못할 수도 있습니다.</p>
<p>그러나 우리가 붐비는 지역에 있다면 두 대의 버스가 도착할 가능성이 있거나 심지어 높을 수 있습니다. 우리는 우리의 확률 변수를 처음 30초 또는 뒤의 30초에 대한 두 부분으로 나누어 이를 모델링할 수 있습니다. 이 경우 다음과 같이 쓸 수 있습니다.</p>
<p>$$
X^{(2)} sim X^{(2)}_1 + X^{(2)}_2,
$$</p>
<p>여기서 $X^{(2)}$는 총 합이고 $X^{(2)}_i sim 	extrm{Bernoulli}(p/2)$입니다. 그러면 총 분포는 $X^{(2)} sim 	extrm{Binomial}(2, p/2)$가 됩니다.</p>
<p>여기서 멈출 이유가 있을까요? 그 1분을 $n$개 부분으로 계속 나누어 봅시다. 위와 동일한 추론에 의해 다음을 알 수 있습니다.</p>
<p>$$X^{(n)} sim 	extrm{Binomial}(n, p/n).$$
:eqlabel:<code>eq_eq_poisson_approx</code></p>
<p>이러한 확률 변수들을 고려해 보십시오. 이전 섹션에 의해 :eqref:<code>eq_eq_poisson_approx</code>은 평균 $\mu_{X^{(n)}} = n(p/n) = p$와 분산 $\sigma_{X^{(n)}}^2 = n(p/n)(1-(p/n)) = p(1-p/n)$를 가짐을 압니다. 만약 $n
ightarrow \infty$이면, 이러한 수치들이 평균 $\mu_{X^{(\infty)}} = p$와 분산 $\sigma_{X^{(\infty)}}^2 = p$로 안정화되는 것을 볼 수 있습니다. 이는 이 무한 분할 극한에서 우리가 정의할 수 있는 어떤 확률 변수가 <em>있을 수 있음</em>을 나타냅니다.</p>
<p>실제 세계에서 우리는 단순히 버스 도착 횟수를 셀 수 있기 때문에 이것은 그리 놀라운 일이 아니어야 하지만, 우리의 수학적 모델이 잘 정의되어 있다는 것을 보는 것은 좋습니다. 이 논의는 *희귀 사건의 법칙(law of rare events)*으로 공식화될 수 있습니다.</p>
<p>이 추론을 신중하게 따라가면 다음과 같은 모델에 도달할 수 있습니다. 확률 변수 $X$가 ${0,1,2, \ldots}$ 값을 다음 확률로 가질 때 $X sim 	extrm{Poisson}(\lambda)$라고 말할 것입니다.</p>
<p>$$p_k = \frac{\lambda^ke^{-\lambda}}{k!}.$$
:eqlabel:<code>eq_poisson_mass</code></p>
<p>값 $\lambda &gt; 0$은 <em>강도(rate)</em> (또는 <em>형태(shape)</em> 파라미터)라고 알려져 있으며, 단위 시간당 우리가 기대하는 평균 도착 횟수를 나타냅니다.</p>
<p>이 확률 질량 함수를 합산하여 누적 분포 함수를 얻을 수 있습니다.</p>
<p>$$F(x) = \begin{cases}
0 &amp; x &lt; 0, \
e^{-\lambda}\sum_{m = 0}^k rac{\lambda^m}{m!} &amp; k \le x &lt; k+1 \textrm{ 이며 } 0 \le k.
\end{cases}$$
:eqlabel:<code>eq_poisson_cdf</code></p>
<p>먼저 확률 질량 함수 :eqref:<code>eq_poisson_mass</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
lam = 5.0

xs = [i for i in range(20)]
pmf = np.array([np.exp(-lam) * lam**k / factorial(k) for k in xs])

d2l.plt.stem(xs, pmf, use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
lam = 5.0

xs = [i for i in range(20)]
pmf = torch.tensor([torch.exp(torch.tensor(-lam)) * lam**k
                    / factorial(k) for k in xs])

d2l.plt.stem(xs, pmf, use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
lam = 5.0

xs = [i for i in range(20)]
pmf = tf.constant([tf.exp(tf.constant(-lam)).numpy() * lam**k
                    / factorial(k) for k in xs])

d2l.plt.stem(xs, pmf, use_line_collection=True)
d2l.plt.xlabel('x')
d2l.plt.ylabel('p.m.f.')
d2l.plt.show()
</code></pre>
<p>이제 누적 분포 함수 :eqref:<code>eq_poisson_cdf</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
x = np.arange(-1, 21, 0.01)
cmf = np.cumsum(pmf)
def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; n else cmf[int(x)]

d2l.plot(x, np.array([F(y) for y in x.tolist()]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
x = torch.arange(-1, 21, 0.01)
cmf = torch.cumsum(pmf, dim=0)
def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; n else cmf[int(x)]

d2l.plot(x, torch.tensor([F(y) for y in x.tolist()]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
x = tf.range(-1, 21, 0.01)
cmf = tf.cumsum(pmf)
def F(x):
    return 0 if x &lt; 0 else 1 if x &gt; n else cmf[int(x)]

d2l.plot(x, [F(y) for y in x.numpy().tolist()], 'x', 'c.d.f.')
</code></pre>
<p>위에서 보았듯이 평균과 분산은 특히 간결합니다. $X sim 	extrm{Poisson}(\lambda)$이면 다음이 성립합니다.</p>
<ul>
<li>$\mu_X = \lambda$,</li>
<li>$\sigma_X^2 = \lambda$.</li>
</ul>
<p>이는 다음과 같이 샘플링될 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
np.random.poisson(lam, size=(10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
m = torch.distributions.poisson.Poisson(lam)
m.sample((10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
m = tfp.distributions.Poisson(lam)
m.sample((10, 10))
</code></pre>
<h2 id="가우스-분포-gaussian"><a class="header" href="#가우스-분포-gaussian">가우스 분포 (Gaussian)</a></h2>
<p>이제 다르지만 관련된 실험을 시도해 봅시다. 우리가 다시 $n$개의 독립적인 $	extrm{Bernoulli}(p)$ 측정 $X_i$를 수행한다고 가정합시다. 이들의 합의 분포는 $X^{(n)} sim 	extrm{Binomial}(n, p)$입니다. $n$이 증가하고 $p$가 감소할 때 극한을 취하는 대신, $p$를 고정하고 $n
ightarrow \infty$로 보냅시다. 이 경우 $\mu_{X^{(n)}} = np
ightarrow \infty$이고 $\sigma_{X^{(n)}}^2 = np(1-p)
ightarrow \infty$이므로, 이 극한이 잘 정의될 것이라고 생각할 이유가 없습니다.</p>
<p>그러나 모든 희망이 사라진 것은 아닙니다! 다음과 같이 정의하여 평균과 분산이 잘 작동하도록 만들어 봅시다.</p>
<p>$$
Y^{(n)} = \frac{X^{(n)} - \mu_{X^{(n)}}}{\sigma_{X^{(n)}}}.
$$</p>
<p>이것은 평균 0과 분산 1을 갖는 것을 알 수 있으며, 따라서 어떤 극한 분포로 수렴할 것이라고 믿는 것이 그럴듯합니다. 이러한 분포들이 어떻게 생겼는지 플롯해 보면, 그것이 작동할 것이라고 더욱 확신하게 될 것입니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
p = 0.2
ns = [1, 10, 100, 1000]
d2l.plt.figure(figsize=(10, 3))
for i in range(4):
    n = ns[i]
    pmf = np.array([p**i * (1-p)**(n-i) * binom(n, i) for i in range(n + 1)])
    d2l.plt.subplot(1, 4, i + 1)
    d2l.plt.stem([(i - n*p)/np.sqrt(n*p*(1 - p)) for i in range(n + 1)], pmf,
                 use_line_collection=True)
    d2l.plt.xlim([-4, 4])
    d2l.plt.xlabel('x')
    d2l.plt.ylabel('p.m.f.')
    d2l.plt.title("n = {}".format(n))
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
p = 0.2
ns = [1, 10, 100, 1000]
d2l.plt.figure(figsize=(10, 3))
for i in range(4):
    n = ns[i]
    pmf = torch.tensor([p**i * (1-p)**(n-i) * binom(n, i)
                        for i in range(n + 1)])
    d2l.plt.subplot(1, 4, i + 1)
    d2l.plt.stem([(i - n*p)/torch.sqrt(torch.tensor(n*p*(1 - p)))
                  for i in range(n + 1)], pmf,
                 use_line_collection=True)
    d2l.plt.xlim([-4, 4])
    d2l.plt.xlabel('x')
    d2l.plt.ylabel('p.m.f.')
    d2l.plt.title("n = {}".format(n))
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
p = 0.2
ns = [1, 10, 100, 1000]
d2l.plt.figure(figsize=(10, 3))
for i in range(4):
    n = ns[i]
    pmf = tf.constant([p**i * (1-p)**(n-i) * binom(n, i)
                        for i in range(n + 1)])
    d2l.plt.subplot(1, 4, i + 1)
    d2l.plt.stem([(i - n*p)/tf.sqrt(tf.constant(n*p*(1 - p)))
                  for i in range(n + 1)], pmf,
                 use_line_collection=True)
    d2l.plt.xlim([-4, 4])
    d2l.plt.xlabel('x')
    d2l.plt.ylabel('p.m.f.')
    d2l.plt.title("n = {}".format(n))
d2l.plt.show()
</code></pre>
<p>한 가지 주목할 점은 포아송 사례와 비교하여 이제 표준 편차로 나누고 있다는 점인데, 이는 가능한 결과들을 점점 더 작은 영역으로 짜내고 있다는 것을 의미합니다. 이는 우리의 극한이 더 이상 이산적이지 않고 오히려 연속적일 것임을 나타냅니다.</p>
<p>발생하는 일에 대한 유도는 이 문서의 범위를 벗어나지만, *중심 극한 정리(central limit theorem)*는 $n
ightarrow \infty$에 따라 이것이 가우스 분포(또는 정규 분포)를 낳을 것이라고 기술합니다. 더 명시적으로, 임의의 $a, b$에 대해 다음과 같습니다.</p>
<p>$$
\lim_{n
ightarrow \infty} P(Y^{(n)} sin [a, b]) = P(r(0,1) sin [a, b]),
$$</p>
<p>여기서 우리는 확률 변수가 주어진 평균 $\mu$와 분산 $\sigma^2$를 가진 정규 분포를 따른다고 말하며, $X sim \mathcal N(\mu, \sigma^2)$라고 씁니다. 만약 $X$가 다음과 같은 밀도를 갖는다면 말입니다.</p>
<p>$$p_X(x) = \frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}.$$
:eqlabel:<code>eq_gaussian_pdf</code></p>
<p>먼저 확률 밀도 함수 :eqref:<code>eq_gaussian_pdf</code>를 플롯해 봅시다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
mu, sigma = 0, 1

x = np.arange(-3, 3, 0.01)
p = 1 / np.sqrt(2 * np.pi * sigma**2) * np.exp(-(x - mu)**2 / (2 * sigma**2))

d2l.plot(x, p, 'x', 'p.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
mu, sigma = 0, 1

x = torch.arange(-3, 3, 0.01)
p = 1 / torch.sqrt(2 * torch.pi * sigma**2) * torch.exp(
    -(x - mu)**2 / (2 * sigma**2))

d2l.plot(x, p, 'x', 'p.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
mu, sigma = 0, 1

x = tf.range(-3, 3, 0.01)
p = 1 / tf.sqrt(2 * tf.pi * sigma**2) * tf.exp(
    -(x - mu)**2 / (2 * sigma**2))

d2l.plot(x, p, 'x', 'p.d.f.')
</code></pre>
<p>이제 누적 분포 함수를 플롯해 봅시다. 이 부록의 범위를 벗어나지만, 가우스 c.d.f.는 더 기초적인 함수들로 된 닫힌 형식의 공식이 없습니다. 우리는 이 적분을 수치적으로 계산하는 방법을 제공하는 <code>erf</code>를 사용할 것입니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
def phi(x):
    return (1.0 + erf((x - mu) / (sigma * np.sqrt(2)))) / 2.0

d2l.plot(x, np.array([phi(y) for y in x.tolist()]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
def phi(x):
    return (1.0 + erf((x - mu) / (sigma * torch.sqrt(d2l.tensor(2.))))) / 2.0

d2l.plot(x, torch.tensor([phi(y) for y in x.tolist()]), 'x', 'c.d.f.')
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
def phi(x):
    return (1.0 + erf((x - mu) / (sigma * tf.sqrt(tf.constant(2.))))) / 2.0

d2l.plot(x, [phi(y) for y in x.numpy().tolist()], 'x', 'c.d.f.')
</code></pre>
<p>눈치 빠른 독자들은 이러한 용어 중 일부를 알아볼 것입니다. 실제로 우리는 이 적분을 :numref:<code>sec_integral_calculus</code>에서 만났습니다. 실제로 이 $p_X(x)$가 총 면적 1을 가지며 따라서 유효한 밀도임을 확인하려면 정확히 그 계산이 필요합니다.</p>
<p>동전 던지기로 작업하기로 한 우리의 선택은 계산을 짧게 만들었지만, 그 선택에 근본적인 것은 아무것도 없었습니다. 실제로 임의의 독립적인 동일 분포 확률 변수 $X_i$ 모음을 취하고 다음을 형성하면</p>
<p>$$
X^{(N)} = \sum_{i=1}^N X_i.
$$</p>
<p>그러면</p>
<p>$$
\frac{X^{(N)} - \mu_{X^{(N)}}}{\sigma_{X^{(N)}}}
$$</p>
<p>은 대략적으로 가우스 분포를 따를 것입니다. 이를 작동시키기 위해 필요한 추가 요구 사항들이 있으며, 가장 흔한 것은 $E[X^4] &lt; \infty$이지만 철학은 명확합니다.</p>
<p>중심 극한 정리는 왜 가우스 분포가 확률, 통계, 머신러닝의 기초가 되는지 설명해 주는 이유입니다. 우리가 측정한 무언가가 많은 작은 독립적인 기여의 합이라고 말할 수 있을 때마다, 측정되는 대상이 가우스 분포에 가까울 것이라고 가정할 수 있습니다.</p>
<p>가우스 분포에는 훨씬 더 많은 흥미로운 속성들이 있으며, 여기서 하나 더 논의하고 싶습니다. 가우스 분포는 *최대 엔트로피 분포(maximum entropy distribution)*로 알려진 것입니다. 우리는 :numref:<code>sec_information_theory</code>에서 엔트로피에 대해 더 깊이 다루겠지만, 지금 시점에서 알아야 할 모든 것은 그것이 무작위성의 척도라는 것입니다. 엄밀한 수학적 의미에서, 우리는 가우스 분포를 고정된 평균과 분산을 가진 확률 변수의 <em>가장</em> 무작위적인 선택으로 생각할 수 있습니다. 따라서 우리의 확률 변수가 어떤 평균과 분산을 갖는다는 것을 안다면, 가우스 분포는 어떤 의미에서 우리가 할 수 있는 가장 보수적인 분포 선택입니다.</p>
<p>섹션을 마무리하기 위해 $X sim \mathcal N(\mu, \sigma^2)$이면 다음이 성립함을 상기합시다.</p>
<ul>
<li>$\mu_X = \mu$,</li>
<li>$\sigma_X^2 = \sigma^2$.</li>
</ul>
<p>아래와 같이 가우스(또는 표준 정규) 분포로부터 샘플링할 수 있습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
np.random.normal(mu, sigma, size=(10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
torch.normal(mu, sigma, size=(10, 10))
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
tf.random.normal((10, 10), mu, sigma)
</code></pre>
<h2 id="지수족-exponential-family"><a class="header" href="#지수족-exponential-family">지수족 (Exponential Family)</a></h2>
<p>:label:<code>subsec_exponential_family</code></p>
<p>위에 나열된 모든 분포의 한 가지 공유된 속성은 그것들이 모두 *지수족(exponential family)*이라고 알려진 것에 속한다는 것입니다. 지수족은 밀도가 다음과 같은 형태로 표현될 수 있는 분포들의 집합입니다.</p>
<p>$$p(\mathbf{x} \mid \boldsymbol{\eta}) = h(\mathbf{x}) \cdot \exp
\left( \boldsymbol{\eta}^{\top} \cdot T(\mathbf{x}) - A(\boldsymbol{\eta})
\right)
$$
:eqlabel:<code>eq_exp_pdf</code></p>
<p>이 정의는 약간 미묘할 수 있으므로 자세히 살펴봅시다.</p>
<p>먼저, $h(\mathbf{x})$는 <em>기저 척도(underlying measure)</em> 또는 *베이스 척도(base measure)*로 알려져 있습니다. 이는 우리가 지수 가중치로 수정하고 있는 원래의 척도 선택으로 볼 수 있습니다.</p>
<p>둘째, <em>자연 파라미터(natural parameters)</em> 또는 *표준 파라미터(canonical parameters)*라고 불리는 벡터 $\boldsymbol{\eta} = (\eta_1, \eta_2, ..., \eta_l) sin
\mathbb{R}^l$가 있습니다. 이들은 베이스 척도가 어떻게 수정될지를 정의합니다. 자연 파라미터는 이러한 파라미터와 $\mathbf{x}= (x_1, x_2, ..., x_n) sin
\mathbb{R}^n$의 어떤 함수 $T(\cdot)$ 사이의 내적을 취하고 지수화함으로써 새로운 척도로 들어갑니다. 벡터 $T(\mathbf{x})= (T_1(\mathbf{x}), T_2(\mathbf{x}), ..., T_l(\mathbf{x}))$는 $\boldsymbol{\eta}$에 대한 *충분 통계량(sufficient statistics)*이라고 불립니다. 이 이름은 $T(\mathbf{x})$로 표현된 정보가 확률 밀도를 계산하기에 충분하며 샘플 $\mathbf{x}$로부터의 다른 정보는 필요하지 않기 때문에 사용됩니다.</p>
<p>셋째, *큐뮬런트 함수(cumulant function)*라고 지칭되는 $A(\boldsymbol{\eta})$가 있으며, 이는 위의 분포 :eqref:<code>eq_exp_pdf</code>가 1로 적분되도록 보장합니다. 즉, 다음과 같습니다.</p>
<p>$$A(\boldsymbol{\eta})  = \log
\left[\int h(\mathbf{x}) \cdot \exp
\left(\boldsymbol{\eta}^{\top} \cdot T(\mathbf{x})
\right) d\mathbf{x}
\right].$$</p>
<p>구체적으로 가우스 분포를 고려해 봅시다. $\mathbf{x}$가 일변량 변수라고 가정할 때, 우리는 그것이 다음과 같은 밀도를 가짐을 보았습니다.</p>
<p>$$
\begin{aligned}
p(x \mid \mu, \sigma) &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \cdot
\exp
\left{
\frac{-(x-\mu)^2}{2 \sigma^2}
\right} \
&amp;= \frac{1}{\sqrt{2 \pi}} \cdot
\exp
\left{
\frac{\mu}{\sigma^2}x
-\frac{1}{2 \sigma^2} x^2 -
\left(
\frac{1}{2 \sigma^2} \mu^2
+\log(\sigma)
\right)
\right}.
\end{aligned}
$$</p>
<p>이는 지수족의 정의와 다음과 같이 일치합니다.</p>
<ul>
<li><em>기저 척도</em>: $h(x) = \frac{1}{\sqrt{2 \pi}}$,</li>
<li><em>자연 파라미터</em>: $\boldsymbol{\eta} = egin{bmatrix} ̣́\eta_1 \ \eta_2
\end{bmatrix} = egin{bmatrix} rac{\mu}{\sigma^2} \ rac{1}{2 \sigma^2}
\end{bmatrix}$,</li>
<li><em>충분 통계량</em>: $T(x) = egin{bmatrix}x-x^2
\end{bmatrix}$,</li>
<li><em>큐뮬런트 함수</em>: $A({\boldsymboḷ́̃}) = \frac{1}{2 \sigma^2} \mu^2 + \log(\sigma)
= rac{\eta_1^2}{4 \eta_2} - rac{1}{2}\log(2 \eta_2)$.</li>
</ul>
<p>위의 각 항의 정확한 선택은 다소 임의적이라는 점에 주목할 가치가 있습니다. 실제로 중요한 특징은 분포가 이 형태로 표현될 수 있다는 것이지, 정확한 형태 그 자체가 아닙니다.</p>
<p>:numref:<code>subsec_softmax_and_derivatives</code>에서 암시했듯이, 널리 사용되는 기술은 최종 출력 $\mathbf{y}$가 지수족 분포를 따른다고 가정하는 것입니다. 지수족은 머신러닝에서 빈번하게 마주치는 흔하고 강력한 분포 가족입니다.</p>
<h2 id="요약-summary"><a class="header" href="#요약-summary">요약 (Summary)</a></h2>
<ul>
<li>베르누이 확률 변수는 예/아니오 결과가 있는 이벤트를 모델링하는 데 사용될 수 있습니다.</li>
<li>이산 균등 분포는 유한한 가능성 세트로부터의 선택을 모델링합니다.</li>
<li>연속 균등 분포는 구간으로부터의 선택을 모델링합니다.</li>
<li>이항 분포는 일련의 베르누이 확률 변수를 모델링하고 성공 횟수를 셉니다.</li>
<li>포아송 확률 변수는 희귀 사건의 도착을 모델링합니다.</li>
<li>가우스 확률 변수는 많은 수의 독립 확률 변수를 함께 더한 결과를 모델링합니다.</li>
<li>위의 모든 분포는 지수족에 속합니다.</li>
</ul>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>두 독립적인 이항 확률 변수 $X, Y sim 	extrm{Binomial}(16, 1/2)$의 차이인 $X-Y$ 확률 변수의 표준 편차는 얼마입니까?</li>
<li>포아송 확률 변수 $X sim 	extrm{Poisson}(\lambda)$를 취하고 $\lambda
ightarrow \infty$에 따라 $(X - \lambda)/\sqrt{\lambda}$를 고려하면, 이것이 대략 가우스 분포가 됨을 보일 수 있습니다. 이것이 왜 말이 됩니까?</li>
<li>$n$개 요소에 대한 두 이산 균등 확률 변수의 합에 대한 확률 질량 함수는 무엇입니까?</li>
</ol>
<p>:begin_tab:<code>mxnet</code>
<a href="https://discuss.d2l.ai/t/417">Discussions</a>
:end_tab:</p>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/1098">Discussions</a>
:end_tab:</p>
<p>:begin_tab:<code>tensorflow</code>
<a href="https://discuss.d2l.ai/t/1099">Discussions</a>
:end_tab:</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
