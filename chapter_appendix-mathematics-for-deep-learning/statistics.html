<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>통계 (Statistics) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html" class="active"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="통계-statistics"><a class="header" href="#통계-statistics">통계 (Statistics)</a></h1>
<p>:label:<code>sec_statistics</code></p>
<p>의심할 여지 없이, 최고의 딥러닝 전문가가 되기 위해서는 최첨단의 고정밀 모델을 훈련하는 능력이 매우 중요합니다. 그러나 개선 사항이 언제 유의미한지, 아니면 단지 훈련 과정의 무작위 변동의 결과인지가 불분명한 경우가 많습니다. 추정값의 불확실성에 대해 논의하려면 통계를 배워야 합니다.</p>
<p>*통계(statistics)*에 대한 가장 이른 기록은 9세기의 아랍 학자 알킨디(Al-Kindi)로 거슬러 올라갑니다. 그는 암호화된 메시지를 해독하기 위해 통계와 빈도 분석을 사용하는 방법에 대해 자세히 설명했습니다. 800년 후, 현대 통계학은 1700년대 독일에서 연구자들이 인구통계학적 및 경제적 데이터 수집과 분석에 집중하면서 시작되었습니다. 오늘날 통계학은 데이터의 수집, 처리, 분석, 해석 및 시각화를 다루는 과학 과목입니다. 게다가 통계학의 핵심 이론은 학계, 산업계 및 정부 내의 연구에서 널리 사용되어 왔습니다.</p>
<p>더 구체적으로, 통계학은 *기술 통계(descriptive statistics)*와 *통계적 추론(statistical inference)*으로 나뉠 수 있습니다. 전자는 *표본(sample)*이라고 불리는 관찰된 데이터 모음의 특징을 요약하고 설명하는 데 집중합니다. 표본은 *모집단(population)*에서 추출되며, 이는 우리 실험 관심사의 유사한 개인, 항목 또는 사건의 전체 집합을 나타냅니다. 기술 통계와 반대로, <em>통계적 추론</em>은 표본 분포가 어느 정도 모집단 분포를 재현할 수 있다는 가정 하에 주어진 <em>표본</em>으로부터 모집단의 특성을 추론합니다.</p>
<p>여러분은 "머신러닝과 통계의 본질적인 차이점은 무엇인가?"라고 궁금해할 수 있습니다. 근본적으로 말해서, 통계학은 추론 문제에 집중합니다. 이러한 유형의 문제에는 인과 추론과 같은 변수 간의 관계 모델링, A/B 테스팅과 같은 모델 파라미터의 통계적 유의성 테스트가 포함됩니다. 반대로 머신러닝은 각 파라미터의 기능을 명시적으로 프로그래밍하고 이해하지 않고도 정확한 예측을 하는 것을 강조합니다.</p>
<p>이 섹션에서는 추정량 평가 및 비교, 가설 검정 수행, 신뢰 구간 구축의 세 가지 유형의 통계 추론 방법을 소개합니다. 이러한 방법들은 주어진 모집단의 특성, 즉 실제 파라미터 $\theta$를 추론하는 데 도움이 될 수 있습니다. 간결함을 위해 주어진 모집단의 실제 파라미터 $\theta$가 스칼라 값이라고 가정합니다. $\theta$가 벡터나 텐서인 경우로 확장하는 것은 간단하므로 논의에서는 생략합니다.</p>
<h2 id="추정량-평가-및-비교-evaluating-and-comparing-estimators"><a class="header" href="#추정량-평가-및-비교-evaluating-and-comparing-estimators">추정량 평가 및 비교 (Evaluating and Comparing Estimators)</a></h2>
<p>통계학에서 *추정량(estimator)*은 실제 파라미터 $\theta$를 추정하기 위해 사용되는 주어진 표본들의 함수입니다. 표본 {$x_1, x_2, \ldots, x_n$}을 관찰한 후 $\theta$에 대한 추정값을 $\hat{\theta}_n = \hat{f}(x_1, \ldots, x_n)$이라고 씁니다.</p>
<p>우리는 이전에 섹션 :numref:<code>sec_maximum_likelihood</code>에서 추정량의 간단한 예를 보았습니다. 베르누이 확률 변수로부터 여러 표본을 가지고 있다면, 확률 변수가 1일 확률에 대한 최대 우도 추정량은 관찰된 1의 개수를 세고 총 표본 수로 나눔으로써 얻을 수 있습니다. 마찬가지로, 연습 문제에서는 여러 표본이 주어졌을 때 가우시안 평균의 최대 우도 추정량이 모든 표본의 평균값으로 주어진다는 것을 보여달라고 요청했습니다. 이러한 추정량들이 파라미터의 실제 값을 제공하는 경우는 거의 없지만, 이상적으로는 표본 수가 많을 때 추정값이 실제값에 가까울 것입니다.</p>
<p>예를 들어, 아래에 평균이 0이고 분산이 1인 가우시안 확률 변수의 실제 밀도와 그 가우시안에서 추출한 표본 모음을 보여줍니다. 모든 점이 보이고 원래 밀도와의 관계가 더 명확해지도록 $y$ 좌표를 구성했습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
from d2l import mxnet as d2l
from mxnet import np, npx
import random
npx.set_np()

# 데이터 포인트 샘플링 및 y 좌표 생성
epsilon = 0.1
random.seed(8675309)
xs = np.random.normal(loc=0, scale=1, size=(300,))

ys = [np.sum(np.exp(-(xs[:i] - xs[i])**2 / (2 * epsilon**2))
             / np.sqrt(2*np.pi*epsilon**2)) / len(xs) for i in range(len(xs))]

# 실제 밀도 계산
xd = np.arange(np.min(xs), np.max(xs), 0.01)

d = np.exp(-xd**2/2) / np.sqrt(2 * np.pi)

# 결과 플롯
d2l.plot(xd, yd, 'x', 'density')
d2l.plt.scatter(xs, ys)
d2l.plt.axvline(x=0)
d2l.plt.axvline(x=np.mean(xs), linestyle='--', color='purple')
d2l.plt.title(f'sample mean: {float(np.mean(xs)):.2f}')
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
from d2l import torch as d2l
import torch

torch.pi = torch.acos(torch.zeros(1)) * 2  # torch에서 pi 정의

# 데이터 포인트 샘플링 및 y 좌표 생성
epsilon = 0.1
torch.manual_seed(8675309)
xs = torch.randn(size=(300,))

ys = torch.tensor(
    [torch.sum(torch.exp(-(xs[:i] - xs[i])**2 / (2 * epsilon**2))
               / torch.sqrt(2*torch.pi*epsilon**2)) / len(xs)
     for i in range(len(xs))])

# 실제 밀도 계산
xd = torch.arange(torch.min(xs), torch.max(xs), 0.01)

d = torch.exp(-xd**2/2) / torch.sqrt(2 * torch.pi)

# 결과 플롯
d2l.plot(xd, yd, 'x', 'density')
d2l.plt.scatter(xs, ys)
d2l.plt.axvline(x=0)
d2l.plt.axvline(x=torch.mean(xs), linestyle='--', color='purple')
d2l.plt.title(f'sample mean: {float(torch.mean(xs).item()):.2f}')
d2l.plt.show()
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
from d2l import tensorflow as d2l
import tensorflow as tf

tf.pi = tf.acos(tf.zeros(1)) * 2  # TensorFlow에서 pi 정의

# 데이터 포인트 샘플링 및 y 좌표 생성
epsilon = 0.1
xs = tf.random.normal((300,))

ys = tf.constant(
    [(tf.reduce_sum(tf.exp(-(xs[:i] - xs[i])**2 / (2 * epsilon**2)) \
               / tf.sqrt(2*tf.pi*epsilon**2)) / tf.cast(
        tf.size(xs), dtype=tf.float32)).numpy() \
     for i in range(tf.size(xs))])

# 실제 밀도 계산
xd = tf.range(tf.reduce_min(xs), tf.reduce_max(xs), 0.01)

d = tf.exp(-xd**2/2) / tf.sqrt(2 * tf.pi)

# 결과 플롯
d2l.plot(xd, yd, 'x', 'density')
d2l.plt.scatter(xs, ys)
d2l.plt.axvline(x=0)
d2l.plt.axvline(x=tf.reduce_mean(xs), linestyle='--', color='purple')
d2l.plt.title(f'sample mean: {float(tf.reduce_mean(xs).numpy()):.2f}')
d2l.plt.show()
</code></pre>
<p>파라미터의 추정량 $\hat{\theta}_n$을 계산하는 방법은 많을 수 있습니다. 이 섹션에서는 추정량을 평가하고 비교하는 세 가지 일반적인 방법인 평균 제곱 오차, 표준 편차 및 통계적 편향을 소개합니다.</p>
<h3 id="평균-제곱-오차-mean-squared-error"><a class="header" href="#평균-제곱-오차-mean-squared-error">평균 제곱 오차 (Mean Squared Error)</a></h3>
<p>추정량을 평가하는 데 사용되는 아마도 가장 간단한 메트릭은 <em>평균 제곱 오차(mean squared error, MSE)</em> (또는 $l_2$ 손실) 추정량이며 다음과 같이 정의될 수 있습니다.</p>
<p>$$\textrm{MSE} (\hat{\theta}_n, \theta) = E[(\hat{\theta}_n - \theta)^2].$$
:eqlabel:<code>eq_mse_est</code></p>
<p>이를 통해 실제 값으로부터의 평균 제곱 편차를 정량화할 수 있습니다. MSE는 항상 음수가 아닙니다. :numref:<code>sec_linear_regression</code>을 읽었다면 이를 가장 흔히 사용되는 회귀 손실 함수로 인식할 것입니다. 추정량을 평가하는 척도로서, 그 값이 0에 가까울수록 추정량이 실제 파라미터 $\theta$에 더 가깝습니다.</p>
<h3 id="통계적-편향-statistical-bias"><a class="header" href="#통계적-편향-statistical-bias">통계적 편향 (Statistical Bias)</a></h3>
<p>MSE는 자연스러운 메트릭을 제공하지만, 이를 크게 만들 수 있는 여러 다른 현상을 쉽게 상상할 수 있습니다. 근본적으로 중요한 두 가지는 데이터셋의 무작위성으로 인한 추정량의 변동과 추정 절차로 인한 추정량의 계통 오차(systematic error)입니다.</p>
<p>먼저 계통 오차를 측정해 봅시다. 추정량 $\hat{\theta}_n$에 대해, *통계적 편향(statistical bias)*의 수학적 설명은 다음과 같이 정의될 수 있습니다.</p>
<p>$$\textrm{bias}(\hat{\theta}_n) = E(\hat{\theta}_n - \theta) = E(\hat{\theta}_n) - \theta.$$
:eqlabel:<code>eq_bias</code></p>
<p>$\textrm{bias}(\hat{\theta}_n) = 0$일 때 추정량 $\hat{\theta}_n$의 기댓값은 파라미터의 실제 값과 같습니다. 이 경우 $\hat{\theta}_n$을 불편 추정량(unbiased estimator)이라고 합니다. 일반적으로 불편 추정량은 기댓값이 실제 파라미터와 같기 때문에 편향 추정량보다 낫습니다.</p>
<p>그러나 편향 추정량이 실제에서 자주 사용된다는 점을 알아두는 것이 좋습니다. 추가적인 가정 없이는 불편 추정량이 존재하지 않거나 계산하기 어려운 경우가 있습니다. 이는 추정량의 중대한 결함처럼 보일 수 있지만, 실제에서 만나는 대다수의 추정량은 가용한 표본 수가 무한대로 갈 때 편향이 0으로 수렴한다는 의미에서 적어도 점근적 불편 추정량(asymptotically unbiased)입니다: $\lim_{n \rightarrow \infty} \textrm{bias}(\hat{\theta}_n) = 0$.</p>
<h3 id="분산과-표준-편차-variance-and-standard-deviation"><a class="header" href="#분산과-표준-편차-variance-and-standard-deviation">분산과 표준 편차 (Variance and Standard Deviation)</a></h3>
<p>둘째, 추정량의 무작위성을 측정해 봅시다. :numref:<code>sec_random_variables</code>에서 상기했듯이, <em>표준 편차(standard deviation)</em> (또는 <em>표준 오차(standard error)</em>)는 분산의 제곱근으로 정의됩니다. 우리는 해당 추정량의 표준 편차나 분산을 측정함으로써 추정량의 변동 정도를 측정할 수 있습니다.</p>
<p>$$\sigma_{\hat{\theta}_n} = \sqrt{\textrm{Var} (\hat{\theta}_n )} = \sqrt{E[(\hat{\theta}_n - E(\hat{\theta}_n))^2]}.$$
:eqlabel:<code>eq_var_est</code></p>
<p>:eqref:<code>eq_var_est</code>를 :eqref:<code>eq_mse_est</code>와 비교하는 것이 중요합니다. 이 방정식에서는 실제 모집단 값 $\theta$와 비교하는 것이 아니라, 기대 표본 평균인 $E(\hat{\theta}_n)$과 비교합니다. 따라서 추정량이 실제 값에서 얼마나 떨어져 있는지를 측정하는 것이 아니라, 추정량 자체의 변동을 측정하는 것입니다.</p>
<h3 id="편향-분산-트레이드오프-the-bias-variance-trade-off"><a class="header" href="#편향-분산-트레이드오프-the-bias-variance-trade-off">편향-분산 트레이드오프 (The Bias-Variance Trade-off)</a></h3>
<p>이 두 가지 주요 구성 요소가 평균 제곱 오차에 기여한다는 것은 직관적으로 명확합니다. 다소 놀라운 점은 이것이 실제로 평균 제곱 오차를 이 두 기여도와 세 번째 기여도로 <em>분해</em>한 것임을 보여줄 수 있다는 것입니다. 즉, 평균 제곱 오차를 편향의 제곱, 분산, 그리고 줄일 수 없는 오차의 합으로 쓸 수 있습니다.</p>
<p>$$
\begin{aligned}
\textrm{MSE} (\hat{\theta}_n, \theta) &amp;= E[(\hat{\theta}_n - \theta)^2] \
&amp;= E[(\hat{\theta}_n)^2] + E[\theta^2] - 2E[\hat{\theta}_n\theta] \
&amp;= \textrm{Var} [\hat{\theta}_n] + E[\hat{\theta}_n]^2 + \textrm{Var} [\theta] + E[\theta]^2 - 2E[\hat{\theta}_n]E[\theta] \
&amp;= (E[\hat{\theta}_n] - E[\theta])^2 + \textrm{Var} [\hat{\theta}_n] + \textrm{Var} [\theta] \
&amp;= (E[\hat{\theta}_n - \theta])^2 + \textrm{Var} [\hat{\theta}_n] + \textrm{Var} [\theta] \
&amp;= (\textrm{bias} [\hat{\theta}_n])^2 + \textrm{Var} (\hat{\theta}_n) + \textrm{Var} [\theta].\
\end{aligned}
$$</p>
<p>우리는 위의 공식을 *편향-분산 트레이드오프(bias-variance trade-off)*라고 부릅니다. 평균 제곱 오차는 세 가지 오차 원인으로 나뉠 수 있습니다: 높은 편향으로 인한 오차, 높은 분산으로 인한 오차, 그리고 줄일 수 없는 오차입니다. 편향 오차는 특성과 출력 사이의 고차원 관계를 추출할 수 없는 단순한 모델(예: 선형 회귀 모델)에서 흔히 보입니다. 모델이 높은 편향 오차를 겪는다면, 우리는 종종 이를 (:numref:<code>sec_generalization_basics</code>에서 도입된 것처럼) <em>과소적합(underfitting)</em> 또는 <em>유연성(flexibility)</em> 부족이라고 말합니다. 높은 분산은 일반적으로 훈련 데이터에 과대적합되는 너무 복잡한 모델에서 비롯됩니다. 결과적으로 <em>과대적합(overfitting)</em> 모델은 데이터의 작은 변동에 민감합니다. 모델이 높은 분산을 겪는다면, 우리는 종종 이를 (:numref:<code>sec_generalization_basics</code>에서 도입된 것처럼) <em>과대적합</em> 및 <em>일반화(generalization)</em> 부족이라고 말합니다. 줄일 수 없는 오차는 $\theta$ 자체의 노이즈로 인한 결과입니다.</p>
<h3 id="코드로-추정량-평가하기-evaluating-estimators-in-code"><a class="header" href="#코드로-추정량-평가하기-evaluating-estimators-in-code">코드로 추정량 평가하기 (Evaluating Estimators in Code)</a></h3>
<p>추정량의 표준 편차는 텐서 <code>a</code>에 대해 단순히 <code>a.std()</code>를 호출함으로써 구현되어 왔으므로, 여기서는 생략하고 통계적 편향과 평균 제곱 오차를 구현해 보겠습니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
# 통계적 편향
def stat_bias(true_theta, est_theta):
    return(np.mean(est_theta) - true_theta)

# 평균 제곱 오차
def mse(data, true_theta):
    return(np.mean(np.square(data - true_theta)))
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
# 통계적 편향
def stat_bias(true_theta, est_theta):
    return(torch.mean(est_theta) - true_theta)

# 평균 제곱 오차
def mse(data, true_theta):
    return(torch.mean(torch.square(data - true_theta)))
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
# 통계적 편향
def stat_bias(true_theta, est_theta):
    return(tf.reduce_mean(est_theta) - true_theta)

# 평균 제곱 오차
def mse(data, true_theta):
    return(tf.reduce_mean(tf.square(data - true_theta)))
</code></pre>
<p>편향-분산 트레이드오프 방정식을 설명하기 위해, 10,000개의 표본으로 정규 분포 $\mathcal{N}(\theta, \sigma^2)$를 시뮬레이션해 봅시다. 여기서는 $\theta = 1$ 및 $\sigma = 4$를 사용합니다. 추정량은 주어진 표본들의 함수이므로, 여기서는 이 정규 분포 $\mathcal{N}(\theta, \sigma^2)$에서 실제 $\theta$에 대한 추정량으로 표본의 평균을 사용합니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
theta_true = 1
sigma = 4
sample_len = 10000
samples = np.random.normal(theta_true, sigma, sample_len)
theta_est = np.mean(samples)
theta_est
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
theta_true = 1
sigma = 4
sample_len = 10000
samples = torch.normal(theta_true, sigma, size=(sample_len, 1))
theta_est = torch.mean(samples)
theta_est
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
theta_true = 1
sigma = 4
sample_len = 10000
samples = tf.random.normal((sample_len, 1), theta_true, sigma)
theta_est = tf.reduce_mean(samples)
theta_est
</code></pre>
<p>우리 추정량의 편향 제곱과 분산의 합을 계산하여 트레이드오프 방정식을 검증해 봅시다. 먼저 우리 추정량의 MSE를 계산합니다.</p>
<pre><code class="language-{.python .input}">#@tab all
mse(samples, theta_true)
</code></pre>
<p>다음으로, 아래와 같이 $\textrm{Var} (\hat{\theta}_n) + [\textrm{bias} (\hat{\theta}_n)]^2$를 계산합니다. 보시다시피, 두 값은 수치적 정밀도 내에서 일치합니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
bias = stat_bias(theta_true, theta_est)
np.square(samples.std()) + np.square(bias)
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
bias = stat_bias(theta_true, theta_est)
torch.square(samples.std(unbiased=False)) + torch.square(bias)
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
bias = stat_bias(theta_true, theta_est)
tf.square(tf.math.reduce_std(samples)) + tf.square(bias)
</code></pre>
<h2 id="가설-검정-수행하기-conducting-hypothesis-tests"><a class="header" href="#가설-검정-수행하기-conducting-hypothesis-tests">가설 검정 수행하기 (Conducting Hypothesis Tests)</a></h2>
<p>통계적 추론에서 가장 흔히 접하는 주제는 가설 검정입니다. 가설 검정은 20세기 초에 대중화되었지만, 첫 번째 사용은 1700년대의 존 아버트넛(John Arbuthnot)으로 거슬러 올라갑니다. 존은 런던의 80년 치 출생 기록을 추적하여 매년 여성보다 남성이 더 많이 태어났다는 결론을 내렸습니다. 그 후, 현대적인 유의성 검정은 $p$-값과 피어슨의 카이제곱 검정을 발명한 칼 피어슨(Karl Pearson), 스튜던트 t-분포의 아버지인 윌리엄 고셋(William Gosset), 그리고 귀무 가설과 유의성 검정을 처음 시작한 로널드 피셔(Ronald Fisher)에 의한 지적 유산입니다.</p>
<p>*가설 검정(hypothesis test)*은 모집단에 대한 기본 진술에 반하는 어떤 증거를 평가하는 방법입니다. 우리는 기본 진술을 <em>귀무 가설(null hypothesis)</em> $H_0$라고 부르며, 관찰된 데이터를 사용하여 이를 기각하려고 시도합니다. 여기서 우리는 $H_0$를 통계적 유의성 검정의 출발점으로 사용합니다. <em>대립 가설(alternative hypothesis)</em> $H_A$ (또는 $H_1$)는 귀무 가설과 상반되는 진술입니다. 귀무 가설은 종종 변수 간의 관계를 가정하는 서술형 형식으로 명시됩니다. 그것은 가능한 한 명확하게 신념을 반영해야 하며, 통계 이론에 의해 테스트 가능해야 합니다.</p>
<p>당신이 화학자라고 상상해 보십시오. 실험실에서 수천 시간을 보낸 후, 당신은 수학을 이해하는 능력을 비약적으로 향상시킬 수 있는 새로운 약을 개발합니다. 그 마법 같은 힘을 보여주기 위해, 당신은 그것을 테스트해야 합니다. 당연히, 약을 복용하고 수학을 더 잘 배우는 데 도움이 되는지 확인해 줄 자원봉사자들이 필요할 것입니다. 어떻게 시작하시겠습니까?</p>
<p>첫째, 어떤 메트릭으로 측정했을 때 수학적 이해 능력에 차이가 없도록 신중하게 무작위로 선택된 두 그룹의 자원봉사자가 필요할 것입니다. 두 그룹은 흔히 실험군(test group)과 대조군(control group)으로 불립니다. <em>실험군</em> (또는 <em>처치군(treatment group)</em>)은 약을 경험하게 될 개인 그룹인 반면, <em>대조군</em>은 벤치마크로 설정된 사용자 그룹을 나타냅니다. 즉, 이 약을 복용하는 것을 제외하고는 동일한 환경 설정입니다. 이런 식으로, 처치에서의 독립 변수의 영향을 제외하고 모든 변수의 영향이 최소화됩니다.</p>
<p>둘째, 일정 기간 약을 복용한 후, 새로운 수학 공식을 배운 후 자원봉사자들에게 동일한 테스트를 보게 하는 것과 같이 동일한 메트릭으로 두 그룹의 수학적 이해도를 측정해야 할 것입니다. 그런 다음 그들의 성적을 수집하고 결과를 비교할 수 있습니다. 이 경우, 우리의 귀무 가설은 두 그룹 사이에 차이가 없다는 것이고, 대립 가설은 차이가 있다는 것입니다.</p>
<p>이것은 여전히 완전히 형식적이지는 않습니다. 당신이 신중하게 생각해야 할 많은 세부 사항들이 있습니다. 예를 들어, 그들의 수학적 이해 능력을 테스트하기에 적합한 메트릭은 무엇입니까? 약의 효과를 주장하는 데 확신을 가질 수 있도록 얼마나 많은 자원봉사자가 필요합니까? 테스트를 얼마나 오래 실행해야 합니까? 두 그룹 사이에 차이가 있는지 어떻게 결정합니까? 평균 성적에만 관심이 있습니까, 아니면 점수의 변동 범위에도 관심이 있습니까? 등등.</p>
<p>이런 방식으로, 가설 검정은 실험 설계와 관찰된 결과의 확실성에 대한 추론을 위한 프레임워크를 제공합니다. 이제 귀무 가설이 참일 가능성이 매우 낮다는 것을 보여줄 수 있다면, 우리는 확신을 가지고 이를 기각할 수 있습니다.</p>
<p>가설 검정을 수행하는 방법에 대한 이야기를 완성하기 위해, 이제 몇 가지 추가 용어를 도입하고 위의 개념들을 형식화해야 합니다.</p>
<h3 id="통계적-유의성-statistical-significance"><a class="header" href="#통계적-유의성-statistical-significance">통계적 유의성 (Statistical Significance)</a></h3>
<p>*통계적 유의성(statistical significance)*은 귀무 가설 $H_0$를 기각해서는 안 될 때 잘못 기각할 확률을 측정합니다. 즉,</p>
<p>$$\textrm{통계적 유의성 }= 1 - \alpha = 1 - P(\textrm{기각 } H_0 \mid H_0 \textrm{ 가 참} ).$$</p>
<p>이를 <em>제1종 오류(type I error)</em> 또는 *위양성(false positive)*이라고도 합니다. $\alpha$는 *유의 수준(significance level)*이라고 불리며 그 흔히 사용되는 값은 $5%$입니다. 즉, $1-\alpha = 95%$입니다. 유의 수준은 참인 귀무 가설을 기각할 때 우리가 감수할 용의가 있는 위험 수준으로 설명될 수 있습니다.</p>
<p>:numref:<code>fig_statistical_significance</code>는 두 표본 가설 검정에서 주어진 정규 분포의 관찰값과 확률을 보여줍니다. 관찰 데이터 예제가 $95%$ 임계값 밖에 위치한다면, 이는 귀무 가설 가정 하에서 매우 일어날 법하지 않은 관찰이 될 것입니다. 따라서 귀무 가설에 무언가 잘못되었을 수 있으며 우리는 이를 기각할 것입니다.</p>
<p><img src="../img/statistical-significance.svg" alt="통계적 유의성." />
:label:<code>fig_statistical_significance</code></p>
<h3 id="통계적-검정력-statistical-power"><a class="header" href="#통계적-검정력-statistical-power">통계적 검정력 (Statistical Power)</a></h3>
<p><em>통계적 검정력(statistical power)</em> (또는 <em>민감도(sensitivity)</em>)은 귀무 가설 $H_0$를 기각해야 할 때 기각할 확률을 측정합니다. 즉,</p>
<p>$$\textrm{통계적 검정력 }= 1 - \beta = 1 - P(\textrm{ 기각 실패 } H_0  \mid H_0 \textrm{ 가 거짓} ).$$</p>
<p><em>제1종 오류</em>는 귀무 가설이 참일 때 기각함으로써 발생하는 오류인 반면, *제2종 오류(type II error)*는 귀무 가설이 거짓일 때 기각하지 못함으로써 발생하는 오류임을 상기하십시오. 제2종 오류는 보통 $\beta$로 표시되며, 따라서 해당 통계적 검정력은 $1-\beta$입니다.</p>
<p>직관적으로, 통계적 검정력은 우리의 검정이 원하는 통계적 유의 수준에서 어떤 최소 규모의 실제 불일치를 얼마나 잘 감지할 것인지를 나타내는 것으로 해석될 수 있습니다. $80%$는 흔히 사용되는 통계적 검정력 임계값입니다. 통계적 검정력이 높을수록 실제 차이를 감지할 가능성이 높아집니다.</p>
<p>통계적 검정력의 가장 일반적인 용도 중 하나는 필요한 표본 수를 결정하는 것입니다. 귀무 가설이 거짓일 때 이를 기각할 확률은 그것이 얼마나 거짓인지( *효과 크기(effect size)*라고 함)와 당신이 가진 표본 수에 달려 있습니다. 예상할 수 있듯이, 작은 효과 크기는 높은 확률로 감지하기 위해 매우 많은 수의 표본을 필요로 할 것입니다. 이 짧은 부록의 범위를 벗어나 자세히 유도하지는 않겠지만, 예를 들어 우리 표본이 평균 0, 분산 1인 가우시안에서 왔다는 귀무 가설을 기각하고 싶고, 우리 표본의 평균이 실제로 1에 가깝다고 믿는다면, 단 $8$개의 표본 크기만으로도 허용 가능한 오차율로 그렇게 할 수 있습니다. 그러나 우리 표본 모집단의 실제 평균이 $0.01$에 가깝다고 생각한다면, 그 차이를 감지하기 위해 거의 $80,000$개의 표본 크기가 필요할 것입니다.</p>
<p>검정력을 정수기 필터로 상상해 볼 수 있습니다. 이 비유에서, 고검정력 가설 검정은 물속의 유해 물질을 가능한 많이 줄여주는 고품질 정수 시스템과 같습니다. 반면에, 더 작은 불일치는 저품질 정수 필터와 같아서 일부 상대적으로 작은 물질들이 틈새로 쉽게 빠져나갈 수 있습니다. 마찬가지로, 통계적 검정력이 충분히 높지 않으면 검정에서 더 작은 불일치를 잡아내지 못할 수 있습니다.</p>
<h3 id="검정-통계량-test-statistic"><a class="header" href="#검정-통계량-test-statistic">검정 통계량 (Test Statistic)</a></h3>
<p><em>검정 통계량(test statistic)</em> $T(x)$는 표본 데이터의 어떤 특성을 요약하는 스칼라입니다. 이러한 통계량을 정의하는 목표는 우리가 서로 다른 분포를 구별하고 가설 검정을 수행할 수 있도록 하는 것입니다. 우리의 화학자 예제를 다시 생각해 보면, 한 집단이 다른 집단보다 더 잘 수행된다는 것을 보여주고 싶다면 평균을 검정 통계량으로 취하는 것이 합리적일 수 있습니다. 검정 통계량의 다른 선택은 현저히 다른 통계적 검정력을 가진 통계 검정으로 이어질 수 있습니다.</p>
<p>종종 $T(X)$ (귀무 가설 하에서의 검정 통계량 분포)는 귀무 가설 하에서 고려될 때 정규 분포와 같은 일반적인 확률 분포를 적어도 근사적으로 따를 것입니다. 우리가 그러한 분포를 명시적으로 유도할 수 있고 우리 데이터셋에서 검정 통계량을 측정할 수 있다면, 우리 통계량이 우리가 예상하는 범위를 크게 벗어날 때 안전하게 귀무 가설을 기각할 수 있습니다. 이를 정량화하는 것은 $p$-값의 개념으로 이어집니다.</p>
<h3 id="p-값-p-value"><a class="header" href="#p-값-p-value">$p$-값 ($p$-value)</a></h3>
<p>$p$-값 (또는 <em>확률 값</em>)은 귀무 가설이 <em>참</em>이라고 가정할 때, $T(X)$가 관찰된 검정 통계량 $T(x)$만큼 극단적일 확률입니다. 즉,</p>
<p>$$ p\textrm{-값} = P_{H_0}(T(X) \geq T(x)).$$</p>
<p>$p$-값이 미리 정의되고 고정된 통계적 유의 수준 $\alpha$보다 작거나 같으면, 우리는 귀무 가설을 기각할 수 있습니다. 그렇지 않으면, 우리는 귀무 가설을 기각할 증거가 부족하다고 결론 내릴 것입니다. 주어진 모집단 분포에 대해, *기각역(region of rejection)*은 통계적 유의 수준 $\alpha$보다 작은 $p$-값을 가진 모든 점들을 포함하는 구간이 될 것입니다.</p>
<h3 id="단측-검정-및-양측-검정-one-side-test-and-two-sided-test"><a class="header" href="#단측-검정-및-양측-검정-one-side-test-and-two-sided-test">단측 검정 및 양측 검정 (One-side Test and Two-sided Test)</a></h3>
<p>보통 유의성 검정에는 두 가지 종류가 있습니다: 단측 검정과 양측 검정입니다. <em>단측 검정(one-sided test)</em> (또는 <em>한쪽 꼬리 검정</em>)은 귀무 가설과 대립 가설이 한 방향만 가질 때 적용 가능합니다. 예를 들어, 귀무 가설은 실제 파라미터 $\theta$가 어떤 값 $c$보다 작거나 같다고 명시할 수 있습니다. 대립 가설은 $\theta$가 $c$보다 크다는 것이 될 것입니다. 즉, 기각역은 표본 분포의 한쪽에만 있습니다. 단측 검정과 반대로, <em>양측 검정(two-sided test)</em> (또는 <em>양쪽 꼬리 검정</em>)은 기각역이 표본 분포의 양쪽에 있을 때 적용 가능합니다. 이 경우의 예로는 귀무 가설이 실제 파라미터 $\theta$가 어떤 값 $c$와 같다고 명시하는 경우가 있습니다. 대립 가설은 $\theta$가 $c$와 같지 않다는 것이 될 것입니다.</p>
<h3 id="가설-검정의-일반적인-단계-general-steps-of-hypothesis-testing"><a class="header" href="#가설-검정의-일반적인-단계-general-steps-of-hypothesis-testing">가설 검정의 일반적인 단계 (General Steps of Hypothesis Testing)</a></h3>
<p>위의 개념들에 익숙해진 후, 가설 검정의 일반적인 단계를 살펴봅시다.</p>
<ol>
<li>질문을 명시하고 귀무 가설 $H_0$를 설정합니다.</li>
<li>통계적 유의 수준 $\alpha$와 통계적 검정력 ($1 - \beta$)을 설정합니다.</li>
<li>실험을 통해 표본을 얻습니다. 필요한 표본 수는 통계적 검정력과 예상 효과 크기에 달려 있습니다.</li>
<li>검정 통계량과 $p$-값을 계산합니다.</li>
<li>$p$-값과 통계적 유의 수준 $\alpha$를 바탕으로 귀무 가설을 유지할지 기각할지 결정합니다.</li>
</ol>
<p>가설 검정을 수행하기 위해, 우리는 귀무 가설과 우리가 감수할 용의가 있는 위험 수준을 정의하는 것으로 시작합니다. 그런 다음 표본의 검정 통계량을 계산하고, 검정 통계량의 극단적인 값을 귀무 가설에 반하는 증거로 삼습니다. 검정 통계량이 기각역에 떨어지면, 우리는 대립 가설을 지지하며 귀무 가설을 기각할 수 있습니다.</p>
<p>가설 검정은 임상 시험 및 A/B 테스팅과 같은 다양한 시나리오에서 적용 가능합니다.</p>
<h2 id="신뢰-구간-구축하기-constructing-confidence-intervals"><a class="header" href="#신뢰-구간-구축하기-constructing-confidence-intervals">신뢰 구간 구축하기 (Constructing Confidence Intervals)</a></h2>
<p>파라미터 $\theta$의 값을 추정할 때, $\hat \theta$와 같은 점 추정량은 불확실성의 개념을 포함하지 않기 때문에 유용성이 제한적입니다. 오히려, 높은 확률로 실제 파라미터 $\theta$를 포함할 구간을 생성할 수 있다면 훨씬 더 좋을 것입니다. 만약 당신이 한 세기 전에 그러한 아이디어에 관심이 있었다면, 1937년에 신뢰 구간의 개념을 처음 도입한 예르지 네이만(Jerzy Neyman)의 "Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability" :cite:<code>Neyman.1937</code>를 읽고 흥분했을 것입니다.</p>
<p>유용하려면, 신뢰 구간은 주어진 확실성 정도에 대해 가능한 한 작아야 합니다. 이를 유도하는 방법을 알아봅시다.</p>
<h3 id="정의-definition"><a class="header" href="#정의-definition">정의 (Definition)</a></h3>
<p>수학적으로, 실제 파라미터 $\theta$에 대한 *신뢰 구간(confidence interval)*은 표본 데이터로부터 계산된 구간 $C_n$으로, 다음을 만족합니다.</p>
<p>$$P_{\theta} (C_n \ni \theta) \geq 1 - \alpha, \forall \theta.$$
:eqlabel:<code>eq_confidence</code></p>
<p>여기서 $\alpha \in (0, 1)$이고, $1 - \alpha$는 구간의 <em>신뢰 수준(confidence level)</em> 또는 *커버리지(coverage)*라고 불립니다. 이것은 위에서 논의한 유의 수준과 동일한 $\alpha$입니다.</p>
<p>:eqref:<code>eq_confidence</code>는 고정된 $\theta$가 아니라 변수 $C_n$에 관한 것임에 유의하십시오. 이를 강조하기 위해, $P_{\theta} (\theta \in C_n)$ 대신 $P_{\theta} (C_n \ni \theta)$라고 씁니다.</p>
<h3 id="해석-interpretation"><a class="header" href="#해석-interpretation">해석 (Interpretation)</a></h3>
<p>$95%$ 신뢰 구간을 실제 파라미터가 존재할 확률이 $95%$인 구간으로 해석하고 싶은 유혹이 매우 강하지만, 아쉽게도 이는 사실이 아닙니다. 실제 파라미터는 고정되어 있고, 무작위인 것은 바로 구간입니다. 따라서 더 나은 해석은 이 절차에 의해 많은 수의 신뢰 구간을 생성했다면, 생성된 구간의 $95%$가 실제 파라미터를 포함할 것이라고 말하는 것입니다.</p>
<p>이는 매우 까다롭게 보일 수 있지만, 결과의 해석에 실제적인 영향을 미칠 수 있습니다. 특히, 우리는 거의 드물게만 그렇게 한다면, 실제 값을 포함하지 않는다는 것이 <em>거의 확실한</em> 구간을 구축함으로써 :eqref:<code>eq_confidence</code>를 충족할 수 있습니다. 이 섹션을 마치며 유혹적이지만 틀린 세 가지 진술을 제공합니다. 이러한 점들에 대한 심층적인 논의는 :citet:<code>Morey.Hoekstra.Rouder.ea.2016</code>에서 찾을 수 있습니다.</p>
<ul>
<li><strong>오류 1</strong>. 좁은 신뢰 구간은 파라미터를 정밀하게 추정할 수 있음을 의미한다.</li>
<li><strong>오류 2</strong>. 신뢰 구간 내부의 값이 구간 외부의 값보다 실제 값일 가능성이 더 높다.</li>
<li><strong>오류 3</strong>. 특정하게 관찰된 $95%$ 신뢰 구간이 실제 값을 포함할 확률은 $95%$이다.</li>
</ul>
<p>말하자면, 신뢰 구간은 미묘한 대상입니다. 그러나 해석을 명확히 유지한다면 강력한 도구가 될 수 있습니다.</p>
<h3 id="가우시안-예제-a-gaussian-example"><a class="header" href="#가우시안-예제-a-gaussian-example">가우시안 예제 (A Gaussian Example)</a></h3>
<p>가장 고전적인 예제인, 평균과 분산을 모르는 가우시안 평균에 대한 신뢰 구간을 논의해 봅시다. 가우시안 $\mathcal{N}(\mu, \sigma^2)$에서 $n$개의 표본 {$x_i$}$_{i=1}^n$을 수집한다고 가정합시다. 우리는 다음과 같이 평균과 분산에 대한 추정량을 계산할 수 있습니다.</p>
<p>$$\hat\mu_n = \frac{1}{n}\sum_{i=1}^n x_i ;\textrm{및}; \hat{\sigma}^2_n = \frac{1}{n-1}\sum_{i=1}^n (x_i - \hat{\mu})^2.$$</p>
<p>이제 확률 변수</p>
<p>$$
T = \frac{\hat{\mu}_n - \mu}{\hat{\sigma}_n/\sqrt{n}},
$$</p>
<p>를 고려하면, 우리는 <em>자유도가</em> $n-1$ <em>인 스튜던트 t-분포</em>라고 불리는 잘 알려진 분포를 따르는 확률 변수를 얻습니다.</p>
<p>이 분포는 매우 잘 연구되어 있으며, 예를 들어 $n\rightarrow \infty$임에 따라 대략 표준 가우시안이 된다는 것이 알려져 있습니다. 따라서 표에서 가우시안 c.d.f. 값을 찾아봄으로써, $T$의 값이 적어도 $95%$의 시간에 구간 $[-1.96, 1.96]$에 있다고 결론 내릴 수 있습니다. 유한한 $n$ 값의 경우 구간은 다소 더 커야 하지만, 잘 알려져 있으며 표에 미리 계산되어 있습니다.</p>
<p>따라서 우리는 큰 $n$에 대해 다음과 같이 결론 내릴 수 있습니다.</p>
<p>$$ P\left(\frac{\hat{\mu}_n - \mu}{\hat{\sigma}_n/\sqrt{n}} \in [-1.96, 1.96]\right) \geq 0.95. $$</p>
<p>양변에 $\hat{\sigma}_n/\sqrt{n}$을 곱한 다음 $\hat{\mu}_n$을 더하여 이를 재배열하면 다음을 얻습니다.</p>
<p>$$ P\left(\mu \in \left[\hat{\mu}_n - 1.96\frac{\hat{\sigma}_n}{\sqrt{n}}, \hat{\mu}_n + 1.96\frac{\hat{\sigma}_n}{\sqrt{n}}\right]\right) \geq 0.95. $$</p>
<p>이렇게 해서 우리는 $95%$ 신뢰 구간을 찾았음을 알게 됩니다:
$$\left[\hat{\mu}_n - 1.96\frac{\hat{\sigma}_n}{\sqrt{n}}, \hat{\mu}_n + 1.96\frac{\hat{\sigma}_n}{\sqrt{n}}\right].$$
:eqlabel:<code>eq_gauss_confidence</code></p>
<p>:eqref:<code>eq_gauss_confidence</code>는 통계학에서 가장 많이 사용되는 공식 중 하나라고 해도 과언이 아닙니다. 이 공식을 구현함으로써 통계에 대한 논의를 마칩니다. 단순함을 위해 점근적 영역(asymptotic regime)에 있다고 가정합니다. $N$의 작은 값은 프로그래밍 방식이나 $t$-표로부터 얻은 <code>t_star</code>의 올바른 값을 포함해야 합니다.</p>
<pre><code class="language-{.python .input}">#@tab mxnet
# 표본 수
N = 1000

# 표본 데이터셋
samples = np.random.normal(loc=0, scale=1, size=(N,))

# 스튜던트 t-분포 c.d.f. 조회
t_star = 1.96

# 구간 구축
mu_hat = np.mean(samples)
sigma_hat = samples.std(ddof=1)
(mu_hat - t_star*sigma_hat/np.sqrt(N), mu_hat + t_star*sigma_hat/np.sqrt(N))
</code></pre>
<pre><code class="language-{.python .input}">#@tab pytorch
# PyTorch는 기본적으로 베셀 보정(Bessel's correction)을 사용하며, 이는 numpy의 기본 ddof=0 대신 
# ddof=1을 사용함을 의미합니다. ddof=0을 모방하기 위해 unbiased=False를 사용할 수 있습니다.

# 표본 수
N = 1000

# 표본 데이터셋
samples = torch.normal(0, 1, size=(N,))

# 스튜던트 t-분포 c.d.f. 조회
t_star = 1.96

# 구간 구축
mu_hat = torch.mean(samples)
sigma_hat = samples.std(unbiased=True)
(mu_hat - t_star*sigma_hat/torch.sqrt(torch.tensor(N, dtype=torch.float32)),\
 mu_hat + t_star*sigma_hat/torch.sqrt(torch.tensor(N, dtype=torch.float32)))
</code></pre>
<pre><code class="language-{.python .input}">#@tab tensorflow
# 표본 수
N = 1000

# 표본 데이터셋
samples = tf.random.normal((N,), 0, 1)

# 스튜던트 t-분포 c.d.f. 조회
t_star = 1.96

# 구간 구축
mu_hat = tf.reduce_mean(samples)
sigma_hat = tf.math.reduce_std(samples)
(mu_hat - t_star*sigma_hat/tf.sqrt(tf.constant(N, dtype=tf.float32)), \
 mu_hat + t_star*sigma_hat/tf.sqrt(tf.constant(N, dtype=tf.float32)))
</code></pre>
<h2 id="요약-summary"><a class="header" href="#요약-summary">요약 (Summary)</a></h2>
<ul>
<li>통계학은 추론 문제에 집중하는 반면, 딥러닝은 명시적인 프로그래밍과 이해 없이 정확한 예측을 하는 것을 강조합니다.</li>
<li>세 가지 일반적인 통계 추론 방법이 있습니다: 추정량 평가 및 비교, 가설 검정 수행, 신뢰 구간 구축입니다.</li>
<li>가장 일반적인 세 가지 추정량이 있습니다: 통계적 편향, 표준 편차, 그리고 평균 제곱 오차입니다.</li>
<li>신뢰 구간은 주어진 표본들로부터 구축할 수 있는 실제 모집단 파라미터의 추정 범위입니다.</li>
<li>가설 검정은 모집단에 대한 기본 진술에 반하는 어떤 증거를 평가하는 방법입니다.</li>
</ul>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>$X_1, X_2, \ldots, X_n \overset{\textrm{iid}}{\sim} \textrm{Unif}(0, \theta)$라고 합시다. 여기서 "iid"는 *독립적이고 동일하게 분포된(independent and identically distributed)*을 의미합니다. $\theta$의 다음 추정량들을 고려해 보십시오:
$$\hat{\theta} = \max {X_1, X_2, \ldots, X_n };
$$
$$\tilde{\theta} = 2 \bar{X_n} = \frac{2}{n} \sum_{i=1}^n X_i.$$
<ul>
<li>$\hat{\theta}$의 통계적 편향, 표준 편차, 그리고 평균 제곱 오차를 구하십시오.</li>
<li>$\tilde{\theta}$의 통계적 편향, 표준 편차, 그리고 평균 제곱 오차를 구하십시오.</li>
<li>어떤 추정량이 더 좋습니까?</li>
</ul>
</li>
<li>서론의 화학자 예제에 대해, 양측 가설 검정을 수행하기 위한 5단계를 유도할 수 있습니까? 통계적 유의 수준 $\alpha = 0.05$와 통계적 검정력 $1 - \beta = 0.8$이 주어졌다고 가정합니다.</li>
<li>독립적으로 생성된 100개의 데이터셋에 대해 $N=2$ 및 $\alpha = 0.5$로 신뢰 구간 코드를 실행하고, 결과 구간들을 플롯하십시오 (이 경우 <code>t_star = 1.0</code>). 실제 평균 0을 포함하는 것과는 거리가 먼 매우 짧은 구간들을 몇 개 보게 될 것입니다. 이것이 신뢰 구간의 해석과 모순됩니까? 짧은 구간을 고정밀 추정치를 나타내는 데 사용하는 것이 편안하게 느껴집니까?</li>
</ol>
<p>:begin_tab:<code>mxnet</code>
<a href="https://discuss.d2l.ai/t/419">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/1102">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>tensorflow</code>
<a href="https://discuss.d2l.ai/t/1103">토론</a>
:end_tab:</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
