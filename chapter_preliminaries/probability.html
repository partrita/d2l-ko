<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>확률과 통계 (Probability and Statistics) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/probability.html" class="active"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-inference.html"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <pre><code class="language-{.python .input}">%load_ext d2lbook.tab
tab.interact_select(['mxnet', 'pytorch', 'tensorflow', 'jax'])
</code></pre>
<h1 id="확률과-통계-probability-and-statistics"><a class="header" href="#확률과-통계-probability-and-statistics">확률과 통계 (Probability and Statistics)</a></h1>
<p>:label:<code>sec_prob</code></p>
<p>어쨌든, 머신러닝은 불확실성에 관한 것입니다.
지도 학습에서 우리는 알려진 것(<em>특성</em>)이 주어졌을 때
알려지지 않은 것(<em>타겟</em>)을 예측하고 싶습니다.
목표에 따라, 우리는 타겟의 가장 가능성 있는 값을 예측하려고 시도할 수 있습니다.
또는 타겟과 예상 거리가 가장 작은 값을 예측할 수 있습니다.
그리고 때때로 우리는 특정 값을 예측할 뿐만 아니라
<em>불확실성을 정량화</em>하고 싶습니다.
예를 들어 환자를 설명하는 일부 특성이 주어졌을 때,
우리는 그들이 내년에 심장마비를 겪을 가능성이 <em>얼마나 되는지</em> 알고 싶을 수 있습니다.
비지도 학습에서 우리는 종종 불확실성에 관심을 갖습니다.
일련의 측정값이 비정상적인지 판단하려면,
관심 집단에서 값을 관찰할 가능성이 얼마나 되는지 아는 것이 도움이 됩니다.
또한 강화 학습에서 우리는 다양한 환경에서 지능적으로 행동하는 에이전트를 개발하기를 원합니다.
이를 위해서는 환경이 어떻게 변할 것으로 예상되는지,
그리고 사용 가능한 각 행동에 대한 응답으로 어떤 보상을 기대할 수 있는지에 대한 추론이 필요합니다.</p>
<p>*확률(Probability)*은 불확실성 하에서의 추론을 다루는 수학 분야입니다.
어떤 프로세스의 확률 모델이 주어지면, 우리는 다양한 사건의 가능성에 대해 추론할 수 있습니다.
반복 가능한 사건(동전 던지기 등)의 빈도를 설명하기 위해 확률을 사용하는 것은
상당히 논란의 여지가 없습니다.
사실, <em>빈도주의(frequentist)</em> 학자들은
그러한 반복 가능한 사건에 <em>만</em> 적용되는 확률 해석을 고수합니다.
반면 <em>베이지안(Bayesian)</em> 학자들은
불확실성 하에서의 추론을 공식화하기 위해 확률 언어를 더 광범위하게 사용합니다.
베이지안 확률은 두 가지 고유한 특징으로 특징지어집니다:
(i) 반복 불가능한 사건에 대한 믿음의 정도 할당,
예: 댐이 무너질 <em>확률</em>은 얼마인가?;
(ii) 주관성. 베이지안 확률은
새로운 증거에 비추어 믿음을 어떻게 업데이트해야 하는지에 대한 모호하지 않은 규칙을 제공하지만,
다른 개인이 다른 <em>사전(prior)</em> 믿음으로 시작할 수 있도록 허용합니다.
*통계(Statistics)*는 데이터 수집 및 구성으로 시작하여
데이터를 생성한 프로세스에 대해 어떤 추론을 도출할 수 있는지로 거슬러 올라가며
우리가 역으로 추론하도록 돕습니다.
데이터셋을 분석할 때마다, 더 넓은 집단을 특징지을 수 있는 패턴을 찾고 있다면,
우리는 통계적 사고를 사용하고 있는 것입니다.
많은 과정, 전공, 논문, 직업, 학과, 회사 및 기관이
확률과 통계 연구에 헌신했습니다.
이 섹션은 겉핥기에 불과하지만,
우리는 모델 구축을 시작하는 데 필요한 기초를 제공할 것입니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
%matplotlib inline
from d2l import mxnet as d2l
from mxnet import np, npx
from mxnet.numpy.random import multinomial
import random
npx.set_np()
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
%matplotlib inline
from d2l import torch as d2l
import random
import torch
from torch.distributions.multinomial import Multinomial
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
%matplotlib inline
from d2l import tensorflow as d2l
import random
import tensorflow as tf
from tensorflow_probability import distributions as tfd
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
%matplotlib inline
from d2l import jax as d2l
import random
import jax
from jax import numpy as jnp
import numpy as np
</code></pre>
<h2 id="간단한-예제-동전-던지기-a-simple-example-tossing-coins"><a class="header" href="#간단한-예제-동전-던지기-a-simple-example-tossing-coins">간단한 예제: 동전 던지기 (A Simple Example: Tossing Coins)</a></h2>
<p>우리가 동전을 던질 계획이고 앞면(대 뒷면)이 나올 가능성이 얼마나 되는지
정량화하고 싶다고 상상해 보십시오.
동전이 *공정(fair)*하다면, 두 결과(앞면과 뒷면)가 나올 가능성은 동일합니다.
게다가 동전을 $n$번 던질 계획이라면, 우리가 볼 것으로 <em>예상</em>되는 앞면의 비율은
뒷면의 <em>예상</em> 비율과 정확히 일치해야 합니다.
이것을 보는 직관적인 방법 중 하나는 대칭입니다:
$n_\textrm{h}$개의 앞면과 $n_\textrm{t} = (n - n_\textrm{h})$개의 뒷면이 있는 모든 가능한 결과에 대해, $n_\textrm{t}$개의 앞면과 $n_\textrm{h}$개의 뒷면이 있는 똑같이 가능한 결과가 있습니다.
이것은 평균적으로 던지기의 $1/2$이 앞면이 나오고 $1/2$이 뒷면이 나올 것으로 예상하는 경우에만 가능하다는 점에 유의하십시오.
물론 각각 $n=1000000$번 던지기로 이 실험을 여러 번 수행하더라도,
$n_\textrm{h} = n_\textrm{t}$가 정확히 일치하는 시행은 결코 보지 못할 수도 있습니다.</p>
<p>공식적으로 양 $1/2$을 <em>확률</em>이라고 하며,
여기서는 주어진 던지기에서 앞면이 나올 확실성을 포착합니다.
확률은 관심 있는 결과, 즉 *사건(events)*에 $0$과 $1$ 사이의 점수를 할당합니다.
여기서 관심 있는 사건은 $\textrm{heads}$이며 해당 확률을 $P(\textrm{heads})$로 나타냅니다.
확률 $1$은 절대적인 확실성을 나타내고(양쪽이 모두 앞면인 속임수 동전을 상상해 보십시오)
확률 $0$은 불가능함을 나타냅니다(예: 양쪽이 모두 뒷면인 경우).
빈도 $n_\textrm{h}/n$과 $n_\textrm{t}/n$은 확률이 아니라 <em>통계</em>입니다.
확률은 데이터 생성 프로세스의 기초가 되는 <em>이론적</em> 양입니다.
여기서 확률 $1/2$은 동전 자체의 속성입니다.
반면 통계는 관찰된 데이터의 함수로 계산되는 <em>경험적</em> 양입니다.
확률적 및 통계적 양에 대한 우리의 관심은 불가분의 관계에 있습니다.
우리는 종종 데이터셋이 주어졌을 때 확률과 같은 모델 파라미터의 *추정치(estimates)*를 생성하는
*추정량(estimators)*이라는 특별한 통계를 설계합니다.
게다가 그 추정량이 *일관성(consistency)*이라는 좋은 속성을 만족할 때,
우리의 추정치는 해당 확률로 수렴할 것입니다.
결과적으로 이러한 추론된 확률은
우리가 미래에 마주칠 수 있는 동일한 모집단의 데이터에 대한
가능성 있는 통계적 속성에 대해 알려줍니다.</p>
<p>우리가 실제 $P(\textrm{heads})$를 모르는
진짜 동전을 우연히 발견했다고 가정해 봅시다.
이 양을 통계적 방법으로 조사하려면,
우리는 (i) 데이터를 수집하고; (ii) 추정량을 설계해야 합니다.
여기서 데이터 획득은 쉽습니다; 동전을 여러 번 던지고 모든 결과를 기록할 수 있습니다.
공식적으로 기본 확률 프로세스에서 실현(realizations)을 그리는 것을 *샘플링(sampling)*이라고 합니다.
짐작하셨겠지만, 하나의 자연스러운 추정량은
관찰된 <em>앞면</em>의 수를 총 던지기 횟수로 나눈 비율입니다.</p>
<p>이제 동전이 실제로 공정하다고 가정해 봅시다.
즉, $P(\textrm{heads}) = 0.5$.
공정한 동전 던지기를 시뮬레이션하기 위해 임의의 난수 생성기를 호출할 수 있습니다.
확률 $0.5$로 사건의 샘플을 그리는 쉬운 방법이 몇 가지 있습니다.
예를 들어 Python의 <code>random.random</code>은 구간 $[0,1]$의 숫자를 산출하며,
여기서 임의의 하위 구간 $[a, b] \subset [0,1]$에 있을 확률은 $b-a$와 같습니다.
따라서 반환된 부동 소수점 숫자가 <code>0.5</code>보다 큰지 테스트하여
각각 확률 <code>0.5</code>로 <code>0</code>과 <code>1</code>을 얻을 수 있습니다.</p>
<pre><code class="language-{.python .input}">%%tab all
num_tosses = 100
heads = sum([random.random() &gt; 0.5 for _ in range(num_tosses)])
tails = num_tosses - heads
print("heads, tails: ", [heads, tails])
</code></pre>
<p>일반적으로 다항 함수(multinomial function)를 호출하여
가능한 결과의 수가 유한한 모든 변수(동전 던지기나 주사위 굴리기 등)에서
여러 번 그리기를 시뮬레이션할 수 있습니다.
첫 번째 인수를 그리기 횟수로 설정하고
두 번째 인수를 각 가능한 결과와 관련된 확률 리스트로 설정합니다.
공정한 동전 던지기를 10번 시뮬레이션하기 위해 확률 벡터 <code>[0.5, 0.5]</code>를 할당하고,
인덱스 0을 앞면으로, 인덱스 1을 뒷면으로 해석합니다.
함수는 가능한 결과의 수(여기서는 2)와 동일한 길이를 가진 벡터를 반환하며,
여기서 첫 번째 성분은 앞면의 발생 횟수를 알려주고
두 번째 성분은 뒷면의 발생 횟수를 알려줍니다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
fair_probs = [0.5, 0.5]
multinomial(100, fair_probs)
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
fair_probs = torch.tensor([0.5, 0.5])
Multinomial(100, fair_probs).sample()
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
fair_probs = tf.ones(2) / 2
tfd.Multinomial(100, fair_probs).sample()
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
fair_probs = [0.5, 0.5]
# jax.random에는 다항 분포가 구현되어 있지 않습니다
np.random.multinomial(100, fair_probs)
</code></pre>
<p>이 샘플링 과정을 실행할 때마다,
이전 결과와 다를 수 있는 새로운 무작위 값을 받게 됩니다.
던진 횟수로 나누면 데이터에서 각 결과의 <em>빈도</em>를 얻을 수 있습니다.
이러한 빈도는 추정하려는 확률과 마찬가지로 합이 $1$이 된다는 점에 유의하십시오.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
multinomial(100, fair_probs) / 100
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
Multinomial(100, fair_probs).sample() / 100
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
tfd.Multinomial(100, fair_probs).sample() / 100
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
np.random.multinomial(100, fair_probs) / 100
</code></pre>
<p>여기서 시뮬레이션된 동전이 공정하더라도
(우리 스스로 확률을 <code>[0.5, 0.5]</code>로 설정했음), 앞면과 뒷면의 수가 동일하지 않을 수 있습니다.
비교적 적은 수의 샘플만 뽑았기 때문입니다.
시뮬레이션을 직접 구현하지 않고 결과만 보았다면,
동전이 약간 불공정한지 아니면 $1/2$에서 벗어난 가능성이
단지 작은 표본 크기의 인공물(artifact)인지 어떻게 알 수 있을까요?
10,000번 던지기를 시뮬레이션할 때 어떤 일이 일어나는지 봅시다.</p>
<pre><code class="language-{.python .input}">%%tab mxnet
counts = multinomial(10000, fair_probs).astype(np.float32)
counts / 10000
</code></pre>
<pre><code class="language-{.python .input}">%%tab pytorch
counts = Multinomial(10000, fair_probs).sample()
counts / 10000
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
counts = tfd.Multinomial(10000, fair_probs).sample()
counts / 10000
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
counts = np.random.multinomial(10000, fair_probs).astype(np.float32)
counts / 10000
</code></pre>
<p>일반적으로 반복되는 사건(동전 던지기 등)의 평균의 경우,
반복 횟수가 증가함에 따라 우리의 추정치는
실제 기본 확률로 수렴하도록 보장됩니다.
이 현상의 수학적 공식화를 *대수의 법칙(law of large numbers)*이라고 하며,
*중심 극한 정리(central limit theorem)*는 많은 상황에서
표본 크기 $n$이 증가함에 따라 이러한 오류가 $(1/\sqrt{n})$의 비율로 줄어들어야 함을 알려줍니다.
던지기 횟수를 1에서 10,000으로 늘림에 따라 추정치가 어떻게 진화하는지 연구하여
더 많은 직관을 얻어 봅시다.</p>
<pre><code class="language-{.python .input}">%%tab pytorch
counts = Multinomial(1, fair_probs).sample((10000,))
cum_counts = counts.cumsum(dim=0)
estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)
estimates = estimates.numpy()

d2l.set_figsize((4.5, 3.5))
d2l.plt.plot(estimates[:, 0], label=("P(coin=heads)"))
d2l.plt.plot(estimates[:, 1], label=("P(coin=tails)"))
d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')
d2l.plt.gca().set_xlabel('Samples')
d2l.plt.gca().set_ylabel('Estimated probability')
d2l.plt.legend();
</code></pre>
<pre><code class="language-{.python .input}">%%tab mxnet
counts = multinomial(1, fair_probs, size=10000)
cum_counts = counts.astype(np.float32).cumsum(axis=0)
estimates = cum_counts / cum_counts.sum(axis=1, keepdims=True)
</code></pre>
<pre><code class="language-{.python .input}">%%tab tensorflow
counts = tfd.Multinomial(1, fair_probs).sample(10000)
cum_counts = tf.cumsum(counts, axis=0)
estimates = cum_counts / tf.reduce_sum(cum_counts, axis=1, keepdims=True)
estimates = estimates.numpy()
</code></pre>
<pre><code class="language-{.python .input}">%%tab jax
counts = np.random.multinomial(1, fair_probs, size=10000).astype(np.float32)
cum_counts = counts.cumsum(axis=0)
estimates = cum_counts / cum_counts.sum(axis=1, keepdims=True)
</code></pre>
<pre><code class="language-{.python .input}">%%tab mxnet, tensorflow, jax
d2l.set_figsize((4.5, 3.5))
d2l.plt.plot(estimates[:, 0], label=("P(coin=heads)"))
d2l.plt.plot(estimates[:, 1], label=("P(coin=tails)"))
d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')
d2l.plt.gca().set_xlabel('Samples')
d2l.plt.gca().set_ylabel('Estimated probability')
d2l.plt.legend();
</code></pre>
<p>각 실선 곡선은 동전의 두 값 중 하나에 해당하며
각 실험 그룹 후 동전이 해당 값을 낼 것으로 추정되는 확률을 제공합니다.
검은색 점선은 실제 기본 확률을 나타냅니다.
더 많은 실험을 수행하여 더 많은 데이터를 얻으면,
곡선은 실제 확률로 수렴합니다.
여러분은 이미 통계학자들을 몰두하게 하는
더 발전된 질문들의 윤곽을 보기 시작했을 것입니다:
이 수렴은 얼마나 빨리 일어나는가?
동일한 공장에서 제조된 많은 동전을 이미 테스트했다면,
이 정보를 어떻게 통합할 수 있을까?</p>
<h2 id="더-공식적인-처리-a-more-formal-treatment"><a class="header" href="#더-공식적인-처리-a-more-formal-treatment">더 공식적인 처리 (A More Formal Treatment)</a></h2>
<p>우리는 이미 꽤 멀리 왔습니다: 확률 모델을 제기하고,
합성 데이터를 생성하고, 통계적 추정량을 실행하고,
경험적으로 수렴을 평가하고, 오류 지표를 보고(편차 확인)했습니다.
그러나 훨씬 더 나아가려면 더 정확해야 합니다.</p>
<p>무작위성을 다룰 때, 우리는 가능한 결과의 집합을 $\mathcal{S}$로 나타내고
이를 <em>표본 공간(sample space)</em> 또는 *결과 공간(outcome space)*이라고 부릅니다.
여기서 각 요소는 별개의 가능한 *결과(outcome)*입니다.
단일 동전을 던지는 경우, $\mathcal{S} = {\textrm{heads}, \textrm{tails}}$입니다.
단일 주사위의 경우, $\mathcal{S} = {1, 2, 3, 4, 5, 6}$입니다.
동전 두 개를 던질 때 가능한 결과는
${(\textrm{heads}, \textrm{heads}), (\textrm{heads}, \textrm{tails}), (\textrm{tails}, \textrm{heads}),  (\textrm{tails}, \textrm{tails})}$입니다.
*사건(Events)*은 표본 공간의 부분 집합입니다.
예를 들어, "첫 번째 동전 던지기가 앞면이 나오는" 사건은
집합 ${(\textrm{heads}, \textrm{heads}), (\textrm{heads}, \textrm{tails})}$에 해당합니다.
무작위 실험의 결과 $z$가 $z \in \mathcal{A}$를 만족할 때마다 사건 $\mathcal{A}$가 발생했습니다.
주사위를 한 번 굴릴 때, 우리는 "$5$ 보기"($\mathcal{A} = {5}$)와
"홀수 보기"($\mathcal{B} = {1, 3, 5}$)라는 사건을 정의할 수 있습니다.
이 경우, 주사위가 $5$가 나오면 $\mathcal{A}$와 $\mathcal{B}$가 모두 발생했다고 말합니다.
반면 $z = 3$이면 $\mathcal{A}$는 발생하지 않았지만 $\mathcal{B}$는 발생했습니다.</p>
<p><em>확률</em> 함수는 사건을 실수 값 ${P: \mathcal{A} \subseteq \mathcal{S} \rightarrow [0,1]}$에 매핑합니다.
주어진 표본 공간 $\mathcal{S}$에서 사건 $\mathcal{A}$의 확률 $P(\mathcal{A})$는
다음 속성을 갖습니다:</p>
<ul>
<li>모든 사건 $\mathcal{A}$의 확률은 음이 아닌 실수입니다. 즉, $P(\mathcal{A}) \geq 0$;</li>
<li>전체 표본 공간의 확률은 $1$입니다. 즉, $P(\mathcal{S}) = 1$;</li>
<li>*상호 배타적(mutually exclusive)*인(즉, 모든 $i \neq j$에 대해 $\mathcal{A}_i \cap \mathcal{A}_j = \emptyset$) 가산 가능한 사건 시퀀스 $\mathcal{A}_1, \mathcal{A}<em>2, \ldots$에 대해, 그들 중 하나라도 발생할 확률은 개별 확률의 합과 같습니다. 즉, $P(\bigcup</em>{i=1}^{\infty} \mathcal{A}<em>i) = \sum</em>{i=1}^{\infty} P(\mathcal{A}_i)$.</li>
</ul>
<p>:citet:<code>Kolmogorov.1933</code>이 제안한 이러한 확률 이론의 공리들은
여러 중요한 결과를 빠르게 도출하는 데 적용될 수 있습니다.
예를 들어, 사건 $\mathcal{A}$ <em>또는</em> 그 여사건 $\mathcal{A}'$가 발생할 확률은 1입니다
($\mathcal{A} \cup \mathcal{A}' = \mathcal{S}$이기 때문).
우리는 또한 $P(\emptyset) = 0$임을 증명할 수 있습니다.
$1 = P(\mathcal{S} \cup \mathcal{S}') = P(\mathcal{S} \cup \emptyset) = P(\mathcal{S}) + P(\emptyset) = 1 + P(\emptyset)$이기 때문입니다.
결과적으로 사건 $\mathcal{A}$ <em>와</em> 그 여사건 $\mathcal{A}'$가 동시에 발생할 확률은
$P(\mathcal{A} \cap \mathcal{A}') = 0$입니다.
비공식적으로, 이것은 불가능한 사건이 발생할 확률이 0임을 알려줍니다.</p>
<h2 id="확률-변수-random-variables"><a class="header" href="#확률-변수-random-variables">확률 변수 (Random Variables)</a></h2>
<p>동전 던지기나 주사위 굴리기와 같은 사건에 대해 이야기할 때,
우리는 *확률 변수(random variable)*라는 아이디어를 불러일으키고 있었습니다.
공식적으로 확률 변수는 기본 표본 공간에서
(아마도 많은) 값의 집합으로의 매핑입니다.
확률 변수가 표본 공간과 어떻게 다른지 궁금할 수 있습니다.
둘 다 결과의 모음이기 때문입니다.
중요한 점은 확률 변수가 원시 표본 공간보다 훨씬 더 거칠 수(coarser) 있다는 것입니다.
기본 표본 공간이 무한하더라도(예: $0$과 $1$ 사이의 선분 위의 점), "0.5보다 큼"과 같은 이진 확률 변수를 정의할 수 있습니다.
또한 여러 확률 변수가 동일한 기본 표본 공간을 공유할 수 있습니다.
예를 들어 "내 집 경보가 울리는지 여부"와
"내 집에 도둑이 들었는지 여부"는
기본 표본 공간을 공유하는 이진 확률 변수입니다.
결과적으로, 한 확률 변수가 취한 값을 알면
다른 확률 변수의 가능한 값에 대해 무언가를 알 수 있습니다.
경보가 울렸다는 것을 알면, 집이 털렸을 가능성이 높다고 의심할 수 있습니다.</p>
<p>확률 변수가 취하는 모든 값은 기본 표본 공간의 부분 집합에 해당합니다.
따라서 확률 변수 $X$가 값 $v$를 취하는 발생($X=v$로 표시)은 <em>사건</em>이며,
$P(X=v)$는 그 확률을 나타냅니다.
때때로 이 표기법은 투박해질 수 있으며, 문맥이 명확할 때 표기법을 남용할 수 있습니다.
예를 들어, $P(X)$를 사용하여 $X$의 <em>분포(distribution)</em>, 즉 $X$가 주어진 값을 취할 확률을 알려주는 함수를 광범위하게 지칭할 수 있습니다.
다른 때에는 $P(X,Y) = P(X) P(Y)$와 같은 표현을 사용하여
확률 변수 $X$와 $Y$가 취할 수 있는 모든 값에 대해 참인 진술을 속기로 표현합니다.
즉, 모든 $i,j$에 대해 $P(X=i \textrm{ and } Y=j) = P(X=i)P(Y=j)$가 성립합니다.
다른 때에는 확률 변수가 문맥에서 명확할 때 $P(v)$라고 써서 표기법을 남용합니다.
확률 이론의 사건은 표본 공간의 결과 집합이므로, 확률 변수가 취할 값의 범위를 지정할 수 있습니다.
예를 들어, $P(1 \leq X \leq 3)$은 사건 ${1 \leq X \leq 3}$의 확률을 나타냅니다.</p>
<p>동전 던지기나 주사위 굴리기와 같은 <em>이산(discrete)</em> 확률 변수와
모집단에서 무작위로 추출한 사람의 체중이나 키와 같은 <em>연속(continuous)</em> 확률 변수 사이에는
미묘한 차이가 있음에 유의하십시오.
이 경우 우리는 누군가의 정확한 키에 대해 거의 신경 쓰지 않습니다.
게다가 우리가 충분히 정밀한 측정을 했다면,
지구상의 어떤 두 사람도 정확히 같은 키를 가지고 있지 않다는 것을 알게 될 것입니다.
사실 충분히 미세한 측정으로, 여러분은 일어날 때와 잠자리에 들 때
절대 같은 키를 가질 수 없을 것입니다.
누군가의 키가 정확히 1.801392782910287192 미터일 정확한 확률을 묻는 것은 의미가 없습니다.
대신, 우리는 일반적으로 누군가의 키가 주어진 구간, 예를 들어 1.79와 1.81 미터 사이에 속하는지 말할 수 있는 것에 더 관심이 있습니다.
이러한 경우 우리는 확률 *밀도(densities)*를 다룹니다.
정확히 1.80 미터의 키는 확률이 없지만 0이 아닌 밀도를 갖습니다.
구간에 할당된 확률을 알아내려면, 해당 구간에 대해 밀도의 *적분(integral)*을 취해야 합니다.</p>
<h2 id="다중-확률-변수-multiple-random-variables"><a class="header" href="#다중-확률-변수-multiple-random-variables">다중 확률 변수 (Multiple Random Variables)</a></h2>
<p>여러 확률 변수 간의 상호 작용과 관련된 진술을 하지 않고는
이전 섹션을 통과할 수도 없었다는 것을 눈치챘을 것입니다
($P(X,Y) = P(X) P(Y)$를 상기하십시오).
머신러닝의 대부분은 이러한 관계와 관련이 있습니다.
여기서 표본 공간은 관심 있는 모집단, 예를 들어 비즈니스와 거래하는 고객, 인터넷상의 사진, 또는 생물학자에게 알려진 단백질일 수 있습니다.
각 확률 변수는 서로 다른 속성의 (알려지지 않은) 값을 나타냅니다.
모집단에서 개인을 샘플링할 때마다, 우리는 각 확률 변수의 실현을 관찰합니다.
확률 변수가 취하는 값은 겹치거나, 부분적으로 겹치거나, 완전히 분리될 수 있는
표본 공간의 부분 집합에 해당하기 때문에, 한 확률 변수가 취한 값을 알면
다른 확률 변수의 어떤 값이 가능성이 있는지에 대한
믿음을 업데이트할 수 있습니다.
환자가 병원에 걸어 들어왔는데 그들이 숨 쉬는 데 어려움을 겪고 있고
후각을 상실했다는 것을 관찰했다면,
그들이 숨 쉬는 데 문제가 없고 완전히 평범한 후각을 가진 경우보다
COVID-19에 걸렸을 가능성이 더 높다고 믿습니다.</p>
<p>여러 확률 변수로 작업할 때, 우리는 변수들이 공동으로 취할 수 있는 모든 값의 조합에 해당하는
사건을 구성할 수 있습니다.
이러한 각 조합(예: $A=a$ 및 $B=b$)에 확률을 할당하는 확률 함수를
<em>결합 확률(joint probability)</em> 함수라고 하며,
단순히 표본 공간의 해당 부분 집합의 교집합에 할당된 확률을 반환합니다.
확률 변수 $A$와 $B$가 각각 값 $a$와 $b$를 취하는 사건에 할당된 <em>결합 확률</em>은
$P(A = a, B = b)$로 표시되며, 여기서 쉼표는 "그리고(and)"를 나타냅니다.
모든 값 $a$와 $b$에 대해 다음이 성립한다는 점에 유의하십시오.</p>
<p>$$P(A=a, B=b) \leq P(A=a) \textrm{ and } P(A=a, B=b) \leq P(B = b),$$</p>
<p>$A=a$와 $B=b$가 발생하려면 $A=a$가 발생해야 <em>하고</em> $B=b$도 발생해야 하기 때문입니다.
흥미롭게도 결합 확률은 이러한 확률 변수에 대해 우리가 알 수 있는 모든 것을
확률적 의미에서 알려주며, 개별 분포 $P(A)$와 $P(B)$를 복구하는 것을 포함하여
다른 많은 유용한 양을 도출하는 데 사용할 수 있습니다.
$P(A=a)$를 복구하려면 확률 변수 $B$가 취할 수 있는 모든 값 $v$에 대해
$P(A=a, B=v)$를 합산하면 됩니다:
$P(A=a) = \sum_v P(A=a, B=v)$.</p>
<p>비율 $\frac{P(A=a, B=b)}{P(A=a)} \leq 1$은 매우 중요한 것으로 밝혀졌습니다.
이것을 *조건부 확률(conditional probability)*이라고 하며 "$\mid$" 기호를 통해 표시됩니다:</p>
<p>$$P(B=b \mid A=a) = P(A=a,B=b)/P(A=a).$$</p>
<p>이것은 $A=a$가 발생했다는 사실을 조건으로 했을 때,
사건 $B=b$와 관련된 새로운 확률을 알려줍니다.
이 조건부 확률을 $A=a$와 관련된 표본 공간의 부분 집합에만 관심을 제한한 다음
모든 확률의 합이 1이 되도록 재정규화하는 것으로 생각할 수 있습니다.
조건부 확률은 사실 일반적인 확률일 뿐이므로
모든 항을 동일한 사건에 조건화하여 동일한 표본 공간에 주의를 제한하는 한
모든 공리를 존중합니다.
예를 들어, 분리된 사건 $\mathcal{B}$와 $\mathcal{B}'$에 대해
$P(\mathcal{B} \cup \mathcal{B}' \mid A = a) = P(\mathcal{B} \mid A = a) + P(\mathcal{B}' \mid A = a)$가 성립합니다.</p>
<p>조건부 확률의 정의를 사용하여 *베이즈 정리(Bayes' theorem)*라는 유명한 결과를 도출할 수 있습니다.
구성에 따라 $P(A, B) = P(B\mid A) P(A)$이고 $P(A, B) = P(A\mid B) P(B)$입니다.
두 방정식을 결합하면 $P(B\mid A) P(A) = P(A\mid B) P(B)$가 되고 따라서 다음을 얻습니다.</p>
<p>$$P(A \mid B) = \frac{P(B\mid A) P(A)}{P(B)}.$$</p>
<p>이 간단한 방정식은 조건화 순서를 뒤집을 수 있게 해주기 때문에 심오한 의미를 갖습니다.
$P(B\mid A)$, $P(A)$, $P(B)$를 추정하는 방법을 안다면,
$P(A\mid B)$를 추정할 수 있습니다.
우리는 종종 한 항을 직접 추정하는 것이 다른 항보다 쉽다는 것을 알게 되는데,
여기서 베이즈 정리가 구출해 줄 수 있습니다.
예를 들어, 특정 질병에 대한 증상의 유병률과 질병 및 증상의 전체 유병률을 각각 알고 있다면,
증상을 바탕으로 누군가가 질병에 걸렸을 가능성을 결정할 수 있습니다.
어떤 경우에는 증상의 유병률과 같은 $P(B)$에 직접 액세스하지 못할 수도 있습니다.
이 경우 베이즈 정리의 단순화된 버전이 유용합니다:</p>
<p>$$P(A \mid B) \propto P(B \mid A) P(A).$$</p>
<p>$P(A \mid B)$가 $1$로 정규화되어야 함을 알고 있으므로, 즉 $\sum_a P(A=a \mid B) = 1$,
다음을 계산하는 데 사용할 수 있습니다.</p>
<p>$$P(A \mid B) = \frac{P(B \mid A) P(A)}{\sum_a P(B \mid A=a) P(A = a)}.$$</p>
<p>베이지안 통계에서 우리는 관찰자가 <em>사전 확률(prior)</em> $P(H)$에 인코딩된
사용 가능한 가설의 타당성에 대한 일부 (주관적인) 사전 믿음과,
클래스 $P(E \mid H)$의 각 가설에 대해 수집된 증거의 값을 관찰할 가능성이 얼마나 되는지 말해주는
*우도 함수(likelihood function)*를 가지고 있다고 생각합니다.
베이즈 정리는 사용 가능한 증거 $E$에 비추어 초기 <em>사전 확률</em> $P(H)$를 업데이트하여
<em>사후 확률(posterior)</em> 믿음 $P(H \mid E) = \frac{P(E \mid H) P(H)}{P(E)}$를 생성하는 방법을
알려주는 것으로 해석됩니다.
비공식적으로 이것은 "사후 확률은 사전 확률 곱하기 우도를 증거로 나눈 것과 같다"라고 진술할 수 있습니다.
이제 증거 $P(E)$는 모든 가설에 대해 동일하므로,
가설에 대해 단순히 정규화하는 것으로 넘어갈 수 있습니다.</p>
<p>$\sum_a P(A=a \mid B) = 1$은 또한 확률 변수에 대해 *주변화(marginalize)*할 수 있게 해줍니다.
즉, $P(A, B)$와 같은 결합 분포에서 변수를 삭제할 수 있습니다.
결국 다음을 얻습니다.</p>
<p>$$\sum_a P(B \mid A=a) P(A=a) = \sum_a P(B, A=a) = P(B).$$</p>
<p>독립성(Independence)은 통계학의 많은 중요한 아이디어의 중추를 형성하는
또 다른 근본적으로 중요한 개념입니다.
간단히 말해서, $A$의 값에 대한 조건화가
$B$와 관련된 확률 분포에 어떠한 변화도 일으키지 않고 그 반대의 경우도 마찬가지라면,
두 변수는 <em>독립</em>입니다.
더 공식적으로, $A \perp B$로 표시되는 독립성은
$P(A \mid B) = P(A)$를 요구하며, 결과적으로
$P(A,B) = P(A \mid B) P(B) = P(A) P(B)$를 요구합니다.
독립성은 종종 적절한 가정입니다.
예를 들어, 확률 변수 $A$가 공정한 동전 하나를 던진 결과를 나타내고
확률 변수 $B$가 다른 동전을 던진 결과를 나타낸다면,
$A$가 앞면이 나왔는지 아는 것이 $B$가 앞면이 나올 확률에 영향을 주어서는 안 됩니다.</p>
<p>독립성은 기본 분포에서 데이터의 연속적인 추출 사이에 성립할 때(강력한 통계적 결론을 내릴 수 있음)
또는 데이터의 다양한 변수 사이에 성립할 때 특히 유용하며,
이 독립성 구조를 인코딩하는 더 간단한 모델로 작업할 수 있게 해줍니다.
반면에 확률 변수 간의 종속성을 추정하는 것은 종종 학습의 바로 그 목표입니다.
우리는 질병과 증상이 독립적이지 않다고 믿기 때문에
증상이 주어졌을 때 질병의 확률을 추정하는 데 관심을 갖습니다.</p>
<p>조건부 확률은 적절한 확률이기 때문에 독립성과 종속성의 개념도 적용된다는 점에 유의하십시오.
두 확률 변수 $A$와 $B$는 제3의 변수 $C$가 주어졌을 때
$P(A, B \mid C) = P(A \mid C)P(B \mid C)$인 경우에만 *조건부 독립(conditionally independent)*입니다.
흥미롭게도 두 변수는 일반적으로 독립적일 수 있지만
제3의 변수에 대해 조건화할 때 종속적이 될 수 있습니다.
이것은 두 확률 변수 $A$와 $B$가 제3의 변수 $C$의 원인에 해당할 때 종종 발생합니다.
예를 들어 골절과 폐암은 일반 모집단에서는 독립적일 수 있지만,
병원에 입원한 경우를 조건으로 하면 골절이 폐암과 음의 상관관계가 있음을 발견할 수 있습니다.
골절이 어떤 사람이 병원에 입원한 이유를 <em>설명해 버리기(explains away)</em> 때문에
폐암에 걸려 입원했을 확률을 낮추기 때문입니다.</p>
<p>반대로, 두 종속 확률 변수는 제3의 변수에 대해 조건화할 때 독립적이 될 수 있습니다.
이것은 그렇지 않으면 관련이 없는 두 사건이 공통 원인을 가질 때 종종 발생합니다.
신발 사이즈와 독해 수준은 초등학생들 사이에서 높은 상관관계가 있지만,
나이를 조건으로 하면 이 상관관계는 사라집니다.</p>
<h2 id="예제-an-example"><a class="header" href="#예제-an-example">예제 (An Example)</a></h2>
<p>:label:<code>subsec_probability_hiv_app</code></p>
<p>우리의 기술을 시험해 봅시다.
의사가 환자에게 HIV 검사를 시행한다고 가정합니다.
이 검사는 상당히 정확하며 환자가 건강하지만 질병이 있다고 보고되는 경우,
즉 건강한 환자가 1%의 경우 양성 반응을 보이는 경우에만 1% 확률로 실패합니다.
게다가 환자가 실제로 HIV에 걸린 경우 감지하는 데 결코 실패하지 않습니다.
우리는 $D_1 \in {0, 1}$을 사용하여 진단을 나타내고
($0$이면 음성, $1$이면 양성)
$H \in {0, 1}$을 사용하여 HIV 상태를 나타냅니다.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">조건부 확률</th><th style="text-align: right">$H=1$</th><th style="text-align: right">$H=0$</th></tr></thead><tbody>
<tr><td style="text-align: left">$P(D_1 = 1 \mid H)$</td><td style="text-align: right">1</td><td style="text-align: right">0.01</td></tr>
<tr><td style="text-align: left">$P(D_1 = 0 \mid H)$</td><td style="text-align: right">0</td><td style="text-align: right">0.99</td></tr>
</tbody></table>
</div>
<p>열의 합은 모두 1입니다(행의 합은 그렇지 않음).
이들은 조건부 확률이기 때문입니다.
검사 결과가 양성으로 나오면 환자가 HIV에 걸릴 확률, 즉 $P(H = 1 \mid D_1 = 1)$을 계산해 봅시다.
직관적으로 이것은 질병이 얼마나 흔한지에 달려 있습니다.
거짓 경보의 수에 영향을 미치기 때문입니다.
모집단에 질병이 거의 없다고 가정해 봅시다. 예: $P(H=1) = 0.0015$.
베이즈 정리를 적용하려면 주변화를 적용하여 다음을 결정해야 합니다.</p>
<p>$$\begin{aligned}
P(D_1 = 1)
=&amp; P(D_1=1, H=0) + P(D_1=1, H=1)  \
=&amp; P(D_1=1 \mid H=0) P(H=0) + P(D_1=1 \mid H=1) P(H=1) \
=&amp; 0.011485.
\end{aligned}
$$</p>
<p>이것은 다음으로 이어집니다.</p>
<p>$$P(H = 1 \mid D_1 = 1) = \frac{P(D_1=1 \mid H=1) P(H=1)}{P(D_1=1)} = 0.1306.$$</p>
<p>즉, 검사가 꽤 정확함에도 불구하고 환자가 실제로 HIV에 걸렸을 확률은 13.06%에 불과합니다.
보시다시피 확률은 직관에 반할 수 있습니다.
그런 무시무시한 소식을 접한 환자는 어떻게 해야 할까요?
아마도 환자는 의사에게 명확성을 얻기 위해 다른 검사를 시행해 달라고 요청할 것입니다.
두 번째 검사는 다른 특성을 가지고 있으며 첫 번째 검사만큼 좋지 않습니다.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">조건부 확률</th><th style="text-align: right">$H=1$</th><th style="text-align: right">$H=0$</th></tr></thead><tbody>
<tr><td style="text-align: left">$P(D_2 = 1 \mid H)$</td><td style="text-align: right">0.98</td><td style="text-align: right">0.03</td></tr>
<tr><td style="text-align: left">$P(D_2 = 0 \mid H)$</td><td style="text-align: right">0.02</td><td style="text-align: right">0.97</td></tr>
</tbody></table>
</div>
<p>불행히도 두 번째 검사도 양성으로 나옵니다.
조건부 독립성을 가정하여 베이즈 정리를 호출하는 데 필요한 확률을 계산해 봅시다.</p>
<p>$$\begin{aligned}
P(D_1 = 1, D_2 = 1 \mid H = 0)
&amp; = P(D_1 = 1 \mid H = 0) P(D_2 = 1 \mid H = 0)
=&amp; 0.0003, \
P(D_1 = 1, D_2 = 1 \mid H = 1)
&amp; = P(D_1 = 1 \mid H = 1) P(D_2 = 1 \mid H = 1)
=&amp; 0.98.
\end{aligned}
$$</p>
<p>이제 주변화를 적용하여 두 검사 모두 양성으로 나올 확률을 얻을 수 있습니다.</p>
<p>$$\begin{aligned}
&amp;P(D_1 = 1, D_2 = 1)\
&amp;= P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \
&amp;= P(D_1 = 1, D_2 = 1 \mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \mid H = 1)P(H=1)\
&amp;= 0.00176955.
\end{aligned}
$$</p>
<p>마지막으로, 두 검사가 모두 양성일 때 환자가 HIV에 걸렸을 확률은 다음과 같습니다.</p>
<p>$$P(H = 1 \mid D_1 = 1, D_2 = 1)
= \frac{P(D_1 = 1, D_2 = 1 \mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)}
= 0.8307.$$</p>
<p>즉, 두 번째 검사를 통해 모든 것이 좋지 않다는 훨씬 더 높은 확신을 얻을 수 있었습니다.
두 번째 검사가 첫 번째 검사보다 훨씬 덜 정확했음에도 불구하고,
여전히 우리의 추정치를 크게 개선했습니다.
두 검사가 서로 조건부 독립적이라는 가정은 더 정확한 추정치를 생성하는 능력에 결정적이었습니다.
동일한 검사를 두 번 실행하는 극단적인 경우를 생각해 보십시오.
이 상황에서는 두 번 모두 같은 결과를 기대하므로 동일한 검사를 다시 실행해도 추가적인 통찰력을 얻을 수 없습니다.
기민한 독자는 진단이 더 많은 특성(검사 결과)을 얻을수록
환자가 건강한지 여부를 결정하는 능력이 증가하는
눈에 잘 띄지 않는 분류기처럼 행동했다는 것을 눈치챘을 수 있습니다.</p>
<h2 id="기댓값-expectations"><a class="header" href="#기댓값-expectations">기댓값 (Expectations)</a></h2>
<p>종종 결정을 내리려면 개별 사건에 할당된 확률만 보는 것이 아니라
지침을 제공할 수 있는 유용한 집계로 구성해야 합니다.
예를 들어, 확률 변수가 연속적인 스칼라 값을 취할 때, 우리는 종종 <em>평균적으로</em> 어떤 값을 기대해야 하는지 아는 데 관심이 있습니다.
이 양을 공식적으로 *기댓값(expectation)*이라고 합니다.
투자를 하는 경우, 첫 번째 관심 수량은
모든 가능한 결과에 대해 평균을 낸(그리고 적절한 확률로 가중치를 둔) 기대 수익일 수 있습니다.
예를 들어, 50% 확률로 투자가 완전히 실패할 수 있고, 40% 확률로 2배 수익을 제공할 수 있으며, 10% 확률로 10배 수익을 제공할 수 있다고 가정해 봅시다.
기대 수익을 계산하기 위해, 모든 수익을 합산하고 각 수익이 발생할 확률을 곱합니다.
이것은 기댓값 $0.5 \cdot 0 + 0.4 \cdot 2 + 0.1 \cdot 10 = 1.8$을 산출합니다.
따라서 기대 수익은 1.8배입니다.</p>
<p>일반적으로 확률 변수 $X$의 <em>기댓값</em> (또는 평균)은 다음과 같이 정의됩니다.</p>
<p>$$E[X] = E_{x \sim P}[x] = \sum_{x} x P(X = x).$$</p>
<p>마찬가지로 밀도에 대해서는 $E[X] = \int x ;dp(x)$를 얻습니다.
때때로 우리는 $x$의 어떤 함수의 기댓값에 관심이 있습니다.
이러한 기댓값은 다음과 같이 계산할 수 있습니다.</p>
<p>$$E_{x \sim P}[f(x)] = \sum_x f(x) P(x) \textrm{ and } E_{x \sim P}[f(x)] = \int f(x) p(x) ;dx$$</p>
<p>이산 확률과 밀도에 대해 각각.
위의 투자 예제로 돌아가서, $f$는 수익과 관련된 <em>효용(utility)</em> (행복)일 수 있습니다.
행동 경제학자들은 오랫동안 사람들이
기준선 대비 1달러를 벌어서 얻는 효용보다
돈을 잃는 것에 더 큰 비효용을 연관시킨다는 점에 주목해 왔습니다.
게다가 돈의 가치는 하위 선형(sub-linear) 경향이 있습니다.
10만 달러를 소유하는 것과 0달러를 소유하는 것의 차이는
임대료를 내고, 잘 먹고, 양질의 의료 서비스를 즐기는 것과
노숙 생활을 겪는 것의 차이를 만들 수 있습니다.
반면 20만 달러 대 10만 달러 소유로 인한 이득은 덜 극적입니다.
이와 같은 추론은 "돈의 효용은 로그적이다"라는 진부한 표현의 동기가 됩니다.</p>
<p>만약 총 손실과 관련된 효용이 $-1$이고,
수익 $1$, $2$, $10$과 관련된 효용이 각각 $1$, $2$, $4$라면, 투자의 기대 행복은 $0.5 \cdot (-1) + 0.4 \cdot 2 + 0.1 \cdot 4 = 0.7$이 됩니다
(효용의 기대 손실 30%).
실제로 이것이 당신의 효용 함수라면, 돈을 은행에 보관하는 것이 가장 좋을 수 있습니다.</p>
<p>재무 결정의 경우, 투자가 얼마나 <em>위험한지</em> 측정하고 싶을 수도 있습니다.
여기서 우리는 기댓값뿐만 아니라 실제 값이 이 값에 비해 얼마나 *변동(vary)*하는 경향이 있는지에 관심을 갖습니다.
실제 값과 기댓값 차이의 기댓값을 취할 수는 없다는 점에 유의하십시오.
차이의 기댓값은 기댓값의 차이이기 때문입니다. 즉, $E[X - E[X]] = E[X] - E[E[X]] = 0$.
그러나 우리는 이 차이의 음이 아닌 함수의 기댓값을 볼 수 있습니다.
확률 변수의 *분산(variance)*은 <em>제곱</em> 차이의 기댓값을 보고 계산됩니다:</p>
<p>$$\textrm{Var}[X] = E\left[(X - E[X])^2\right] = E[X^2] - E[X]^2.$$</p>
<p>여기서 등식은 $(X - E[X])^2 = X^2 - 2 X E[X] + E[X]^2$를 확장하고
각 항에 대한 기댓값을 취함으로써 따릅니다.
분산의 제곱근은 *표준 편차(standard deviation)*라고 하는 또 다른 유용한 양입니다.
이것과 분산은 동일한 정보를 전달하지만(서로 계산 가능),
표준 편차는 확률 변수가 나타내는 원래 수량과 동일한 단위로 표현된다는
좋은 속성을 가지고 있습니다.</p>
<p>마지막으로, 확률 변수 함수의 분산은 유사하게 다음과 같이 정의됩니다.</p>
<p>$$\textrm{Var}<em>{x \sim P}[f(x)] = E</em>{x \sim P}[f^2(x)] - E_{x \sim P}[f(x)]^2.$$</p>
<p>투자 예제로 돌아가서, 이제 투자의 분산을 계산할 수 있습니다.
$0.5 \cdot 0 + 0.4 \cdot 2^2 + 0.1 \cdot 10^2 - 1.8^2 = 8.36$으로 주어집니다.
모든 의도와 목적에 있어 이것은 위험한 투자입니다.
수학적 관례에 따라 평균과 분산은 종종 $\mu$와 $\sigma^2$로 참조됩니다.
이것은 가우스 분포를 파라미터화하기 위해 사용할 때 특히 그렇습니다.</p>
<p><em>스칼라</em> 확률 변수에 대해 기댓값과 분산을 도입한 것과 같은 방식으로,
벡터 값 확률 변수에 대해서도 할 수 있습니다.
기댓값은 요소별로 적용할 수 있으므로 쉽습니다.
예를 들어, $\boldsymbol{\mu} \stackrel{\textrm{def}}{=} E_{\mathbf{x} \sim P}[\mathbf{x}]$는
좌표 $\mu_i = E_{\mathbf{x} \sim P}[x_i]$를 갖습니다.
*공분산(Covariances)*은 더 복잡합니다.
우리는 확률 변수와 그 평균의 차이의 *외적(outer product)*의 기댓값을 취하여 정의합니다:</p>
<p>$$\boldsymbol{\Sigma} \stackrel{\textrm{def}}{=} \textrm{Cov}<em>{\mathbf{x} \sim P}[\mathbf{x}] = E</em>{\mathbf{x} \sim P}\left[(\mathbf{x} - \boldsymbol{\mu}) (\mathbf{x} - \boldsymbol{\mu})^\top\right].$$</p>
<p>이 행렬 $\boldsymbol{\Sigma}$를 공분산 행렬이라고 합니다.
그 효과를 보는 쉬운 방법은 $\mathbf{x}$와 같은 크기의 어떤 벡터 $\mathbf{v}$를 고려하는 것입니다.
다음과 같습니다.</p>
<p>$$\mathbf{v}^\top \boldsymbol{\Sigma} \mathbf{v} = E_{\mathbf{x} \sim P}\left[\mathbf{v}^\top(\mathbf{x} - \boldsymbol{\mu}) (\mathbf{x} - \boldsymbol{\mu})^\top \mathbf{v}\right] = \textrm{Var}_{x \sim P}[\mathbf{v}^\top \mathbf{x}].$$</p>
<p>따라서 $\boldsymbol{\Sigma}$를 사용하면 간단한 행렬 곱셈으로 $\mathbf{x}$의 모든 선형 함수에 대한 분산을 계산할 수 있습니다.
비대각선 요소는 좌표가 얼마나 상관되어 있는지 알려줍니다: 0 값은 상관관계가 없음을 의미하며,
더 큰 양수 값은 더 강하게 상관되어 있음을 의미합니다.</p>
<h2 id="토론"><a class="header" href="#토론">토론</a></h2>
<p>머신러닝에는 불확실한 것들이 많습니다!
입력이 주어졌을 때 레이블의 값에 대해 불확실할 수 있습니다.
파라미터의 추정 값에 대해 불확실할 수 있습니다.
배포 시 도착하는 데이터가 훈련 데이터와 동일한 분포에서 온 것인지조차 불확실할 수 있습니다.</p>
<p>*우연적 불확실성(aleatoric uncertainty)*이란 문제에 내재되어 있고
관찰된 변수로 설명되지 않는 진정한 무작위성으로 인한 불확실성을 의미합니다.
*인식적 불확실성(epistemic uncertainty)*이란 모델 파라미터에 대한 불확실성, 즉 더 많은 데이터를 수집하여 줄일 수 있기를 바라는 종류의 불확실성을 의미합니다.
우리는 동전이 앞면이 나올 확률에 관해 인식적 불확실성을 가질 수 있지만,
이 확률을 알고 나더라도 미래의 던지기 결과에 대한 우연적 불확실성은 남습니다.
누군가가 공정한 동전을 던지는 것을 아무리 오래 지켜보더라도,
다음 던지기가 앞면이 될 것이라는 확신은 50% 이상도 이하도 아닐 것입니다.
이 용어들은 기계적 모델링에서 왔습니다
(<a href="https://en.wikipedia.org/wiki/Uncertainty_quantification">불확실성 정량화</a>의 이 측면에 대한 검토는 예: :citet:<code>Der-Kiureghian.Ditlevsen.2009</code> 참조).
그러나 이 용어들이 언어를 약간 남용하고 있다는 점에 주목할 가치가 있습니다.
<em>인식적</em>이라는 용어는 <em>지식</em>에 관한 모든 것을 지칭하므로, 철학적 의미에서 모든 불확실성은 인식적입니다.</p>
<p>알려지지 않은 확률 분포에서 데이터를 샘플링하면
데이터 생성 분포의 파라미터를 추정하는 데 사용할 수 있는 정보를 제공할 수 있음을 보았습니다.
그렇기는 하지만, 이것이 가능한 속도는 꽤 느릴 수 있습니다.
동전 던지기 예제(및 다른 많은 예제)에서
$1/\sqrt{n}$의 비율로 수렴하는 추정량을 설계하는 것보다 더 잘할 수는 없습니다.
여기서 $n$은 표본 크기(예: 던지기 횟수)입니다.
이는 10개에서 1000개의 관찰로 이동하면(보통 매우 달성 가능한 작업) 불확실성이 10배 감소하는 것을 볼 수 있는 반면,
다음 1000개의 관찰은 비교적 도움이 거의 안 되며 1.41배 감소만 제공한다는 것을 의미합니다.
이것은 머신러닝의 지속적인 특징입니다:
종종 쉬운 이득이 있지만, 추가적인 이득을 얻으려면 매우 많은 양의 데이터와
종종 그에 따른 엄청난 양의 계산이 필요합니다.
대규모 언어 모델에 대한 이 사실의 경험적 검토는 :citet:<code>Revels.Lubin.Papamarkou.2016</code>을 참조하십시오.</p>
<p>우리는 또한 통계적 모델링을 위한 언어와 도구를 연마했습니다.
그 과정에서 우리는 조건부 확률과 통계에서 가장 중요한 방정식 중 하나인 베이즈 정리에 대해 배웠습니다.
이것은 관찰 $B$가 파라미터 $A$의 선택과 얼마나 잘 일치하는지를 다루는 우도 항 $P(B \mid A)$와
애초에 $A$의 특정 선택이 얼마나 그럴듯한지를 지배하는 사전 확률 $P(A)$를 통해
데이터가 전달하는 정보를 분리하는 데 효과적인 도구입니다.
특히, 검사의 효능 <em>및</em> 질병 자체의 유병률(즉, 우리의 사전 확률)을 기반으로
진단에 확률을 할당하는 데 이 규칙을 어떻게 적용할 수 있는지 보았습니다.</p>
<p>마지막으로, 특정 확률 분포의 효과에 대한 첫 번째 비자명한 질문 세트,
즉 기댓값과 분산을 소개했습니다.
확률 분포에 대한 선형 및 2차 기댓값 외에도 더 많은 것이 있지만,
이 두 가지는 이미 분포의 가능한 동작에 대한 상당한 지식을 제공합니다.
예를 들어, <a href="https://en.wikipedia.org/wiki/Chebyshev%27s_inequality">체비쇼프 부등식(Chebyshev's inequality)</a>은
$P(|X - \mu| \geq k \sigma) \leq 1/k^2$라고 명시합니다.
여기서 $\mu$는 기댓값, $\sigma^2$는 분포의 분산, $k &gt; 1$은 우리가 선택한 신뢰 파라미터입니다.
이것은 분포에서 추출한 값이 기댓값을 중심으로 한 $[-\sqrt{2} \sigma, \sqrt{2} \sigma]$ 구간 내에
적어도 50%의 확률로 존재함을 알려줍니다.</p>
<h2 id="연습-문제"><a class="header" href="#연습-문제">연습 문제</a></h2>
<ol>
<li>더 많은 데이터를 관찰하면 결과에 대한 불확실성의 양을 임의로 낮은 수준으로 줄일 수 있는 예를 제시하십시오.</li>
<li>더 많은 데이터를 관찰하면 불확실성의 양이 일정 지점까지만 줄어들고 그 이상은 줄어들지 않는 예를 제시하십시오. 왜 이런 경우가 발생하는지 그리고 이 지점이 어디에서 발생할 것으로 예상하는지 설명하십시오.</li>
<li>우리는 동전 던지기에 대한 평균으로의 수렴을 경험적으로 입증했습니다. $n$개의 샘플을 추출한 후 앞면을 볼 확률 추정치의 분산을 계산하십시오.
<ol>
<li>분산은 관찰 수에 따라 어떻게 확장됩니까?</li>
<li>체비쇼프 부등식을 사용하여 기댓값으로부터의 편차를 제한하십시오.</li>
<li>이것은 중심 극한 정리와 어떤 관련이 있습니까?</li>
</ol>
</li>
<li>평균이 0이고 분산이 1인 확률 분포에서 $m$개의 샘플 $x_i$를 추출한다고 가정합니다. 평균 $z_m \stackrel{\textrm{def}}{=} m^{-1} \sum_{i=1}^m x_i$를 계산합니다. 모든 $z_m$에 대해 독립적으로 체비쇼프 부등식을 적용할 수 있습니까? 왜 안 됩니까?</li>
<li>확률이 $P(\mathcal{A})$와 $P(\mathcal{B})$인 두 사건이 주어졌을 때, $P(\mathcal{A} \cup \mathcal{B})$와 $P(\mathcal{A} \cap \mathcal{B})$의 상한과 하한을 계산하십시오. 힌트: <a href="https://en.wikipedia.org/wiki/Venn_diagram">벤 다이어그램</a>을 사용하여 상황을 그래프로 나타내십시오.</li>
<li>일련의 확률 변수, 예를 들어 $A$, $B$, $C$가 있고, 여기서 $B$는 $A$에만 의존하고 $C$는 $B$에만 의존한다고 가정할 때, 결합 확률 $P(A, B, C)$를 단순화할 수 있습니까? 힌트: 이것은 <a href="https://en.wikipedia.org/wiki/Markov_chain">마르코프 체인</a>입니다.</li>
<li>:numref:<code>subsec_probability_hiv_app</code>에서 두 검사의 결과가 독립적이지 않다고 가정합니다. 특히 두 검사 중 하나라도 10%의 위양성률과 1%의 위음성률을 갖는다고 가정합니다. 즉, $P(D =1 \mid H=0) = 0.1$이고 $P(D = 0 \mid H=1) = 0.01$이라고 가정합니다. 또한 $H = 1$ (감염됨)인 경우 검사 결과는 조건부 독립적, 즉 $P(D_1, D_2 \mid H=1) = P(D_1 \mid H=1) P(D_2 \mid H=1)$이지만 건강한 환자의 경우 결과는 $P(D_1 = D_2 = 1 \mid H=0) = 0.02$를 통해 결합된다고 가정합니다.
<ol>
<li>지금까지 가진 정보를 바탕으로 $H=0$이 주어졌을 때 $D_1$과 $D_2$에 대한 결합 확률 표를 작성하십시오.</li>
<li>한 검사가 양성으로 나온 후 환자가 병에 걸렸을($H=1$) 확률을 도출하십시오. 이전과 동일한 기준 확률 $P(H=1) = 0.0015$를 가정할 수 있습니다.</li>
<li>두 검사 모두 양성으로 나온 후 환자가 병에 걸렸을($H=1$) 확률을 도출하십시오.</li>
</ol>
</li>
<li>당신이 투자 은행의 자산 관리자이고 투자할 주식 $s_i$를 선택할 수 있다고 가정합니다. 포트폴리오는 각 주식에 대한 가중치 $\alpha_i$의 합이 $1$이어야 합니다. 주식은 평균 수익 $\boldsymbol{\mu} = E_{\mathbf{s} \sim P}[\mathbf{s}]$과 공분산 $\boldsymbol{\Sigma} = \textrm{Cov}_{\mathbf{s} \sim P}[\mathbf{s}]$을 갖습니다.
<ol>
<li>주어진 포트폴리오 $\boldsymbol{\alpha}$에 대한 기대 수익을 계산하십시오.</li>
<li>포트폴리오의 수익을 극대화하고 싶다면 투자를 어떻게 선택해야 합니까?</li>
<li>포트폴리오의 <em>분산</em>을 계산하십시오.</li>
<li>분산을 상한으로 제한하면서 수익을 극대화하는 최적화 문제를 공식화하십시오. 이것은 노벨상을 수상한 <a href="https://en.wikipedia.org/wiki/Markowitz_model">마코비츠 포트폴리오</a> :cite:<code>Mangram.2013</code>입니다. 이를 해결하려면 2차 프로그래밍 솔버가 필요하며, 이는 이 책의 범위를 훨씬 벗어납니다.</li>
</ol>
</li>
</ol>
<p>:begin_tab:<code>mxnet</code>
<a href="https://discuss.d2l.ai/t/36">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/37">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>tensorflow</code>
<a href="https://discuss.d2l.ai/t/198">토론</a>
:end_tab:</p>
<p>:begin_tab:<code>jax</code>
<a href="https://discuss.d2l.ai/t/17971">토론</a>
:end_tab:</p>
<pre><code></code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_preliminaries/autograd.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_preliminaries/lookup-api.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_preliminaries/autograd.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_preliminaries/lookup-api.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
