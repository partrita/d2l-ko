<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>가우스 과정 추론 (Gaussian Process Inference) - Dive into Deep Learning</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../static/d2l.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../index.html">딥러닝 (Deep Learning)</a></li><li class="chapter-item expanded "><a href="../chapter_preface/index.html"><strong aria-hidden="true">1.</strong> 서문 (Preface)</a></li><li class="chapter-item expanded "><a href="../chapter_installation/index.html"><strong aria-hidden="true">2.</strong> 설치 (Installation)</a></li><li class="chapter-item expanded "><a href="../chapter_notation/index.html"><strong aria-hidden="true">3.</strong> 표기법 (Notation)</a></li><li class="chapter-item expanded "><a href="../chapter_introduction/index.html"><strong aria-hidden="true">4.</strong> 소개 (Introduction)</a></li><li class="chapter-item expanded "><a href="../chapter_preliminaries/index.html"><strong aria-hidden="true">5.</strong> 예비 지식 (Preliminaries)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_preliminaries/ndarray.html"><strong aria-hidden="true">5.1.</strong> 데이터 조작 (Data Manipulation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/pandas.html"><strong aria-hidden="true">5.2.</strong> 데이터 전처리 (Data Preprocessing)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/linear-algebra.html"><strong aria-hidden="true">5.3.</strong> 선형 대수 (Linear Algebra)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/calculus.html"><strong aria-hidden="true">5.4.</strong> 미적분 (Calculus)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/autograd.html"><strong aria-hidden="true">5.5.</strong> 자동 미분 (Automatic Differentiation)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/probability.html"><strong aria-hidden="true">5.6.</strong> 확률과 통계 (Probability and Statistics)</a></li><li class="chapter-item "><a href="../chapter_preliminaries/lookup-api.html"><strong aria-hidden="true">5.7.</strong> 문서화 (Documentation)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-regression/index.html"><strong aria-hidden="true">6.</strong> 회귀를 위한 선형 신경망 (Linear Neural Networks for Regression)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression.html"><strong aria-hidden="true">6.1.</strong> 선형 회귀 (Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/oo-design.html"><strong aria-hidden="true">6.2.</strong> 구현을 위한 객체 지향 설계 (Object-Oriented Design for Implementation)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/synthetic-regression-data.html"><strong aria-hidden="true">6.3.</strong> 합성 회귀 데이터 (Synthetic Regression Data)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-scratch.html"><strong aria-hidden="true">6.4.</strong> 밑바닥부터 시작하는 선형 회귀 구현 (Linear Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/linear-regression-concise.html"><strong aria-hidden="true">6.5.</strong> 선형 회귀의 간결한 구현 (Concise Implementation of Linear Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/generalization.html"><strong aria-hidden="true">6.6.</strong> 일반화 (Generalization)</a></li><li class="chapter-item "><a href="../chapter_linear-regression/weight-decay.html"><strong aria-hidden="true">6.7.</strong> 가중치 감쇠 (Weight Decay)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_linear-classification/index.html"><strong aria-hidden="true">7.</strong> 분류를 위한 선형 신경망 (Linear Neural Networks for Classification)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression.html"><strong aria-hidden="true">7.1.</strong> 소프트맥스 회귀 (Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/image-classification-dataset.html"><strong aria-hidden="true">7.2.</strong> 이미지 분류 데이터셋 (The Image Classification Dataset)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/classification.html"><strong aria-hidden="true">7.3.</strong> 기본 분류 모델 (The Base Classification Model)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-scratch.html"><strong aria-hidden="true">7.4.</strong> 밑바닥부터 시작하는 소프트맥스 회귀 구현 (Softmax Regression Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/softmax-regression-concise.html"><strong aria-hidden="true">7.5.</strong> 소프트맥스 회귀의 간결한 구현 (Concise Implementation of Softmax Regression)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/generalization-classification.html"><strong aria-hidden="true">7.6.</strong> 분류에서의 일반화 (Generalization in Classification)</a></li><li class="chapter-item "><a href="../chapter_linear-classification/environment-and-distribution-shift.html"><strong aria-hidden="true">7.7.</strong> 환경 및 분포 이동 (Environment and Distribution Shift)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_multilayer-perceptrons/index.html"><strong aria-hidden="true">8.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp.html"><strong aria-hidden="true">8.1.</strong> 다층 퍼셉트론 (Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/mlp-implementation.html"><strong aria-hidden="true">8.2.</strong> 다층 퍼셉트론의 구현 (Implementation of Multilayer Perceptrons)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/backprop.html"><strong aria-hidden="true">8.3.</strong> 순전파, 역전파, 그리고 계산 그래프 (Forward Propagation, Backward Propagation, and Computational Graphs)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html"><strong aria-hidden="true">8.4.</strong> 수치적 안정성과 초기화 (Numerical Stability and Initialization)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/generalization-deep.html"><strong aria-hidden="true">8.5.</strong> 딥러닝에서의 일반화 (Generalization in Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/dropout.html"><strong aria-hidden="true">8.6.</strong> 드롭아웃 (Dropout)</a></li><li class="chapter-item "><a href="../chapter_multilayer-perceptrons/kaggle-house-price.html"><strong aria-hidden="true">8.7.</strong> Kaggle에서 주택 가격 예측하기 (Predicting House Prices on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_builders-guide/index.html"><strong aria-hidden="true">9.</strong> 빌더 가이드 (Builders' Guide)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_builders-guide/model-construction.html"><strong aria-hidden="true">9.1.</strong> 레이어와 모듈 (Layers and Modules)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/parameters.html"><strong aria-hidden="true">9.2.</strong> 파라미터 관리 (Parameter Management)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/init-param.html"><strong aria-hidden="true">9.3.</strong> 파라미터 초기화 (Parameter Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/lazy-init.html"><strong aria-hidden="true">9.4.</strong> 지연 초기화 (Lazy Initialization)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/custom-layer.html"><strong aria-hidden="true">9.5.</strong> 사용자 정의 레이어 (Custom Layers)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/read-write.html"><strong aria-hidden="true">9.6.</strong> 파일 I/O (File I/O)</a></li><li class="chapter-item "><a href="../chapter_builders-guide/use-gpu.html"><strong aria-hidden="true">9.7.</strong> GPU (GPUs)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-neural-networks/index.html"><strong aria-hidden="true">10.</strong> 합성곱 신경망 (Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/why-conv.html"><strong aria-hidden="true">10.1.</strong> 완전 연결 레이어에서 합성곱으로 (From Fully Connected Layers to Convolutions)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/conv-layer.html"><strong aria-hidden="true">10.2.</strong> 이미지를 위한 합성곱 (Convolutions for Images)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/padding-and-strides.html"><strong aria-hidden="true">10.3.</strong> 패딩과 스트라이드 (Padding and Stride)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/channels.html"><strong aria-hidden="true">10.4.</strong> 다중 입력 및 다중 출력 채널 (Multiple Input and Multiple Output Channels)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/pooling.html"><strong aria-hidden="true">10.5.</strong> 풀링 (Pooling)</a></li><li class="chapter-item "><a href="../chapter_convolutional-neural-networks/lenet.html"><strong aria-hidden="true">10.6.</strong> 합성곱 신경망 (LeNet) (Convolutional Neural Networks (LeNet))</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_convolutional-modern/index.html"><strong aria-hidden="true">11.</strong> 현대 합성곱 신경망 (Modern Convolutional Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_convolutional-modern/alexnet.html"><strong aria-hidden="true">11.1.</strong> 심층 합성곱 신경망 (AlexNet) (Deep Convolutional Neural Networks (AlexNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/vgg.html"><strong aria-hidden="true">11.2.</strong> 블록을 사용하는 네트워크 (VGG) (Networks Using Blocks (VGG))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/nin.html"><strong aria-hidden="true">11.3.</strong> 네트워크 속의 네트워크 (NiN) (Network in Network (NiN))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/googlenet.html"><strong aria-hidden="true">11.4.</strong> 다중 분기 네트워크 (GoogLeNet) (Multi-Branch Networks (GoogLeNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/batch-norm.html"><strong aria-hidden="true">11.5.</strong> 배치 정규화 (Batch Normalization)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/resnet.html"><strong aria-hidden="true">11.6.</strong> 잔차 네트워크 (ResNet)와 ResNeXt (Residual Networks (ResNet) and ResNeXt)</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/densenet.html"><strong aria-hidden="true">11.7.</strong> 밀집 연결 네트워크 (DenseNet) (Densely Connected Networks (DenseNet))</a></li><li class="chapter-item "><a href="../chapter_convolutional-modern/cnn-design.html"><strong aria-hidden="true">11.8.</strong> 합성곱 네트워크 아키텍처 설계 (Designing Convolution Network Architectures)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-neural-networks/index.html"><strong aria-hidden="true">12.</strong> 순환 신경망 (Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/sequence.html"><strong aria-hidden="true">12.1.</strong> 시퀀스 다루기 (Working with Sequences)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/text-sequence.html"><strong aria-hidden="true">12.2.</strong> 원시 텍스트를 시퀀스 데이터로 변환하기 (Converting Raw Text into Sequence Data)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/language-model.html"><strong aria-hidden="true">12.3.</strong> 언어 모델 (Language Models)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn.html"><strong aria-hidden="true">12.4.</strong> 순환 신경망 (Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-scratch.html"><strong aria-hidden="true">12.5.</strong> 밑바닥부터 시작하는 순환 신경망 구현 (Recurrent Neural Network Implementation from Scratch)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/rnn-concise.html"><strong aria-hidden="true">12.6.</strong> 순환 신경망의 간결한 구현 (Concise Implementation of Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-neural-networks/bptt.html"><strong aria-hidden="true">12.7.</strong> BPTT (Backpropagation Through Time)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recurrent-modern/index.html"><strong aria-hidden="true">13.</strong> 현대 순환 신경망 (Modern Recurrent Neural Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recurrent-modern/lstm.html"><strong aria-hidden="true">13.1.</strong> 장단기 메모리 (LSTM) (Long Short-Term Memory (LSTM))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/gru.html"><strong aria-hidden="true">13.2.</strong> 게이트 순환 유닛 (GRU) (Gated Recurrent Units (GRU))</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/deep-rnn.html"><strong aria-hidden="true">13.3.</strong> 심층 순환 신경망 (Deep Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/bi-rnn.html"><strong aria-hidden="true">13.4.</strong> 양방향 순환 신경망 (Bidirectional Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/machine-translation-and-dataset.html"><strong aria-hidden="true">13.5.</strong> 기계 번역과 데이터셋 (Machine Translation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/encoder-decoder.html"><strong aria-hidden="true">13.6.</strong> 인코더-디코더 아키텍처 (The Encoder--Decoder Architecture)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/seq2seq.html"><strong aria-hidden="true">13.7.</strong> 기계 번역을 위한 시퀀스-투-시퀀스 학습 (Sequence-to-Sequence Learning for Machine Translation)</a></li><li class="chapter-item "><a href="../chapter_recurrent-modern/beam-search.html"><strong aria-hidden="true">13.8.</strong> 빔 검색 (Beam Search)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_attention-mechanisms-and-transformers/index.html"><strong aria-hidden="true">14.</strong> 어텐션 메커니즘과 트랜스포머 (Attention Mechanisms and Transformers)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html"><strong aria-hidden="true">14.1.</strong> 쿼리, 키, 그리고 값 (Queries, Keys, and Values)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html"><strong aria-hidden="true">14.2.</strong> 유사도에 의한 어텐션 풀링 (Attention Pooling by Similarity)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html"><strong aria-hidden="true">14.3.</strong> 어텐션 점수 함수 (Attention Scoring Functions)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html"><strong aria-hidden="true">14.4.</strong> Bahdanau 어텐션 메커니즘 (The Bahdanau Attention Mechanism)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html"><strong aria-hidden="true">14.5.</strong> 다중 헤드 어텐션 (Multi-Head Attention)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html"><strong aria-hidden="true">14.6.</strong> 자기 어텐션과 위치 인코딩 (Self-Attention and Positional Encoding)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/transformer.html"><strong aria-hidden="true">14.7.</strong> 트랜스포머 아키텍처 (The Transformer Architecture)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html"><strong aria-hidden="true">14.8.</strong> 비전을 위한 트랜스포머 (Transformers for Vision)</a></li><li class="chapter-item "><a href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html"><strong aria-hidden="true">14.9.</strong> 트랜스포머를 이용한 대규모 사전 훈련 (Large-Scale Pretraining with Transformers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_optimization/index.html"><strong aria-hidden="true">15.</strong> 최적화 알고리즘 (Optimization Algorithms)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_optimization/optimization-intro.html"><strong aria-hidden="true">15.1.</strong> 최적화와 딥러닝 (Optimization and Deep Learning)</a></li><li class="chapter-item "><a href="../chapter_optimization/convexity.html"><strong aria-hidden="true">15.2.</strong> 볼록성 (Convexity)</a></li><li class="chapter-item "><a href="../chapter_optimization/gd.html"><strong aria-hidden="true">15.3.</strong> 경사 하강법 (Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/sgd.html"><strong aria-hidden="true">15.4.</strong> 확률적 경사 하강법 (Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/minibatch-sgd.html"><strong aria-hidden="true">15.5.</strong> 미니배치 확률적 경사 하강법 (Minibatch Stochastic Gradient Descent)</a></li><li class="chapter-item "><a href="../chapter_optimization/momentum.html"><strong aria-hidden="true">15.6.</strong> 모멘텀 (Momentum)</a></li><li class="chapter-item "><a href="../chapter_optimization/adagrad.html"><strong aria-hidden="true">15.7.</strong> Adagrad</a></li><li class="chapter-item "><a href="../chapter_optimization/rmsprop.html"><strong aria-hidden="true">15.8.</strong> RMSProp</a></li><li class="chapter-item "><a href="../chapter_optimization/adadelta.html"><strong aria-hidden="true">15.9.</strong> Adadelta</a></li><li class="chapter-item "><a href="../chapter_optimization/adam.html"><strong aria-hidden="true">15.10.</strong> Adam</a></li><li class="chapter-item "><a href="../chapter_optimization/lr-scheduler.html"><strong aria-hidden="true">15.11.</strong> 학습률 스케줄링 (Learning Rate Scheduling)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computational-performance/index.html"><strong aria-hidden="true">16.</strong> 계산 성능 (Computational Performance)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computational-performance/hybridize.html"><strong aria-hidden="true">16.1.</strong> 컴파일러와 인터프리터 (Compilers and Interpreters)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/async-computation.html"><strong aria-hidden="true">16.2.</strong> 비동기 계산 (Asynchronous Computation)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/auto-parallelism.html"><strong aria-hidden="true">16.3.</strong> 자동 병렬화 (Automatic Parallelism)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/hardware.html"><strong aria-hidden="true">16.4.</strong> 하드웨어 (Hardware)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus.html"><strong aria-hidden="true">16.5.</strong> 다중 GPU에서의 훈련 (Training on Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/multiple-gpus-concise.html"><strong aria-hidden="true">16.6.</strong> 다중 GPU를 위한 간결한 구현 (Concise Implementation for Multiple GPUs)</a></li><li class="chapter-item "><a href="../chapter_computational-performance/parameterserver.html"><strong aria-hidden="true">16.7.</strong> 파라미터 서버 (Parameter Servers)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_computer-vision/index.html"><strong aria-hidden="true">17.</strong> 컴퓨터 비전 (Computer Vision)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_computer-vision/image-augmentation.html"><strong aria-hidden="true">17.1.</strong> 이미지 증강 (Image Augmentation)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fine-tuning.html"><strong aria-hidden="true">17.2.</strong> 미세 조정 (Fine-Tuning)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/bounding-box.html"><strong aria-hidden="true">17.3.</strong> 객체 탐지와 바운딩 박스 (Object Detection and Bounding Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/anchor.html"><strong aria-hidden="true">17.4.</strong> 앵커 박스 (Anchor Boxes)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/multiscale-object-detection.html"><strong aria-hidden="true">17.5.</strong> 멀티스케일 객체 탐지 (Multiscale Object Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/object-detection-dataset.html"><strong aria-hidden="true">17.6.</strong> 객체 탐지 데이터셋 (The Object Detection Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/ssd.html"><strong aria-hidden="true">17.7.</strong> 싱글 샷 멀티박스 탐지 (SSD) (Single Shot Multibox Detection)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/rcnn.html"><strong aria-hidden="true">17.8.</strong> 영역 기반 CNN (R-CNNs) (Region-based CNNs (R-CNNs))</a></li><li class="chapter-item "><a href="../chapter_computer-vision/semantic-segmentation-and-dataset.html"><strong aria-hidden="true">17.9.</strong> 시맨틱 세그멘테이션과 데이터셋 (Semantic Segmentation and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/transposed-conv.html"><strong aria-hidden="true">17.10.</strong> 전치 합성곱 (Transposed Convolution)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/fcn.html"><strong aria-hidden="true">17.11.</strong> 완전 합성곱 네트워크 (Fully Convolutional Networks)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/neural-style.html"><strong aria-hidden="true">17.12.</strong> 신경 스타일 전송 (Neural Style Transfer)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-cifar10.html"><strong aria-hidden="true">17.13.</strong> Kaggle에서의 이미지 분류 (CIFAR-10) (Image Classification (CIFAR-10) on Kaggle)</a></li><li class="chapter-item "><a href="../chapter_computer-vision/kaggle-dog.html"><strong aria-hidden="true">17.14.</strong> Kaggle에서의 견종 식별 (ImageNet Dogs) (Dog Breed Identification (ImageNet Dogs) on Kaggle)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-pretraining/index.html"><strong aria-hidden="true">18.</strong> 자연어 처리: 사전 훈련 (Natural Language Processing: Pretraining)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec.html"><strong aria-hidden="true">18.1.</strong> 단어 임베딩 (word2vec) (Word Embedding (word2vec))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/approx-training.html"><strong aria-hidden="true">18.2.</strong> 근사 훈련 (Approximate Training)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html"><strong aria-hidden="true">18.3.</strong> 단어 임베딩 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining Word Embeddings)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html"><strong aria-hidden="true">18.4.</strong> word2vec 사전 훈련 (Pretraining word2vec)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/glove.html"><strong aria-hidden="true">18.5.</strong> GloVe를 이용한 단어 임베딩 (Word Embedding with Global Vectors (GloVe))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/subword-embedding.html"><strong aria-hidden="true">18.6.</strong> 서브워드 임베딩 (Subword Embedding)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/similarity-analogy.html"><strong aria-hidden="true">18.7.</strong> 단어 유사도와 유추 (Word Similarity and Analogy)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert.html"><strong aria-hidden="true">18.8.</strong> 트랜스포머의 양방향 인코더 표현 (BERT) (Bidirectional Encoder Representations from Transformers (BERT))</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-dataset.html"><strong aria-hidden="true">18.9.</strong> BERT 사전 훈련을 위한 데이터셋 (The Dataset for Pretraining BERT)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-pretraining/bert-pretraining.html"><strong aria-hidden="true">18.10.</strong> BERT 사전 훈련 (Pretraining BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_natural-language-processing-applications/index.html"><strong aria-hidden="true">19.</strong> 자연어 처리: 응용 (Natural Language Processing: Applications)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html"><strong aria-hidden="true">19.1.</strong> 감성 분석과 데이터셋 (Sentiment Analysis and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html"><strong aria-hidden="true">19.2.</strong> 감성 분석: 순환 신경망 사용 (Sentiment Analysis: Using Recurrent Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html"><strong aria-hidden="true">19.3.</strong> 감성 분석: 합성곱 신경망 사용 (Sentiment Analysis: Using Convolutional Neural Networks)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html"><strong aria-hidden="true">19.4.</strong> 자연어 추론과 데이터셋 (Natural Language Inference and the Dataset)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html"><strong aria-hidden="true">19.5.</strong> 자연어 추론: 어텐션 사용 (Natural Language Inference: Using Attention)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/finetuning-bert.html"><strong aria-hidden="true">19.6.</strong> 시퀀스 레벨 및 토큰 레벨 응용을 위한 BERT 미세 조정 (Fine-Tuning BERT for Sequence-Level and Token-Level Applications)</a></li><li class="chapter-item "><a href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html"><strong aria-hidden="true">19.7.</strong> 자연어 추론: BERT 미세 조정 (Natural Language Inference: Fine-Tuning BERT)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_reinforcement-learning/index.html"><strong aria-hidden="true">20.</strong> 강화 학습 (Reinforcement Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_reinforcement-learning/mdp.html"><strong aria-hidden="true">20.1.</strong> 마르코프 결정 과정 (MDP) (Markov Decision Process (MDP))</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/value-iter.html"><strong aria-hidden="true">20.2.</strong> 가치 반복 (Value Iteration)</a></li><li class="chapter-item "><a href="../chapter_reinforcement-learning/qlearning.html"><strong aria-hidden="true">20.3.</strong> Q-러닝 (Q-Learning)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/index.html"><strong aria-hidden="true">21.</strong> 가우스 과정 (Gaussian Processes)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-intro.html"><strong aria-hidden="true">21.1.</strong> 가우스 과정 소개 (Introduction to Gaussian Processes)</a></li><li class="chapter-item "><a href="../chapter_gaussian-processes/gp-priors.html"><strong aria-hidden="true">21.2.</strong> 가우스 과정 사전 분포 (Gaussian Process Priors)</a></li><li class="chapter-item expanded "><a href="../chapter_gaussian-processes/gp-inference.html" class="active"><strong aria-hidden="true">21.3.</strong> 가우스 과정 추론 (Gaussian Process Inference)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_hyperparameter-optimization/index.html"><strong aria-hidden="true">22.</strong> 하이퍼파라미터 최적화 (Hyperparameter Optimization)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-intro.html"><strong aria-hidden="true">22.1.</strong> 하이퍼파라미터 최적화란 무엇인가? (What Is Hyperparameter Optimization?)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/hyperopt-api.html"><strong aria-hidden="true">22.2.</strong> 하이퍼파라미터 최적화 API (Hyperparameter Optimization API)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/rs-async.html"><strong aria-hidden="true">22.3.</strong> 비동기 무작위 검색 (Asynchronous Random Search)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-intro.html"><strong aria-hidden="true">22.4.</strong> 다중 충실도 하이퍼파라미터 최적화 (Multi-Fidelity Hyperparameter Optimization)</a></li><li class="chapter-item "><a href="../chapter_hyperparameter-optimization/sh-async.html"><strong aria-hidden="true">22.5.</strong> 비동기 연속 반감법 (Asynchronous Successive Halving)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_generative-adversarial-networks/index.html"><strong aria-hidden="true">23.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/gan.html"><strong aria-hidden="true">23.1.</strong> 생성적 적대 신경망 (Generative Adversarial Networks)</a></li><li class="chapter-item "><a href="../chapter_generative-adversarial-networks/dcgan.html"><strong aria-hidden="true">23.2.</strong> 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_recommender-systems/index.html"><strong aria-hidden="true">24.</strong> 추천 시스템 (Recommender Systems)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_recommender-systems/recsys-intro.html"><strong aria-hidden="true">24.1.</strong> 추천 시스템 개요 (Overview of Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/movielens.html"><strong aria-hidden="true">24.2.</strong> MovieLens 데이터셋 (The MovieLens Dataset)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/mf.html"><strong aria-hidden="true">24.3.</strong> 행렬 분해 (Matrix Factorization)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/autorec.html"><strong aria-hidden="true">24.4.</strong> AutoRec: 오토인코더를 이용한 평점 예측 (AutoRec: Rating Prediction with Autoencoders)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ranking.html"><strong aria-hidden="true">24.5.</strong> 추천 시스템을 위한 개인화된 순위 지정 (Personalized Ranking for Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/neumf.html"><strong aria-hidden="true">24.6.</strong> 개인화된 순위 지정을 위한 신경 협업 필터링 (Neural Collaborative Filtering for Personalized Ranking)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/seqrec.html"><strong aria-hidden="true">24.7.</strong> 시퀀스 인식 추천 시스템 (Sequence-Aware Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/ctr.html"><strong aria-hidden="true">24.8.</strong> 풍부한 특성 추천 시스템 (Feature-Rich Recommender Systems)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/fm.html"><strong aria-hidden="true">24.9.</strong> 인수 분해 머신 (Factorization Machines)</a></li><li class="chapter-item "><a href="../chapter_recommender-systems/deepfm.html"><strong aria-hidden="true">24.10.</strong> 심층 인수 분해 머신 (Deep Factorization Machines)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-mathematics-for-deep-learning/index.html"><strong aria-hidden="true">25.</strong> 부록: 딥러닝을 위한 수학 (Appendix: Mathematics for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html"><strong aria-hidden="true">25.1.</strong> 기하학 및 선형 대수 연산 (Geometry and Linear Algebraic Operations)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html"><strong aria-hidden="true">25.2.</strong> 고유 분해 (Eigendecompositions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html"><strong aria-hidden="true">25.3.</strong> 단일 변수 미적분 (Single Variable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html"><strong aria-hidden="true">25.4.</strong> 다변수 미적분 (Multivariable Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html"><strong aria-hidden="true">25.5.</strong> 적분 (Integral Calculus)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html"><strong aria-hidden="true">25.6.</strong> 확률 변수 (Random Variables)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html"><strong aria-hidden="true">25.7.</strong> 최대 우도 (Maximum Likelihood)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/distributions.html"><strong aria-hidden="true">25.8.</strong> 분포 (Distributions)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html"><strong aria-hidden="true">25.9.</strong> 나이브 베이즈 (Naive Bayes)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/statistics.html"><strong aria-hidden="true">25.10.</strong> 통계 (Statistics)</a></li><li class="chapter-item "><a href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html"><strong aria-hidden="true">25.11.</strong> 정보 이론 (Information Theory)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_appendix-tools-for-deep-learning/index.html"><strong aria-hidden="true">26.</strong> 부록: 딥러닝을 위한 도구 (Appendix: Tools for Deep Learning)</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/jupyter.html"><strong aria-hidden="true">26.1.</strong> 주피터 노트북 사용하기 (Using Jupyter Notebooks)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/sagemaker.html"><strong aria-hidden="true">26.2.</strong> Amazon SageMaker 사용하기 (Using Amazon SageMaker)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/aws.html"><strong aria-hidden="true">26.3.</strong> AWS EC2 인스턴스 사용하기 (Using AWS EC2 Instances)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/colab.html"><strong aria-hidden="true">26.4.</strong> Google Colab 사용하기 (Using Google Colab)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html"><strong aria-hidden="true">26.5.</strong> 서버 및 GPU 선택하기 (Selecting Servers and GPUs)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/contributing.html"><strong aria-hidden="true">26.6.</strong> 이 책에 기여하기 (Contributing to This Book)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/utils.html"><strong aria-hidden="true">26.7.</strong> 유틸리티 함수 및 클래스 (Utility Functions and Classes)</a></li><li class="chapter-item "><a href="../chapter_appendix-tools-for-deep-learning/d2l.html"><strong aria-hidden="true">26.8.</strong> d2l API 문서 (The d2l API Document)</a></li></ol></li><li class="chapter-item expanded "><a href="../chapter_references/zreferences.html"><strong aria-hidden="true">27.</strong> 참고 문헌 (chapter_references/zreferences.md)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Dive into Deep Learning</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/d2l-ai/d2l-en" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <pre><code class="language-{.python .input}">%load_ext d2lbook.tab
tab.interact_select(["pytorch"])
#required_libs("gpytorch")
</code></pre>
<h1 id="가우시안-프로세스-추론-gaussian-process-inference"><a class="header" href="#가우시안-프로세스-추론-gaussian-process-inference">가우시안 프로세스 추론 (Gaussian Process Inference)</a></h1>
<p>이 섹션에서는 이전 섹션에서 소개한 GP 사전 분포를 사용하여 사후 추론을 수행하고 예측하는 방법을 보여줄 것입니다. 우리는 *닫힌 형식(closed form)*으로 추론을 수행할 수 있는 회귀로 시작할 것입니다. 이것은 가우시안 프로세스를 실제로 빠르게 시작하고 실행하기 위한 "요약된 GP" 섹션입니다. 처음부터 모든 기본 연산을 코딩한 다음, 최신 가우시안 프로세스 작업과 심층 신경망과의 통합을 훨씬 더 편리하게 만들어 줄 <a href="https://gpytorch.ai/">GPyTorch</a>를 소개할 것입니다. 우리는 다음 섹션에서 이러한 고급 주제를 깊이 있게 고려할 것입니다. 해당 섹션에서는 분류, 포인트 프로세스 또는 비가우시안 우도와 같이 근사 추론이 필요한 설정도 고려할 것입니다.</p>
<h2 id="회귀에-대한-사후-추론-posterior-inference-for-regression"><a class="header" href="#회귀에-대한-사후-추론-posterior-inference-for-regression">회귀에 대한 사후 추론 (Posterior Inference for Regression)</a></h2>
<p><em>관찰(observation)</em> 모델은 우리가 학습하려는 함수 $f(x)$를 관찰 $y(x)$와 관련시키며, 둘 다 일부 입력 $x$에 의해 인덱싱됩니다. 분류에서 $x$는 이미지의 픽셀이 될 수 있고 $y$는 관련 클래스 레이블이 될 수 있습니다. 회귀에서 $y$는 일반적으로 지표면 온도, 해수면, $CO_2$ 농도 등과 같은 연속적인 출력을 나타냅니다.</p>
<p>회귀에서는 종종 출력이 잠재적인 노이즈 없는 함수 $f(x)$에 i.i.d. 가우시안 노이즈 $\epsilon(x)$를 더한 것으로 가정합니다.</p>
<p>$$y(x) = f(x) + \epsilon(x),$$
:eqlabel:<code>eq_gp-regression</code></p>
<p>여기서 $\epsilon(x) \sim \mathcal{N}(0,\sigma^2)$입니다. $\mathbf{y} = y(X) = (y(x_1),\dots,y(x_n))^{\top}$를 훈련 관찰 벡터라고 하고, $\textbf{f} = (f(x_1),\dots,f(x_n))^{\top}$를 훈련 입력 $X = {x_1, \dots, x_n}$에서 쿼리된 잠재 노이즈 없는 함수 값의 벡터라고 합시다.</p>
<p>우리는 $f(x) \sim \mathcal{GP}(m,k)$라고 가정할 것입니다. 이는 함수 값 $\textbf{f}$의 모음이 평균 벡터 $\mu_i = m(x_i)$와 공분산 행렬 $K_{ij} = k(x_i,x_j)$를 갖는 결합 다변량 가우시안 분포를 갖는다는 것을 의미합니다. RBF 커널 $k(x_i,x_j) = a^2 \exp\left(-\frac{1}{2\ell^2}||x_i-x_j||^2\right)$는 공분산 함수의 표준 선택이 될 것입니다. 표기법의 단순성을 위해 평균 함수 $m(x)=0$이라고 가정하겠습니다. 우리의 유도는 나중에 쉽게 일반화될 수 있습니다.</p>
<p>입력 세트 $$X_* = x_{<em>1},x_{<em>2},\dots,x_{<em>m}$$에서 예측을 하고 싶다고 가정해 봅시다. 그런 다음 $p(\mathbf{f}_</em> | \mathbf{y}, X)$를 찾고 싶습니다. 회귀 설정에서는 $\mathbf{f}_</em> = f(X_</em>)$와 $\mathbf{y}$에 대한 결합 분포를 찾은 후 가우시안 항등식을 사용하여 이 분포를 편리하게 찾을 수 있습니다.</p>
<p>훈련 입력 $X$에서 방정식 :eqref:<code>eq_gp-regression</code>을 평가하면 $\mathbf{y} = \mathbf{f} + \mathbf{\epsilon}$이 됩니다. 가우시안 프로세스의 정의(지난 섹션 참조)에 의해 $\mathbf{f} \sim \mathcal{N}(0,K(X,X))$이며, 여기서 $K(X,X)$는 가능한 모든 입력 쌍 $x_i, x_j \in X$에서 공분산 함수(일명 <em>커널</em>)를 평가하여 형성된 $n \times n$ 행렬입니다. $\mathbf{\epsilon}$은 단순히 $\mathcal{N}(0,\sigma^2)$의 iid 샘플로 구성된 벡터이므로 분포 $\mathcal{N}(0,\sigma^2I)$를 갖습니다. 따라서 $\mathbf{y}$는 두 개의 독립적인 다변량 가우시안 변수의 합이므로 분포 $\mathcal{N}(0, K(X,X) + \sigma^2I)$를 갖습니다. 또한 $\textrm{cov}(\mathbf{f}<em>*, \mathbf{y}) = \textrm{cov}(\mathbf{y},\mathbf{f}</em><em>)^{\top} = K(X_</em>,X)$임을 보일 수 있습니다. 여기서 $K(X_*,X)$는 테스트 및 훈련 입력의 모든 쌍에서 커널을 평가하여 형성된 $m \times n$ 행렬입니다.</p>
<p>$$
\begin{bmatrix}
\mathbf{y} \
\mathbf{f}_*
\end{bmatrix}</p>
<p>\sim</p>
<p>\mathcal{N}</p>
<p>\left(0,</p>
<p>\mathbf{A} = \begin{bmatrix}
K(X,X)+\sigma^2I &amp; K(X,X_<em>)
\K(X_</em>,X) &amp; K(X_<em>,X_</em>)
\end{bmatrix}</p>
<p>\right)
$$</p>
<p>그런 다음 표준 가우시안 항등식을 사용하여 결합 분포에서 조건부 분포를 찾을 수 있습니다(예: Bishop Chapter 2 참조).
$\mathbf{f}<em>* | \mathbf{y}, X, X</em>* \sim \mathcal{N}(m_<em>,S_</em>)$, 여기서 $m_* = K(X_<em>,X)[K(X,X)+\sigma^2I]^{-1}\textbf{y}$이고 $S = K(X_</em>,X_<em>) - K(X_</em>,X)[K(X,X)+\sigma^2I]^{-1}K(X,X_*)$입니다.</p>
<p>일반적으로 우리는 전체 예측 공분산 행렬 $S$를 사용할 필요가 없으며, 대신 각 예측에 대한 불확실성으로 $S$의 대각선을 사용합니다. 종종 이러한 이유로 테스트 포인트 모음이 아닌 단일 테스트 포인트 $x_*$에 대한 예측 분포를 씁니다.</p>
<p>커널 행렬에는 위의 RBF 커널의 진폭 $a$와 길이 척도 $\ell$과 같이 추정하고자 하는 파라미터 $\theta$가 있습니다. 이러한 목적으로 우리는 <em>주변 우도(marginal likelihood)</em> $p(\textbf{y} | \theta, X)$를 사용합니다. 이는 $\textbf{y},\textbf{f}_*$에 대한 결합 분포를 찾기 위해 주변 분포를 계산할 때 이미 유도했습니다. 보게 되겠지만, 주변 우도는 모델 적합성 및 모델 복잡성 항으로 구분되며 하이퍼파라미터 학습을 위한 오컴의 면도날 개념을 자동으로 인코딩합니다. 자세한 논의는 MacKay Ch. 28 :cite:<code>mackay2003information</code> 및 Rasmussen and Williams Ch. 5 :cite:<code>rasmussen2006gaussian</code>를 참조하십시오.</p>
<pre><code class="language-{.python .input}">from d2l import torch as d2l
import numpy as np
from scipy.spatial import distance_matrix
from scipy import optimize
import matplotlib.pyplot as plt
import math
import torch
import gpytorch
import os

d2l.set_figsize()
</code></pre>
<h2 id="gp-회귀에서-예측-및-커널-하이퍼파라미터-학습을-위한-방정식-equations-for-making-predictions-and-learning-kernel-hyperparameters-in-gp-regression"><a class="header" href="#gp-회귀에서-예측-및-커널-하이퍼파라미터-학습을-위한-방정식-equations-for-making-predictions-and-learning-kernel-hyperparameters-in-gp-regression">GP 회귀에서 예측 및 커널 하이퍼파라미터 학습을 위한 방정식 (Equations for Making Predictions and Learning Kernel Hyperparameters in GP Regression)</a></h2>
<p>여기서는 가우시안 프로세스 회귀에서 하이퍼파라미터를 학습하고 예측하는 데 사용할 방정식을 나열합니다. 다시 말하지만, 입력 $X = {x_1,\dots,x_n}$으로 인덱싱된 회귀 타겟 벡터 $\textbf{y}$를 가정하고 테스트 입력 $x_<em>$에서 예측을 하려고 합니다. 분산 $\sigma^2$를 갖는 i.i.d. 가법적 0 평균 가우시안 노이즈를 가정합니다. 우리는 잠재 노이즈 없는 함수에 대해 평균 함수 $m$과 커널 함수 $k$를 갖는 가우시안 프로세스 사전 분포 $f(x) \sim \mathcal{GP}(m,k)$를 사용합니다. 커널 자체에는 학습하려는 파라미터 $\theta$가 있습니다. 예를 들어 RBF 커널 $k(x_i,x_j) = a^2\exp\left(-\frac{1}{2\ell^2}||x-x'||^2\right)$를 사용하는 경우 $\theta = {a^2, \ell^2}$를 학습하려고 합니다. $K(X,X)$를 $n$개의 훈련 입력의 가능한 모든 쌍에 대해 커널을 평가하는 것에 해당하는 $n \times n$ 행렬이라고 합시다. $K(x_</em>,X)$를 $i=1,\dots,n$에 대해 $k(x_*, x_i)$를 평가하여 형성된 $1 \times n$ 벡터라고 합시다. $\mu$를 모든 훈련 포인트 $x$에서 평균 함수 $m(x)$를 평가하여 형성된 평균 벡터라고 합시다.</p>
<p>일반적으로 가우시안 프로세스 작업에서는 두 단계 절차를 따릅니다.</p>
<ol>
<li>이러한 하이퍼파라미터에 대한 주변 우도를 최대화하여 커널 하이퍼파라미터 $\hat{\theta}$를 학습합니다.</li>
<li>예측 평균을 점 예측기로 사용하고 예측 표준 편차의 2배를 사용하여 이러한 학습된 하이퍼파라미터 $\hat{\theta}$에 대한 95% 신용 집합을 형성합니다.</li>
</ol>
<p>로그 주변 우도는 단순히 로그 가우시안 밀도이며 다음과 같은 형식을 갖습니다.
$$\log p(\textbf{y} | \theta, X) = -\frac{1}{2}\textbf{y}^{\top}[K_{\theta}(X,X) + \sigma^2I]^{-1}\textbf{y} - \frac{1}{2}\log|K_{\theta}(X,X)| + c$$</p>
<p>예측 분포는 다음과 같은 형식을 갖습니다.
$$p(y_* | x_<em>, \textbf{y}, \theta) = \mathcal{N}(a_</em>,v_<em>)$$
$$a_</em> = k_{\theta}(x_<em>,X)[K_{\theta}(X,X)+\sigma^2I]^{-1}(\textbf{y}-\mu) + \mu$$
$$v_</em> = k_{\theta}(x_<em>,x_</em>) - K_{\theta}(x_<em>,X)[K_{\theta}(X,X)+\sigma^2I]^{-1}k_{\theta}(X,x_</em>)$$</p>
<h2 id="학습-및-예측을-위한-방정식-해석-interpreting-equations-for-learning-and-predictions"><a class="header" href="#학습-및-예측을-위한-방정식-해석-interpreting-equations-for-learning-and-predictions">학습 및 예측을 위한 방정식 해석 (Interpreting Equations for Learning and Predictions)</a></h2>
<p>가우시안 프로세스에 대한 예측 분포에 대해 주목해야 할 몇 가지 요점이 있습니다.</p>
<ul>
<li>
<p>모델 클래스의 유연성에도 불구하고 GP 회귀에 대해 <em>닫힌 형식</em>으로 <em>정확한</em> 베이지안 추론을 수행할 수 있습니다. 커널 하이퍼파라미터를 학습하는 것 외에는 <em>훈련</em>이 없습니다. 예측을 위해 사용하려는 방정식을 정확히 적을 수 있습니다. 가우시안 프로세스는 이러한 측면에서 비교적 예외적이며, 이는 편리함, 다재다능함 및 지속적인 인기에 크게 기여했습니다.</p>
</li>
<li>
<p>예측 평균 $a_<em>$는 훈련 타겟 $\textbf{y}$의 선형 결합이며, 커널 $k_{\theta}(x_</em>,X)[K_{\theta}(X,X)+\sigma^2I]^{-1}$에 의해 가중치가 부여됩니다. 보게 되겠지만 커널(및 그 하이퍼파라미터)은 따라서 모델의 일반화 속성에서 중요한 역할을 합니다.</p>
</li>
<li>
<p>예측 평균은 타겟 값 $\textbf{y}$에 명시적으로 의존하지만 예측 분산은 그렇지 않습니다. 대신 예측 불확실성은 커널 함수에 의해 제어되는 대로 테스트 입력 $x_*$가 타겟 위치 $X$에서 멀어짐에 따라 증가합니다. 그러나 불확실성은 데이터에서 학습된 커널 하이퍼파라미터 $\theta$를 통해 타겟 $\textbf{y}$의 값에 암시적으로 의존합니다.</p>
</li>
<li>
<p>주변 우도는 모델 적합성 및 모델 복잡성(로그 행렬식) 항으로 구분됩니다. 주변 우도는 데이터와 여전히 일치하는 가장 단순한 피팅을 제공하는 하이퍼파라미터를 선택하는 경향이 있습니다.</p>
</li>
<li>
<p>주요 계산 병목 현상은 선형 시스템을 해결하고 $n$개의 훈련 포인트에 대해 $n \times n$ 대칭 양의 정부호 행렬 $K(X,X)$에 대한 로그 행렬식을 계산하는 데서 발생합니다. 순진하게 이러한 연산은 각각 $\mathcal{O}(n^3)$ 계산과 커널(공분산) 행렬의 각 항목에 대한 $\mathcal{O}(n^2)$ 저장소를 초래하며, 종종 촐레스키 분해로 시작합니다. 역사적으로 이러한 병목 현상은 GP를 약 10,000개 미만의 훈련 포인트가 있는 문제로 제한했으며 거의 10년 동안 부정확했던 "느리다"는 평판을 GP에 주었습니다. 고급 주제에서는 수백만 개의 포인트가 있는 문제로 GP를 확장하는 방법에 대해 논의할 것입니다.</p>
</li>
<li>
<p>널리 사용되는 커널 함수 선택의 경우, $K(X,X)$는 종종 특이(singular)에 가까워 촐레스키 분해 또는 선형 시스템을 해결하기 위한 기타 연산을 수행할 때 수치적 문제를 일으킬 수 있습니다. 다행히도 회귀에서는 종종 $K_{\theta}(X,X)+\sigma^2I$로 작업하므로 노이즈 분산 $\sigma^2$이 $K(X,X)$의 대각선에 추가되어 조건이 크게 개선됩니다. 노이즈 분산이 작거나 노이즈 없는 회귀를 수행하는 경우 조건을 개선하기 위해 대각선에 $10^{-6}$ 정도의 소량의 "지터(jitter)"를 추가하는 것이 일반적입니다.</p>
</li>
</ul>
<h2 id="처음부터-작업한-예제-worked-example-from-scratch"><a class="header" href="#처음부터-작업한-예제-worked-example-from-scratch">처음부터 작업한 예제 (Worked Example from Scratch)</a></h2>
<p>회귀 데이터를 생성한 다음, 처음부터 모든 단계를 구현하여 GP로 데이터를 피팅해 봅시다.
$\epsilon \sim \mathcal{N}(0,\sigma^2)$인 $$y(x) = \sin(x) + \frac{1}{2}\sin(4x) + \epsilon$$에서 데이터를 샘플링할 것입니다. 우리가 찾고자 하는 노이즈 없는 함수는 $f(x) = \sin(x) + \frac{1}{2}\sin(4x)$입니다. 노이즈 표준 편차 $\sigma = 0.25$를 사용하여 시작하겠습니다.</p>
<pre><code class="language-{.python .input}">def data_maker1(x, sig):
    return np.sin(x) + 0.5 * np.sin(4 * x) + np.random.randn(x.shape[0]) * sig

sig = 0.25
train_x, test_x = np.linspace(0, 5, 50), np.linspace(0, 5, 500)
train_y, test_y = data_maker1(train_x, sig=sig), data_maker1(test_x, sig=0.)

d2l.plt.scatter(train_x, train_y)
d2l.plt.plot(test_x, test_y)
d2l.plt.xlabel("x", fontsize=20)
d2l.plt.ylabel("Observations y", fontsize=20)
d2l.plt.show()
</code></pre>
<p>여기서 우리는 원으로 표시된 노이즈가 있는 관찰과 파란색으로 표시된 우리가 찾고자 하는 노이즈 없는 함수를 봅니다.</p>
<p>이제 잠재 노이즈 없는 함수에 대한 GP 사전 분포 $f(x)\sim \mathcal{GP}(m,k)$를 지정해 봅시다. 평균 함수 $m(x) = 0$과 RBF 공분산 함수(커널)를 사용할 것입니다.
$$k(x_i,x_j) = a^2\exp\left(-\frac{1}{2\ell^2}||x-x'||^2\right).$$</p>
<pre><code class="language-{.python .input}">mean = np.zeros(test_x.shape[0])
cov = d2l.rbfkernel(test_x, test_x, ls=0.2)
</code></pre>
<p>우리는 길이 척도 0.2로 시작했습니다. 데이터를 피팅하기 전에 합리적인 사전 분포를 지정했는지 고려하는 것이 중요합니다. 이 사전 분포의 샘플 함수 몇 가지와 95% 신용 집합(실제 함수가 이 영역 내에 있을 확률이 95%라고 믿습니다)을 시각화해 봅시다.</p>
<pre><code class="language-{.python .input}">prior_samples = np.random.multivariate_normal(mean=mean, cov=cov, size=5)
d2l.plt.plot(test_x, prior_samples.T, color='black', alpha=0.5)
d2l.plt.plot(test_x, mean, linewidth=2.)
d2l.plt.fill_between(test_x, mean - 2 * np.diag(cov), mean + 2 * np.diag(cov), 
                 alpha=0.25)
d2l.plt.show()
</code></pre>
<p>이 샘플들이 합리적으로 보입니까? 함수의 고수준 속성이 우리가 모델링하려는 데이터 유형과 일치합니까?</p>
<p>이제 임의의 테스트 포인트 $x_*$에서 사후 예측 분포의 평균과 분산을 형성해 봅시다.</p>
<p>$$
\bar{f}<em>{*} = K(x, x</em>*)^T (K(x, x) + \sigma^2 I)^{-1}y
$$</p>
<p>$$
V(f_{<em>}) = K(x_</em>, x_<em>) - K(x, x_</em>)^T (K(x, x) + \sigma^2 I)^{-1}K(x, x_*)
$$</p>
<p>예측을 하기 전에 커널 하이퍼파라미터 $\theta$와 노이즈 분산 $\sigma^2$을 학습해야 합니다. 사전 함수가 우리가 피팅하는 데이터에 비해 너무 빠르게 변하는 것처럼 보였으므로 길이 척도를 0.75로 초기화해 봅시다. 또한 노이즈 표준 편차 $\sigma$를 0.75로 추측할 것입니다.</p>
<p>이러한 파라미터를 학습하기 위해, 이 파라미터에 대한 주변 우도를 최대화할 것입니다.</p>
<p>$$
\log p(y | X) = \log \int p(y | f, X)p(f | X)df
$$
$$
\log p(y | X) = -\frac{1}{2}y^T(K(x, x) + \sigma^2 I)^{-1}y - \frac{1}{2}\log |K(x, x) + \sigma^2 I| - \frac{n}{2}\log 2\pi
$$</p>
<p>아마도 우리의 사전 함수가 너무 빠르게 변했을 것입니다. 길이 척도를 0.4로 추측해 봅시다. 또한 노이즈 표준 편차를 0.75로 추측할 것입니다. 이들은 단순히 하이퍼파라미터 초기화입니다. 우리는 주변 우도에서 이러한 파라미터를 학습할 것입니다.</p>
<pre><code class="language-{.python .input}">ell_est = 0.4
post_sig_est = 0.5

def neg_MLL(pars):
    K = d2l.rbfkernel(train_x, train_x, ls=pars[0])
    kernel_term = -0.5 * train_y @ \
        np.linalg.inv(K + pars[1] ** 2 * np.eye(train_x.shape[0])) @ train_y
    logdet = -0.5 * np.log(np.linalg.det(K + pars[1] ** 2 * \
                                         np.eye(train_x.shape[0])))
    const = -train_x.shape[0] / 2. * np.log(2 * np.pi)
    
    return -(kernel_term + logdet + const)


learned_hypers = optimize.minimize(neg_MLL, x0=np.array([ell_est,post_sig_est]), 
                                   bounds=((0.01, 10.), (0.01, 10.)))
ell = learned_hypers.x[0]
post_sig_est = learned_hypers.x[1]
</code></pre>
<p>이 경우 우리는 길이 척도 0.299와 노이즈 표준 편차 0.24를 학습합니다. 학습된 노이즈가 실제 노이즈에 매우 가깝다는 점에 유의하십시오. 이는 우리 GP가 이 문제에 매우 잘 지정되었음을 나타내는 데 도움이 됩니다.</p>
<p>일반적으로 커널을 선택하고 하이퍼파라미터를 초기화하는 데 신중한 생각을 기울이는 것이 중요합니다. 주변 우도 최적화는 초기화에 비교적 견고할 수 있지만 나쁜 초기화에 면역이 되지는 않습니다. 다양한 초기화로 위의 스크립트를 실행해 보고 어떤 결과를 얻는지 확인해 보십시오.</p>
<p>이제 학습된 하이퍼파라미터로 예측을 해봅시다.</p>
<pre><code class="language-{.python .input}">K_x_xstar = d2l.rbfkernel(train_x, test_x, ls=ell)
K_x_x = d2l.rbfkernel(train_x, train_x, ls=ell)
K_xstar_xstar = d2l.rbfkernel(test_x, test_x, ls=ell)

post_mean = K_x_xstar.T @ np.linalg.inv((K_x_x + \
                post_sig_est ** 2 * np.eye(train_x.shape[0]))) @ train_y
post_cov = K_xstar_xstar - K_x_xstar.T @ np.linalg.inv((K_x_x + \
                post_sig_est ** 2 * np.eye(train_x.shape[0]))) @ K_x_xstar

lw_bd = post_mean - 2 * np.sqrt(np.diag(post_cov))
up_bd = post_mean + 2 * np.sqrt(np.diag(post_cov))

d2l.plt.scatter(train_x, train_y)
d2l.plt.plot(test_x, test_y, linewidth=2.)
d2l.plt.plot(test_x, post_mean, linewidth=2.)
d2l.plt.fill_between(test_x, lw_bd, up_bd, alpha=0.25)
d2l.plt.legend(['Observed Data', 'True Function', 'Predictive Mean', '95% Set on True Func'])
d2l.plt.show()
</code></pre>
<p>주황색의 사후 평균이 실제 노이즈 없는 함수와 거의 완벽하게 일치하는 것을 볼 수 있습니다! 우리가 보여주는 95% 신용 집합은 데이터 포인트가 아니라 잠재 <em>노이즈 없는</em>(실제) 함수에 대한 것입니다. 이 신용 집합이 실제 함수를 완전히 포함하고 있으며 지나치게 넓거나 좁아 보이지 않음을 알 수 있습니다. 우리는 그것이 데이터 포인트를 포함하기를 원하지도 기대하지도 않습니다. 관찰에 대한 신용 집합을 갖고 싶다면 다음을 계산해야 합니다.</p>
<pre><code class="language-{.python .input}">lw_bd_observed = post_mean - 2 * np.sqrt(np.diag(post_cov) + post_sig_est ** 2)
up_bd_observed = post_mean + 2 * np.sqrt(np.diag(post_cov) + post_sig_est ** 2)
</code></pre>
<p>두 가지 불확실성 소스가 있습니다. <em>줄일 수 있는</em> 불확실성을 나타내는 <em>인식적</em> 불확실성과 <em>우발적(aleatoric)</em> 또는 <em>줄일 수 없는</em> 불확실성입니다. 여기서 <em>인식적</em> 불확실성은 노이즈 없는 함수의 실제 값에 대한 불확실성을 나타냅니다. 데이터에서 멀어질수록 데이터와 일치하는 다양한 함수 값이 존재하므로 이 불확실성은 데이터 포인트에서 멀어질수록 커져야 합니다. 점점 더 많은 데이터를 관찰함에 따라 실제 함수에 대한 우리의 믿음은 더 확신을 갖게 되고 인식적 불확실성은 사라집니다. 이 경우 <em>우발적</em> 불확실성은 관찰 노이즈입니다. 데이터가 이 노이즈와 함께 우리에게 주어지며 줄일 수 없기 때문입니다.</p>
<p>데이터의 <em>인식적</em> 불확실성은 잠재 노이즈 없는 함수의 분산 np.diag(post_cov)에 의해 포착됩니다. <em>우발적</em> 불확실성은 노이즈 분산 post_sig_est**2에 의해 포착됩니다.</p>
<p>불행히도 사람들은 불확실성을 표현하는 방법에 대해 종종 부주의하여, 많은 논문이 완전히 정의되지 않은 오차 막대를 보여주거나, 인식적 불확실성 또는 우발적 불확실성 또는 둘 다를 시각화하고 있는지에 대한 명확한 감각이 없으며, 노이즈 분산을 노이즈 표준 편차와 혼동하고, 표준 편차를 표준 오차와 혼동하고, 신뢰 구간을 신용 집합과 혼동하는 등의 일이 발생합니다. 불확실성이 무엇을 나타내는지 정확하지 않으면 본질적으로 무의미합니다.</p>
<p>우리의 불확실성이 무엇을 나타내는지에 세심한 주의를 기울이는 정신으로, 노이즈 없는 함수에 대한 분산 추정치의 <em>제곱근</em>의 <em>두 배</em>를 취하고 있다는 점에 유의하는 것이 중요합니다. 예측 분포가 가우시안이므로 이 수량을 통해 실제 함수를 포함할 확률이 95%인 구간에 대한 우리의 믿음을 나타내는 95% 신용 집합을 형성할 수 있습니다. 노이즈 <em>분산</em>은 완전히 다른 스케일에 있으며 훨씬 덜 해석 가능합니다.</p>
<p>마지막으로 20개의 사후 샘플을 살펴봅시다. 이 샘플들은 사후적으로 우리 데이터에 적합할 수 있다고 믿는 함수의 유형을 알려줍니다.</p>
<pre><code class="language-{.python .input}">post_samples = np.random.multivariate_normal(post_mean, post_cov, size=20)
d2l.plt.scatter(train_x, train_y)
d2l.plt.plot(test_x, test_y, linewidth=2.)
d2l.plt.plot(test_x, post_mean, linewidth=2.)
d2l.plt.plot(test_x, post_samples.T, color='gray', alpha=0.25)
d2l.plt.fill_between(test_x, lw_bd, up_bd, alpha=0.25)
plt.legend(['Observed Data', 'True Function', 'Predictive Mean', 'Posterior Samples'])
d2l.plt.show()
</code></pre>
<p>기본 회귀 응용 프로그램에서는 사후 예측 평균과 표준 편차를 각각 점 예측기 및 불확실성 지표로 사용하는 것이 가장 일반적입니다. 몬테카를로 획득 함수를 사용한 베이지안 최적화 또는 모델 기반 RL을 위한 가우시안 프로세스와 같은 고급 응용 프로그램에서는 종종 사후 샘플을 취해야 합니다. 그러나 기본 응용 프로그램에서 엄격하게 요구되지 않더라도 이러한 샘플은 데이터에 대한 적합성에 대한 더 많은 직관을 제공하며 시각화에 포함하는 데 종종 유용합니다.</p>
<h2 id="gpytorch로-쉽게-만들기-making-life-easy-with-gpytorch"><a class="header" href="#gpytorch로-쉽게-만들기-making-life-easy-with-gpytorch">GPyTorch로 쉽게 만들기 (Making Life Easy with GPyTorch)</a></h2>
<p>우리가 보았듯이 기본 가우시안 프로세스 회귀를 처음부터 완전히 구현하는 것은 실제로 꽤 쉽습니다. 그러나 다양한 커널 선택을 탐색하거나, 근사 추론(분류에도 필요함)을 고려하거나, GP를 신경망과 결합하거나, 심지어 약 10,000개 이상의 포인트가 있는 데이터셋을 갖게 되면 처음부터 구현하는 것은 다루기 힘들고 번거로워집니다. SKI(KISS-GP라고도 함)와 같은 확장 가능한 GP 추론을 위한 가장 효과적인 방법 중 일부는 수백 줄의 코드로 고급 수치 선형 대수 루틴을 구현해야 할 수 있습니다.</p>
<p>이러한 경우 <em>GPyTorch</em> 라이브러리는 우리의 삶을 훨씬 쉽게 만들어 줄 것입니다. 우리는 가우시안 프로세스 수치 및 고급 방법에 대한 향후 노트북에서 GPyTorch에 대해 더 논의할 것입니다. GPyTorch 라이브러리에는 <a href="https://github.com/cornellius-gp/gpytorch/tree/master/examples">많은 예제</a>가 포함되어 있습니다. 패키지에 대한 감을 잡기 위해 <a href="https://github.com/cornellius-gp/gpytorch/blob/master/examples/01_Exact_GPs/Simple_GP_Regression.ipynb">간단한 회귀 예제</a>를 살펴보며 GPyTorch를 사용하여 위의 결과를 재현하도록 어떻게 조정할 수 있는지 보여줄 것입니다. 이것은 단순히 위의 기본 회귀를 재현하기 위해 많은 코드처럼 보일 수 있으며, 어떤 의미에서는 그렇습니다. 그러나 잠재적으로 수천 줄의 새 코드를 작성하는 대신 아래 코드에서 몇 줄만 변경하여 다양한 커널, 확장 가능한 추론 기술 및 근사 추론을 즉시 사용할 수 있습니다.</p>
<pre><code class="language-{.python .input}"># 먼저 데이터를 PyTorch에서 사용할 수 있도록 텐서로 변환해 봅시다
train_x = torch.tensor(train_x)
train_y = torch.tensor(train_y)
test_y = torch.tensor(test_y)

# 우리는 0 평균과 RBF 커널을 사용하여 정확한 GP 추론을 사용하고 있습니다
class ExactGPModel(gpytorch.models.ExactGP):
    def __init__(self, train_x, train_y, likelihood):
        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)
        self.mean_module = gpytorch.means.ZeroMean()
        self.covar_module = gpytorch.kernels.ScaleKernel(
            gpytorch.kernels.RBFKernel())
    
    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)
</code></pre>
<p>이 코드 블록은 데이터를 GPyTorch에 맞는 형식으로 넣고, 정확한 추론을 사용하고 있음을 지정하며, 사용하려는 평균 함수(0)와 커널 함수(RBF)를 지정합니다. 예를 들어 gpytorch.kernels.matern_kernel() 또는 gpyotrch.kernels.spectral_mixture_kernel()을 호출하여 다른 커널을 매우 쉽게 사용할 수 있습니다. 지금까지 우리는 근사를 하지 않고 예측 분포를 추론할 수 있는 정확한 추론에 대해서만 논의했습니다.
가우시안 프로세스의 경우 가우시안 우도가 있을 때만 정확한 추론을 수행할 수 있습니다. 더 구체적으로 말하자면, 관찰이 가우시안 프로세스로 표현되는 노이즈 없는 함수와 가우시안 노이즈로 생성된다고 가정할 때입니다.
향후 노트북에서는 이러한 가정을 할 수 없는 분류와 같은 다른 설정을 고려할 것입니다.</p>
<pre><code class="language-{.python .input}"># 가우시안 우도 초기화
likelihood = gpytorch.likelihoods.GaussianLikelihood()
model = ExactGPModel(train_x, train_y, likelihood)
training_iter = 50
# 최적 모델 하이퍼파라미터 찾기
model.train()
likelihood.train()
# adam 최적화 도구 사용, GaussianLikelihood 파라미터 포함
optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  
# 손실을 음의 로그 GP 주변 우도로 설정
mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)
</code></pre>
<p>여기서 우리는 사용하려는 우도(가우시안), 커널 하이퍼파라미터 훈련에 사용할 목적 함수(여기서는 주변 우도), 그리고 해당 목적 함수를 최적화하는 데 사용할 절차(이 경우 Adam)를 명시적으로 지정합니다. "확률적" 최적화 도구인 Adam을 사용하고 있지만, 이 경우에는 전체 배치 Adam입니다. 주변 우도는 데이터 인스턴스에 대해 인수분해되지 않으므로 데이터의 "미니배치"에 대한 최적화 도구를 사용할 수 없으며 수렴이 보장되지 않습니다. L-BFGS와 같은 다른 최적화 도구도 GPyTorch에서 지원됩니다. 표준 딥러닝과 달리 주변 우도를 최적화하는 작업을 잘 수행하는 것은 좋은 일반화와 강력하게 일치하며, 엄청나게 비싸지 않다고 가정할 때 L-BFGS와 같은 강력한 최적화 도구로 기울게 합니다.</p>
<pre><code class="language-{.python .input}">for i in range(training_iter):
    # 이전 반복의 기울기 0으로 설정
    optimizer.zero_grad()
    # 모델의 출력
    output = model(train_x)
    # 손실 계산 및 역전파 기울기
    loss = -mll(output, train_y)
    loss.backward()
    if i % 10 == 0:
        print(f'Iter {i+1:d}/{training_iter:d} - Loss: {loss.item():.3f} '
              f'squared lengthscale: '
              f'{model.covar_module.base_kernel.lengthscale.item():.3f} '
              f'noise variance: {model.likelihood.noise.item():.3f}')
    optimizer.step()
</code></pre>
<p>여기서 실제로 최적화 절차를 실행하고 10번의 반복마다 손실 값을 출력합니다.</p>
<pre><code class="language-{.python .input}"># 평가(예측 사후) 모드로 전환
test_x = torch.tensor(test_x)
model.eval()
likelihood.eval()
observed_pred = likelihood(model(test_x)) 
</code></pre>
<p>위의 코드 블록을 사용하면 테스트 입력에 대한 예측을 할 수 있습니다.</p>
<pre><code class="language-{.python .input}">with torch.no_grad():
    # 플롯 초기화
    f, ax = d2l.plt.subplots(1, 1, figsize=(4, 3))
    # 95% 신용 집합에 대한 상한 및 하한 가져오기 (이 경우 관찰 공간에서)
    lower, upper = observed_pred.confidence_region()
    ax.scatter(train_x.numpy(), train_y.numpy())
    ax.plot(test_x.numpy(), test_y.numpy(), linewidth=2.)
    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), linewidth=2.)
    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.25)
    ax.set_ylim([-1.5, 1.5])
    ax.legend(['True Function', 'Predictive Mean', 'Observed Data',
               '95% Credible Set'])
</code></pre>
<p>마지막으로 피팅을 플로팅합니다.</p>
<p>피팅이 사실상 동일함을 알 수 있습니다. 주목해야 할 몇 가지 사항: GPyTorch는 <em>제곱된</em> 길이 척도와 관찰 노이즈로 작업합니다. 예를 들어, 처음부터 작성한 코드에서 학습된 노이즈 표준 편차는 약 0.283입니다. GPyTorch가 찾은 노이즈 분산은 $0.81 \approx 0.283^2$입니다. GPyTorch 플롯에서는 잠재 함수 공간이 아닌 <em>관찰 공간</em>에 신용 집합을 표시하여 실제로 관찰된 데이터 포인트를 덮고 있음을 보여줍니다.</p>
<h2 id="요약-summary"><a class="header" href="#요약-summary">요약 (Summary)</a></h2>
<p>가우시안 프로세스 사전 분포를 데이터와 결합하여 사후 분포를 형성하고 이를 사용하여 예측을 할 수 있습니다. 또한 가우시안 프로세스의 변화율과 같은 속성을 제어하는 커널 하이퍼파라미터의 자동 학습에 유용한 주변 우도를 형성할 수 있습니다. 회귀에 대한 사후 분포를 형성하고 커널 하이퍼파라미터를 학습하는 메커니즘은 간단하며 약 12줄의 코드를 포함합니다. 이 노트북은 실제로 가우시안 프로세스를 빠르게 "시작하고 실행"하려는 독자에게 좋은 참고 자료입니다. 또한 GPyTorch 라이브러리를 소개했습니다. 기본 회귀를 위한 GPyTorch 코드는 비교적 길지만, 다른 커널 함수나 확장 가능한 추론 또는 분류를 위한 비가우시안 우드와 같이 향후 노트북에서 논의할 고급 기능을 위해 사소하게 수정할 수 있습니다.</p>
<h2 id="연습-문제-exercises"><a class="header" href="#연습-문제-exercises">연습 문제 (Exercises)</a></h2>
<ol>
<li>우리는 커널 하이퍼파라미터 <em>학습</em>의 중요성과 하이퍼파라미터 및 커널이 가우시안 프로세스의 일반화 속성에 미치는 영향을 강조했습니다. 하이퍼를 학습하는 단계를 건너뛰고 대신 다양한 길이 척도와 노이즈 분산을 추측하고 예측에 미치는 영향을 확인해 보십시오. 큰 길이 척도를 사용하면 어떻게 됩니까? 작은 길이 척도는요? 큰 노이즈 분산은요? 작은 노이즈 분산은요?</li>
<li>우리는 주변 우도가 볼록 목적 함수가 아니지만 길이 척도 및 노이즈 분산과 같은 하이퍼파라미터를 GP 회귀에서 안정적으로 추정할 수 있다고 말했습니다. 이것은 일반적으로 사실입니다. 실제로 주변 우도는 경험적 자기상관 함수("covariograms")를 피팅하는 것을 포함하는 공간 통계의 기존 접근 방식보다 길이 척도 하이퍼파라미터를 학습하는 데 <em>훨씬</em> 더 좋습니다. 틀림없이, 적어도 확장 가능한 추론에 대한 최근 작업 이전에 가우시안 프로세스 연구에 대한 머신러닝의 가장 큰 기여는 하이퍼파라미터 학습을 위한 주변 우도의 도입이었습니다.</li>
</ol>
<p><em>그러나</em> 이러한 파라미터의 다른 쌍조차도 많은 데이터셋에 대해 해석 가능하게 다른 타당한 설명을 제공하여 목적 함수에서 국소 최적값을 초래합니다. 큰 길이 척도를 사용하면 기본 실제 함수가 천천히 변한다고 가정합니다. 관찰된 데이터가 실제로 상당히 변하는 경우, 큰 길이 척도를 가질 수 있는 유일한 방법은 큰 노이즈 분산을 갖는 것입니다. 반면에 작은 길이 척도를 사용하면 피팅이 데이터의 변동에 매우 민감하여 노이즈(우발적 불확실성)로 변동을 설명할 여지가 거의 없습니다.</p>
<p>이러한 국소 최적값을 찾을 수 있는지 확인해 보십시오. 큰 노이즈가 있는 매우 큰 길이 척도와 작은 노이즈가 있는 작은 길이 척도로 초기화하십시오. 다른 솔루션으로 수렴합니까?</p>
<ol start="3">
<li>
<p>우리는 베이지안 방법의 근본적인 장점이 <em>인식적</em> 불확실성을 자연스럽게 표현하는 데 있다고 말했습니다. 위의 예에서는 인식적 불확실성의 효과를 완전히 볼 수 없습니다. 대신 <code>test_x = np.linspace(0, 10, 1000)</code>으로 예측해 보십시오. 예측이 데이터를 넘어서 이동함에 따라 95% 신용 집합에 어떤 일이 발생합니까? 해당 구간에서 실제 함수를 덮습니까? 해당 영역에서 우발적 불확실성만 시각화하면 어떻게 됩니까?</p>
</li>
<li>
<p>위의 예제를 실행하되, 대신 10,000, 20,000 및 40,000개의 훈련 포인트로 실행하고 런타임을 측정해 보십시오. 훈련 시간은 어떻게 확장됩니까? 대안으로 런타임은 테스트 포인트 수에 따라 어떻게 확장됩니까? 예측 평균과 예측 분산에 대해 다릅니까? 훈련 및 테스트 시간 복잡도를 이론적으로 해결하고 다른 수의 포인트로 위 코드를 실행하여 이 질문에 답하십시오.</p>
</li>
<li>
<p>Matern 커널과 같은 다른 공분산 함수를 사용하여 GPyTorch 예제를 실행해 보십시오. 결과는 어떻게 변합니까? GPyTorch 라이브러리에서 찾을 수 있는 스펙트럼 혼합 커널은 어떻습니까? 일부는 다른 것보다 주변 우도를 훈련하기가 더 쉽습니까? 장거리 대 단거리 예측에 더 가치 있는 것이 있습니까?</p>
</li>
<li>
<p>GPyTorch 예제에서는 관찰 노이즈를 포함한 예측 분포를 플로팅한 반면, "처음부터" 예제에서는 인식적 불확실성만 포함했습니다. 이번에는 인식적 불확실성만 플로팅하여 GPyTorch 예제를 다시 실행하고 처음부터 결과와 비교하십시오. 예측 분포가 이제 동일하게 보입니까? (그래야 합니다.)</p>
</li>
</ol>
<p>:begin_tab:<code>pytorch</code>
<a href="https://discuss.d2l.ai/t/12117">Discussions</a>
:end_tab:</p>
<pre><code></code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../chapter_gaussian-processes/gp-priors.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../chapter_hyperparameter-optimization/index.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../chapter_gaussian-processes/gp-priors.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../chapter_hyperparameter-optimization/index.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
